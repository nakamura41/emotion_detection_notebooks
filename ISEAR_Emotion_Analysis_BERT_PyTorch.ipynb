{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from pytorch_pretrained_bert.modeling import BertForSequenceClassification\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n",
    "\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, usually either \"0\" or \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6,7\"\n",
    "os.environ[\"TFHUB_CACHE_DIR\"]=\"tfhub_modules\"\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_rank = -1\n",
    "max_seq_length = 200\n",
    "bert_model = \"bert-base-uncased\"\n",
    "do_lower_case = True\n",
    "num_labels = 7\n",
    "gradient_accumulation_steps = 1\n",
    "train_batch_size = 32\n",
    "eval_batch_size = 8\n",
    "test_batch_size = 8\n",
    "learning_rate = 5e-5\n",
    "num_train_epochs = 3.0\n",
    "warmup_proportion = 0.1\n",
    "output_dir = \"bert\"\n",
    "do_train = True\n",
    "do_eval = True\n",
    "fp16 = True\n",
    "loss_scale = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if local_rank == -1:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "else:\n",
    "    torch.cuda.set_device(local_rank)\n",
    "    device = torch.device(\"cuda\", local_rank)\n",
    "    n_gpu = 1\n",
    "    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "    torch.distributed.init_process_group(backend='nccl')\n",
    "\n",
    "seed = 20190104\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2019 14:22:52 - INFO - __main__ -   device: cuda, n_gpu: 2, distributed training: False, 16-bits training: True\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"device: {}, n_gpu: {}, distributed training: {}, 16-bits training: {}\".format(\n",
    "    device, n_gpu, bool(local_rank != -1), fp16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer Comparison - NLTK Tokenizer vs BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"I love Kung Fu Panda and chicken tikka masala!\",\n",
    "    \"Divide each difficulty into as many parts as is feasible and necessary to resolve it.\",\n",
    "    \"It is not enough to have a good mind; the main thing is to use it well.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   [   'i',\n",
      "        'love',\n",
      "        'kung',\n",
      "        'fu',\n",
      "        'panda',\n",
      "        'and',\n",
      "        'chicken',\n",
      "        'tikka',\n",
      "        'masala',\n",
      "        '!'],\n",
      "    [   'divide',\n",
      "        'each',\n",
      "        'difficulty',\n",
      "        'into',\n",
      "        'as',\n",
      "        'many',\n",
      "        'parts',\n",
      "        'as',\n",
      "        'is',\n",
      "        'feasible',\n",
      "        'and',\n",
      "        'necessary',\n",
      "        'to',\n",
      "        'resolve',\n",
      "        'it',\n",
      "        '.'],\n",
      "    [   'it',\n",
      "        'is',\n",
      "        'not',\n",
      "        'enough',\n",
      "        'to',\n",
      "        'have',\n",
      "        'a',\n",
      "        'good',\n",
      "        'mind',\n",
      "        ';',\n",
      "        'the',\n",
      "        'main',\n",
      "        'thing',\n",
      "        'is',\n",
      "        'to',\n",
      "        'use',\n",
      "        'it',\n",
      "        'well',\n",
      "        '.']]\n"
     ]
    }
   ],
   "source": [
    "nltk_tokenized_text = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
    "pp.pprint(nltk_tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2019 14:23:18 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/david/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   [   'i',\n",
      "        'love',\n",
      "        'kung',\n",
      "        'fu',\n",
      "        'panda',\n",
      "        'and',\n",
      "        'chicken',\n",
      "        'ti',\n",
      "        '##kka',\n",
      "        'mas',\n",
      "        '##ala',\n",
      "        '!'],\n",
      "    [   'divide',\n",
      "        'each',\n",
      "        'difficulty',\n",
      "        'into',\n",
      "        'as',\n",
      "        'many',\n",
      "        'parts',\n",
      "        'as',\n",
      "        'is',\n",
      "        'feasible',\n",
      "        'and',\n",
      "        'necessary',\n",
      "        'to',\n",
      "        'resolve',\n",
      "        'it',\n",
      "        '.'],\n",
      "    [   'it',\n",
      "        'is',\n",
      "        'not',\n",
      "        'enough',\n",
      "        'to',\n",
      "        'have',\n",
      "        'a',\n",
      "        'good',\n",
      "        'mind',\n",
      "        ';',\n",
      "        'the',\n",
      "        'main',\n",
      "        'thing',\n",
      "        'is',\n",
      "        'to',\n",
      "        'use',\n",
      "        'it',\n",
      "        'well',\n",
      "        '.']]\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_model, do_lower_case=do_lower_case)\n",
    "bert_tokenized_text = [bert_tokenizer.tokenize(sentence) for sentence in sentences]\n",
    "pp.pprint(bert_tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2019 14:23:18 - INFO - __main__ -   {'anger': 0, 'sadness': 1, 'joy': 2}\n"
     ]
    }
   ],
   "source": [
    "label_list = [\"anger\", \"sadness\", \"joy\"]\n",
    "label_map = {label : i for i, label in enumerate(label_list)}\n",
    "logger.info(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISEARDataset(object):\n",
    "    FILENAME = \"data/isear_databank.csv\"\n",
    "    RANDOM_STATE = 41\n",
    "  \n",
    "    def get_labels(self):\n",
    "        return [\"anger\", \"disgust\", \"fear\", \"guilt\", \"joy\", \"sadness\", \"shame\"]\n",
    "  \n",
    "    def get_label_map(self):\n",
    "        return {label : i for i, label in enumerate(self.get_labels())}\n",
    "    \n",
    "    def len(self):\n",
    "        return len(self.data.index)\n",
    "\n",
    "    def __init__(self, n_items=0):\n",
    "        data = pd.read_csv(self.FILENAME)\n",
    "\n",
    "        if n_items > 0:\n",
    "            data = data.iloc[0:n_items,:]\n",
    "\n",
    "        data[\"text\"] = data[\"SIT\"]\n",
    "        data[\"label\"] = data[\"Field1\"]\n",
    "\n",
    "        for label in self.get_labels():\n",
    "            data.loc[data[\"label\"] == label, \"label_int\"] = self.get_label_map()[label]\n",
    "            \n",
    "        self.data = data[[\"text\", \"label\", \"label_int\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ISEARDataset()\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(dataset.data, test_size=0.3, random_state=dataset.RANDOM_STATE, stratify=dataset.data.label)\n",
    "train_dataset, eval_dataset = train_test_split(train_dataset, test_size=0.2, random_state=dataset.RANDOM_STATE, stratify=train_dataset.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2019 14:23:18 - INFO - __main__ -   row index:6800\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   text:The time when my sister had her first baby I was so happy and á\n",
      "joyous because she stayed for two days after marriage before she á\n",
      "had a child.\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   label:joy\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   label_int:4.0\n"
     ]
    }
   ],
   "source": [
    "for (row_index, row) in train_dataset.iterrows():\n",
    "    logger.info(\"row index:{}\".format(row_index))\n",
    "    logger.info(\"text:{}\".format(row.text))\n",
    "    logger.info(\"label:{}\".format(row.label))\n",
    "    logger.info(\"label_int:{}\".format(row.label_int))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "        \n",
    "def convert_dataset_to_features(dataset, label_map, max_seq_length, tokenizer):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "\n",
    "    features = []\n",
    "    index = 0\n",
    "    for (guid, row) in dataset.iterrows():\n",
    "        tokens = tokenizer.tokenize(row.text)\n",
    "\n",
    "        # Account for [CLS] and [SEP] with \"- 2\"\n",
    "        if len(tokens) > max_seq_length - 2:\n",
    "            tokens = tokens[:(max_seq_length - 2)]\n",
    "\n",
    "        # The convention in BERT is:\n",
    "        # (a) For sequence pairs:\n",
    "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "        #  type_ids: 0   0  0    0    0     0       0 0    1  1  1  1   1 1\n",
    "        # (b) For single sequences:\n",
    "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
    "        #  type_ids: 0   0   0   0  0     0 0\n",
    "        #\n",
    "        # Where \"type_ids\" are used to indicate whether this is the first\n",
    "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
    "        # embedding vector (and position vector). This is not *strictly* necessary\n",
    "        # since the [SEP] token unambigiously separates the sequences, but it makes\n",
    "        # it easier for the model to learn the concept of sequences.\n",
    "        #\n",
    "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
    "        # the entire model is fine-tuned.\n",
    "        tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "        segment_ids = [0] * len(tokens)\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "\n",
    "        label_id = label_map[row.label]\n",
    "        if index < 5:\n",
    "            logger.info(\"*** row ***\")\n",
    "            logger.info(\"guid: %s\" % (guid))\n",
    "            logger.info(\"tokens: %s\" % \" \".join(\n",
    "                    [str(x) for x in tokens]))\n",
    "            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "            logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "            logger.info(\n",
    "                    \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "            logger.info(\"label: %s (id = %d)\" % (row.label, label_id))\n",
    "\n",
    "        features.append(\n",
    "                InputFeatures(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              label_id=label_id))\n",
    "        index += 1\n",
    "        \n",
    "    return features\n",
    "\n",
    "\n",
    "def _truncate_seq_pair(tokens, tokens_b, max_length):\n",
    "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "    # This is a simple heuristic which will always truncate the longer sequence\n",
    "    # one token at a time. This makes more sense than truncating an equal percent\n",
    "    # of tokens from each, since if one sequence is very short then each token\n",
    "    # that's truncated likely contains more information than a longer sequence.\n",
    "    while True:\n",
    "        total_length = len(tokens) + len(tokens_b)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        if len(tokens) > len(tokens_b):\n",
    "            tokens.pop()\n",
    "        else:\n",
    "            tokens_b.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2019 14:23:18 - INFO - __main__ -   *** row ***\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   guid: 6800\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   tokens: [CLS] the time when my sister had her first baby i was so happy and a joy ##ous because she stayed for two days after marriage before she a had a child . [SEP]\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   input_ids: 101 1996 2051 2043 2026 2905 2018 2014 2034 3336 1045 2001 2061 3407 1998 1037 6569 3560 2138 2016 4370 2005 2048 2420 2044 3510 2077 2016 1037 2018 1037 2775 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   label: joy (id = 4)\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   *** row ***\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   guid: 4663\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   tokens: [CLS] when i learnt that i was selected for form i . [SEP]\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   input_ids: 101 2043 1045 20215 2008 1045 2001 3479 2005 2433 1045 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   label: joy (id = 4)\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   *** row ***\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   guid: 6867\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   tokens: [CLS] saw my brother - in - law insulting my sister . [SEP]\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   input_ids: 101 2387 2026 2567 1011 1999 1011 2375 23979 2026 2905 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   label: disgust (id = 1)\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   *** row ***\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   guid: 1517\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   tokens: [CLS] my little cat which i had raised all by myself , hanged itself when a playing in the garden . [SEP]\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   input_ids: 101 2026 2210 4937 2029 1045 2018 2992 2035 2011 2870 1010 17818 2993 2043 1037 2652 1999 1996 3871 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   label: sadness (id = 5)\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   *** row ***\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   guid: 5687\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   tokens: [CLS] i bought a possible answer to a homework problem which was a completely ina ##pp ##lica ##ble to the question due to my not having read a about the subject matter . [SEP]\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   input_ids: 101 1045 4149 1037 2825 3437 2000 1037 19453 3291 2029 2001 1037 3294 27118 9397 19341 3468 2000 1996 3160 2349 2000 2026 2025 2383 3191 1037 2055 1996 3395 3043 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2019 14:23:18 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:18 - INFO - __main__ -   label: shame (id = 6)\n"
     ]
    }
   ],
   "source": [
    "train_features = convert_dataset_to_features(train_dataset, dataset.get_label_map(), max_seq_length, bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2019 14:23:21 - INFO - __main__ -   *** row ***\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   guid: 3305\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   tokens: [CLS] when i decided to leave my steady , secure employment to come to a university . because i didn ' t know if i could cope with all the a requirements of study and also being older i didn ' t know if i a would enjoy mixing with younger people , also financial a ins ##ec ##urity . [SEP]\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   input_ids: 101 2043 1045 2787 2000 2681 2026 6706 1010 5851 6107 2000 2272 2000 1037 2118 1012 2138 1045 2134 1005 1056 2113 2065 1045 2071 11997 2007 2035 1996 1037 5918 1997 2817 1998 2036 2108 3080 1045 2134 1005 1056 2113 2065 1045 1037 2052 5959 6809 2007 3920 2111 1010 2036 3361 1037 16021 8586 25137 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   label: fear (id = 2)\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   *** row ***\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   guid: 5944\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   tokens: [CLS] when i failed the m . s . c exam . [SEP]\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   input_ids: 101 2043 1045 3478 1996 1049 1012 1055 1012 1039 11360 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   label: shame (id = 6)\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   *** row ***\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   guid: 1743\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   tokens: [CLS] my school ##mates were teasing a pupil who was not able to defend a himself very well ; i should have taken his part . [SEP]\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   input_ids: 101 2026 2082 15416 2020 12216 1037 11136 2040 2001 2025 2583 2000 6985 1037 2370 2200 2092 1025 1045 2323 2031 2579 2010 2112 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   label: guilt (id = 3)\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   *** row ***\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   guid: 6909\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   tokens: [CLS] a woman picked her nose and spit right next to me . [SEP]\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   input_ids: 101 1037 2450 3856 2014 4451 1998 13183 2157 2279 2000 2033 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   label: disgust (id = 1)\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   *** row ***\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   guid: 7466\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   tokens: [CLS] when the thing that made my friends and relatives sad happened to a them . [SEP]\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   input_ids: 101 2043 1996 2518 2008 2081 2026 2814 1998 9064 6517 3047 2000 1037 2068 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2019 14:23:21 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   label: sadness (id = 5)\n"
     ]
    }
   ],
   "source": [
    "eval_features = convert_dataset_to_features(eval_dataset, dataset.get_label_map(), max_seq_length, bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2019 14:23:21 - INFO - __main__ -   *** row ***\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   guid: 3559\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   tokens: [CLS] a person i know who tells lies and so pretending to be better a than she is . [SEP]\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   input_ids: 101 1037 2711 1045 2113 2040 4136 3658 1998 2061 12097 2000 2022 2488 1037 2084 2016 2003 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   label: disgust (id = 1)\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   *** row ***\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   guid: 5810\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   tokens: [CLS] recent break - up with my girlfriend . we had been together for over a a year . i was overseas and discovered over the phone ( while i was a at work ) . [SEP]\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   input_ids: 101 3522 3338 1011 2039 2007 2026 6513 1012 2057 2018 2042 2362 2005 2058 1037 1037 2095 1012 1045 2001 6931 1998 3603 2058 1996 3042 1006 2096 1045 2001 1037 2012 2147 1007 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   label: sadness (id = 5)\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   *** row ***\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   guid: 5673\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   tokens: [CLS] i had just master ##bate ##d with another boy . [SEP]\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   input_ids: 101 1045 2018 2074 3040 20179 2094 2007 2178 2879 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   label: shame (id = 6)\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   *** row ***\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   guid: 697\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   tokens: [CLS] [ no response . ] [SEP]\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   input_ids: 101 1031 2053 3433 1012 1033 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   label: shame (id = 6)\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   *** row ***\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   guid: 1092\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   tokens: [CLS] when we decided , my boyfriend and i , that we would separate , i a realized that he would have wanted to continue our relationship a and the coming separation hurt him . [SEP]\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   input_ids: 101 2043 2057 2787 1010 2026 6898 1998 1045 1010 2008 2057 2052 3584 1010 1045 1037 3651 2008 2002 2052 2031 2359 2000 3613 2256 3276 1037 1998 1996 2746 8745 3480 2032 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2019 14:23:21 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2019 14:23:21 - INFO - __main__ -   label: sadness (id = 5)\n"
     ]
    }
   ],
   "source": [
    "test_features = convert_dataset_to_features(test_dataset, dataset.get_label_map(), max_seq_length, bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2019 14:23:23 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/david/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "01/25/2019 14:23:23 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/david/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmph69q1q0m\n",
      "01/25/2019 14:23:28 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "01/25/2019 14:23:33 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "01/25/2019 14:23:33 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "# Prepare model\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    bert_model,\n",
    "    cache_dir=PYTORCH_PRETRAINED_BERT_CACHE / 'distributed_{}'.format(local_rank),\n",
    "    num_labels = num_labels\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "if fp16:\n",
    "    model.half()\n",
    "        \n",
    "if local_rank != -1:\n",
    "    try:\n",
    "        from apex.parallel import DistributedDataParallel as DDP\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
    "\n",
    "    model = DDP(model)\n",
    "elif n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2019 14:23:38 - INFO - __main__ -   train_batch_size = 32\n",
      "01/25/2019 14:23:38 - INFO - __main__ -   num train_dataset = 4292\n",
      "01/25/2019 14:23:38 - INFO - __main__ -   gradient_accumulation_steps = 1\n",
      "01/25/2019 14:23:38 - INFO - __main__ -   num_train_epochs = 3.0\n",
      "01/25/2019 14:23:38 - INFO - __main__ -   num_train_steps = 402\n",
      "01/25/2019 14:23:38 - INFO - __main__ -   t_total = 402\n"
     ]
    }
   ],
   "source": [
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "train_batch_size = int(train_batch_size / gradient_accumulation_steps)\n",
    "logger.info(\"train_batch_size = {}\".format(train_batch_size))\n",
    "logger.info(\"num train_dataset = {}\".format(len(train_dataset)))\n",
    "logger.info(\"gradient_accumulation_steps = {}\".format(gradient_accumulation_steps))\n",
    "logger.info(\"num_train_epochs = {}\".format(num_train_epochs))\n",
    "\n",
    "num_train_steps = int(\n",
    "    len(train_dataset) / train_batch_size / gradient_accumulation_steps * num_train_epochs\n",
    ")\n",
    "logger.info(\"num_train_steps = {}\".format(num_train_steps))\n",
    "\n",
    "t_total = num_train_steps\n",
    "\n",
    "if local_rank != -1:\n",
    "    t_total = t_total // torch.distributed.get_world_size()\n",
    "\n",
    "logger.info(\"t_total = {}\".format(t_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fp16:\n",
    "    try:\n",
    "        from apex.optimizers import FP16_Optimizer\n",
    "        from apex.optimizers import FusedAdam\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
    "\n",
    "    optimizer = FusedAdam(optimizer_grouped_parameters,\n",
    "                          lr=learning_rate,\n",
    "                          bias_correction=False,\n",
    "                          max_grad_norm=1.0)\n",
    "    if loss_scale == 0:\n",
    "        optimizer = FP16_Optimizer(optimizer, dynamic_loss_scale=True)\n",
    "    else:\n",
    "        optimizer = FP16_Optimizer(optimizer, static_loss_scale=loss_scale)\n",
    "\n",
    "else:\n",
    "    optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                         lr=learning_rate,\n",
    "                         warmup=warmup_proportion,\n",
    "                         t_total=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2019 14:23:38 - INFO - __main__ -   ***** Running training *****\n",
      "01/25/2019 14:23:38 - INFO - __main__ -     Num examples = 4292\n",
      "01/25/2019 14:23:38 - INFO - __main__ -     Batch size = 32\n",
      "01/25/2019 14:23:38 - INFO - __main__ -     Num steps = 402\n"
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "nb_tr_steps = 0\n",
    "tr_loss = 0\n",
    "    \n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "logger.info(\"  Batch size = %d\", train_batch_size)\n",
    "logger.info(\"  Num steps = %d\", num_train_steps)\n",
    "train_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "train_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "train_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "train_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 1996, 2051,  ...,    0,    0,    0],\n",
       "        [ 101, 2043, 1045,  ...,    0,    0,    0],\n",
       "        [ 101, 2387, 2026,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 1037, 2154,  ...,    0,    0,    0],\n",
       "        [ 101, 2019, 8875,  ...,    0,    0,    0],\n",
       "        [ 101, 2043, 2026,  ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 101, 1996, 2051, 2043, 2026, 2905, 2018, 2014, 2034, 3336, 1045, 2001,\n",
       "        2061, 3407, 1998, 1037, 6569, 3560, 2138, 2016, 4370, 2005, 2048, 2420,\n",
       "        2044, 3510, 2077, 2016, 1037, 2018, 1037, 2775, 1012,  102,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4292, 200])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4292, 200])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_segment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_segment_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4292, 200])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_segment_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 1,  ..., 6, 3, 5])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4292])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_input_ids, train_input_mask, train_segment_ids, train_label_ids)\n",
    "if local_rank == -1:\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "else:\n",
    "    train_sampler = DistributedSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.sampler.RandomSampler at 0x7f3afd2f6b00>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2019 14:23:38 - INFO - __main__ -   num_train_epochs = 3.0\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"num_train_epochs = {}\".format(num_train_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(preds, labels):\n",
    "    return np.sum(preds == labels)\n",
    "\n",
    "def warmup_linear(x, warmup=0.002):\n",
    "    if x < warmup:\n",
    "        return x/warmup\n",
    "    return 1.0 - x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98faf601de8446dba93efbf1ef28e7bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=135, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grad overflow on iteration 0\n",
      "Using dynamic loss scale of 4294967296\n",
      "\n",
      "Grad overflow on iteration 1\n",
      "Using dynamic loss scale of 2147483648.0\n",
      "\n",
      "Grad overflow on iteration 2\n",
      "Using dynamic loss scale of 1073741824.0\n",
      "\n",
      "Grad overflow on iteration 3\n",
      "Using dynamic loss scale of 536870912.0\n",
      "\n",
      "Grad overflow on iteration 4\n",
      "Using dynamic loss scale of 268435456.0\n",
      "\n",
      "Grad overflow on iteration 5\n",
      "Using dynamic loss scale of 134217728.0\n",
      "\n",
      "Grad overflow on iteration 6\n",
      "Using dynamic loss scale of 67108864.0\n",
      "\n",
      "Grad overflow on iteration 7\n",
      "Using dynamic loss scale of 33554432.0\n",
      "\n",
      "Grad overflow on iteration 8\n",
      "Using dynamic loss scale of 16777216.0\n",
      "\n",
      "Grad overflow on iteration 9\n",
      "Using dynamic loss scale of 8388608.0\n",
      "\n",
      "Grad overflow on iteration 10\n",
      "Using dynamic loss scale of 4194304.0\n",
      "\n",
      "Grad overflow on iteration 11\n",
      "Using dynamic loss scale of 2097152.0\n",
      "\n",
      "Grad overflow on iteration 12\n",
      "Using dynamic loss scale of 1048576.0\n",
      "\n",
      "Grad overflow on iteration 13\n",
      "Using dynamic loss scale of 524288.0\n",
      "\n",
      "Grad overflow on iteration 14\n",
      "Using dynamic loss scale of 262144.0\n",
      "\n",
      "Grad overflow on iteration 15\n",
      "Using dynamic loss scale of 131072.0\n",
      "\n",
      "Grad overflow on iteration 16\n",
      "Using dynamic loss scale of 65536.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|███▎      | 1/3 [01:27<02:54, 87.46s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4455de2a496476db82c951862febf3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=135, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████▋   | 2/3 [02:50<01:26, 86.10s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849426425c4248f5aef7ddcd4a4e85a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=135, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 3/3 [04:14<00:00, 85.39s/it]\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for _ in trange(int(num_train_epochs), desc=\"Epoch\"):\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        train_input_ids, train_input_mask, train_segment_ids, train_label_ids = batch\n",
    "        loss = model(train_input_ids, train_segment_ids, train_input_mask, train_label_ids)\n",
    "        if n_gpu > 1:\n",
    "            loss = loss.mean() # mean() to average on multi-gpu.\n",
    "        if gradient_accumulation_steps > 1:\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "            \n",
    "        if fp16:\n",
    "            optimizer.backward(loss)\n",
    "        else:\n",
    "            loss.backward()\n",
    "            \n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += train_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "            # modify learning rate with special warm up BERT uses\n",
    "            lr_this_step = learning_rate * warmup_linear(global_step/t_total, warmup_proportion)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr_this_step\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "train_loss = tr_loss/nb_tr_steps if do_train else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2019 14:28:29 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/david/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "01/25/2019 14:28:29 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/david/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpl42d5x92\n",
      "01/25/2019 14:28:33 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1)\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save a trained model\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "output_model_file = \"pytorch_isear_bert_model.pt\"\n",
    "torch.save(model_to_save.state_dict(), output_model_file)\n",
    "\n",
    "# Load a trained model that you have fine-tuned\n",
    "model_state_dict = torch.load(output_model_file)\n",
    "model = BertForSequenceClassification.from_pretrained(bert_model, state_dict=model_state_dict, num_labels=num_labels)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(mode, features, batch_size):\n",
    "    logger.info(\"***** Running {} *****\".format(mode))\n",
    "    logger.info(\"  Num examples = %d\", len(features))\n",
    "    logger.info(\"  Batch size = %d\", batch_size)\n",
    "    \n",
    "    input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "    data = TensorDataset(input_ids, input_mask, segment_ids, label_ids)\n",
    "    \n",
    "    # Run prediction for full data\n",
    "    sampler = SequentialSampler(data)\n",
    "    dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n",
    "\n",
    "    model.eval()\n",
    "    loss, accuracy = 0, 0\n",
    "    nb_steps, nb_examples = 0, 0\n",
    "    all_pred_label_ids = []\n",
    "    all_actual_label_ids = []\n",
    "\n",
    "    for input_ids, input_mask, segment_ids, label_ids in tqdm(dataloader, desc=mode):\n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "        label_ids = label_ids.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tmp_loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "            logits = model(input_ids, segment_ids, input_mask)\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        preds = np.argmax(logits, axis=1)\n",
    "        \n",
    "        label_ids = label_ids.to('cpu').numpy()\n",
    "        \n",
    "        all_pred_label_ids += preds.tolist()\n",
    "        all_actual_label_ids += label_ids.tolist()\n",
    "        \n",
    "        tmp_accuracy = calc_accuracy(preds, label_ids)\n",
    "\n",
    "        loss += tmp_loss.mean().item()\n",
    "        accuracy += tmp_accuracy\n",
    "\n",
    "        nb_examples += input_ids.size(0)\n",
    "        nb_steps += 1\n",
    "\n",
    "    loss = loss / nb_steps\n",
    "    accuracy = accuracy / nb_examples\n",
    "    \n",
    "    result = {'{}_loss'.format(mode): loss,\n",
    "              '{}_accuracy'.format(mode): accuracy,\n",
    "              'global_step': global_step}\n",
    "\n",
    "    output_file = \"pytorch_isear_bert_{}_results.txt\".format(mode)\n",
    "    with open(output_file, \"w\") as writer:\n",
    "        logger.info(\"***** {} results *****\".format(mode))\n",
    "        for key in sorted(result.keys()):\n",
    "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "\n",
    "    return loss, accuracy, all_pred_label_ids, all_actual_label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2019 14:28:36 - INFO - __main__ -   ***** Running eval *****\n",
      "01/25/2019 14:28:36 - INFO - __main__ -     Num examples = 1074\n",
      "01/25/2019 14:28:36 - INFO - __main__ -     Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfdd20afd8b441ebaa714297187aa6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='eval', max=135, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2019 14:28:49 - INFO - __main__ -   ***** eval results *****\n",
      "01/25/2019 14:28:49 - INFO - __main__ -     eval_accuracy = 0.6983240223463687\n",
      "01/25/2019 14:28:49 - INFO - __main__ -     eval_loss = 1.0040278805626763\n",
      "01/25/2019 14:28:49 - INFO - __main__ -     global_step = 405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = evaluate('eval', eval_features, eval_batch_size)\n",
    "eval_loss, eval_accuracy, eval_pred_label_ids, eval_actual_label_ids = eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>guilt</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>shame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>110</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>25</td>\n",
       "      <td>91</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guilt</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shame</th>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         anger  disgust  fear  guilt  joy  sadness  shame\n",
       "anger      110       17     5      9    2        2      9\n",
       "disgust     25       91     7      3    5        5     17\n",
       "fear         6        7   119      2    2        6     11\n",
       "guilt        8        2     4    103    1       13     22\n",
       "joy          2        3     1      2  132        6      7\n",
       "sadness     13        1     8     11    3      107     11\n",
       "shame       16        6     2     31    5        6     88"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "cf_matrix = confusion_matrix(eval_actual_label_ids, eval_pred_label_ids)\n",
    "\n",
    "df_cm = pd.DataFrame(\n",
    "    cf_matrix, index=dataset.get_labels(), columns=dataset.get_labels(), \n",
    ")\n",
    "\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (4,3), fontsize=15):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure(288x216)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(print_confusion_matrix(cf_matrix, class_names=dataset.get_labels()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.6111</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.6587</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>0.7165</td>\n",
       "      <td>0.5948</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.8151</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.7960</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guilt</th>\n",
       "      <td>0.6398</td>\n",
       "      <td>0.6732</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.8627</td>\n",
       "      <td>0.8713</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.7379</td>\n",
       "      <td>0.6948</td>\n",
       "      <td>0.7157</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shame</th>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.5517</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         precision  recall  f1-score  support\n",
       "anger       0.6111  0.7143    0.6587      154\n",
       "disgust     0.7165  0.5948    0.6500      153\n",
       "fear        0.8151  0.7778    0.7960      153\n",
       "guilt       0.6398  0.6732    0.6561      153\n",
       "joy         0.8800  0.8627    0.8713      153\n",
       "sadness     0.7379  0.6948    0.7157      154\n",
       "shame       0.5333  0.5714    0.5517      154"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, fscore, support = precision_recall_fscore_support(eval_actual_label_ids, eval_pred_label_ids)\n",
    "score_dict = {\n",
    "  \"precision\": precision.round(4),\n",
    "  \"recall\": recall.round(4),\n",
    "  \"f1-score\": fscore.round(4),\n",
    "  \"support\": support.round(4)\n",
    "}\n",
    "score_df = pd.DataFrame(score_dict, index=dataset.get_labels())\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa: 0.6480341147245171\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "kappa_score = cohen_kappa_score(eval_actual_label_ids, eval_pred_label_ids)\n",
    "print(\"kappa:\", kappa_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2019 14:28:50 - INFO - __main__ -   ***** Running eval *****\n",
      "01/25/2019 14:28:50 - INFO - __main__ -     Num examples = 2300\n",
      "01/25/2019 14:28:50 - INFO - __main__ -     Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd56948e61914ca3a42a18c77aec21e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='eval', max=288, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2019 14:29:18 - INFO - __main__ -   ***** eval results *****\n",
      "01/25/2019 14:29:18 - INFO - __main__ -     eval_accuracy = 0.7043478260869566\n",
      "01/25/2019 14:29:18 - INFO - __main__ -     eval_loss = 0.9534986084844503\n",
      "01/25/2019 14:29:18 - INFO - __main__ -     global_step = 405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_result = evaluate('eval', test_features, test_batch_size)\n",
    "test_loss, test_accuracy, test_pred_label_ids, test_actual_label_ids = test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>guilt</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>shame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>220</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>47</td>\n",
       "      <td>223</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>259</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guilt</th>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>219</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>276</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>227</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shame</th>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         anger  disgust  fear  guilt  joy  sadness  shame\n",
       "anger      220       27    16     19    8       13     26\n",
       "disgust     47      223    18      3    2       12     24\n",
       "fear        10       14   259     13   11       11     10\n",
       "guilt       28        9    11    219    2       10     49\n",
       "joy          5        2    10      4  276       14     17\n",
       "sadness     35       12    15     11   10      227     19\n",
       "shame       27       11    14     66    7        8    196"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "cf_matrix = confusion_matrix(test_actual_label_ids, test_pred_label_ids)\n",
    "\n",
    "df_cm = pd.DataFrame(\n",
    "    cf_matrix, index=dataset.get_labels(), columns=dataset.get_labels(), \n",
    ")\n",
    "\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure(288x216)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAD/CAYAAACAew++AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzsnXd4FFUXh9+ThBISakIHaSKIqKD0JqEHUDpiQVFQaRZA/EBBOtKL0qR3pAooRbp0CQLSexVICEV6STnfHzMJS0g2ZXdDAvPyzEP2zp1z7+xuTm45c36iqlhYWFg8i7g96Q5YWFhYPCksB2hhYfHMYjlACwuLZxbLAVpYWDyzWA7QwsLimcVygBYWFs8slgO0sLB4ZrEcoIWFxTOL5QAtLCyeWTyedAeeFe5O7OjyR26Kdtng6ia4EXLb5W0AuIvr/zZfv3/H5W0ApHZP4fI2MqZO6/I2AE5e3i1xrRty+aTd73wK3/xxtuUqLAdoYWHhGsJCnnQPYsVygBYWFq4hPPxJ9yBWLAdoYWHhEjQs9El3IVYsB2hhYeEa1BoBWlhYPKtYa4AWFhbPLNYaoEVMBN64S7fle7h65wEAjV59jvdez8ewDYfYeCKIFG5u5MqQhl7+r5IutRFGMWn7cRbvO4ebCP+r+hLl8mWOc3vZc2RlyJje+GT2QVWZO30RU8fP4ceJA8hXIA8A6dKn5cb1m7zp906C72vkqP5Ur1WZy8FXqFT2zcjyVp++z8efvEdYWBirV/1J7+8HJ7gNgOGj+lK9ZmUuB1+lcrm3AChStBCDhvXEyysN586dp+0nnbl103lhO59/3pIWLZqhqhw4cJhPP+3M/fv3Hbb705gfqOlfhcvBVyhXqjYA33b/itp1qhEeHk5w8FXaffYNgYGXEtyG8fn3wdf8/H+ZvpCp4+cA8EGrZjRv2ZSwsHDWr97EwF4jHb4nSB5rgGJlhHYcEfFU1bv26kSNAwy+dY/Lt+/zYtb03H4QyjvTNzO8/usE3bxHqTw+eLi5MeLPQwB89caLnLh8k66/72bm++UJvnWfz+b9xZJWlXF3exhKZS8OMHNWX7Jk9eXA3sN4eadhydpZtG7ekeNHT0XW6dq7Azdv3GLUkAkx2oktDrBsuRLcvn2HUeMGRjrA8hVL0+Hr1rzb5FMePAjB1zcTly9ftWsntjjAMmY7P40dEOkAV66bR6/ug9m2JYB33m9I7jy5GNTvxxhtxCcOMEeOrKxdu5Dixaty7959Zs4czcqV65k5c0Gs18YWB1iufElu3brDuAmDIx1g2rTe3Lx5C4BP23xA4cLP0/HL72O0EVscYNTPf+na2XzWvCO+WTLRrkMrWr7zOQ8ehODjm5Erl6/FaCc+cYD3D/9p17mkKvzGE48DTPJPgohIWRFZKiIXReS2iOwRkfdszrcQERWRl0VktVnnsIg0jGJHRKSPiFwSkRsiMllEmpnX5rWpl1pEBonIORG5LyL/iEjtKLZOi8hQEekuIv8CN+J7X5m9U/Ni1vQAeKX0IL+PN5du3aNcvsx4uBkfyyvZMxJ08x4AG44HUbNwDlJ6uJMzQxpyZ0zD/ov/xbm94KDLHNh7GIDbt+5w/OgpsmbP8kidOvWq8/uilfG9lUfYtnUn165df6Tso5bv8OPw8Tx4YKwJxeb84sL2rTv579qj95+/QF62bQkA4M/1W6n7ZnWH27HFw8MdT8/UuLu74+npycWLQU6xu3VLANei3EuE8wPwSpMGRwcq0X3+2bJn5r0WTRg3ckrkZ2PP+cUbDbd/JAGSvAME8gBbgJbAm8BCYIqIRJ2nzQaWAg2AY8AvIpLL5vxXwLfAOKAxcBcYFE17C4AWQH+zvQBgqYgUi1LvXeANoC3wdgLvDYDz1+9wOOg6L2fP8Ej54v3nqGBOcy/duke2tKkjz2VNm5pLt+4lqL2cubPz0suF+Ofv/ZFlJcu+xuXgq5w+eS5BNu1RoEBeypQtwcq181iybAbFXnvZ6W0AHDl8nFp1qgLwZv2a5MiZ3Wm2L1wIYsSI8Rw9uo1TpwK4ceMma9ducpr96OjWoyP7D2+iydtv0b+vc6al8PDz3/P3fvIVyEPJssVZ9Md05iydyCvFizitHcJC7R9JgCTvAFX1F1UdqKrLgfXAD8AU4JMoVYer6k+qugrDgbkBdQFExB34Bhinqt+r6ipVbQfstzUgIlWBOkATVR1r1msFbAW+i6Z7dVV1qaouiq7vIvKpiOwUkZ2TNu6N9v7uPAjl6yV/07lKEbxTPZwqTdh2DHcRahfJaff9iS9pvDwZM3UIfb4byq1bD6ezbzasyW8Ojv5iwt3DnYwZ01OralN6dh/ExKkjXNJOh/bf0aLlO/yxYQHe3l48CHHeLmSGDOmoW7cGL75Ygfz5S+Hl5UmzZg2cZj86+vYaRtHCFZk/dymffNbcKTYffv5DuHXrNu4e7qTPkJ6GNT/ghx7D+WlidGOCBBIebv9IAiR5BygiGUXkRxE5A4SYx6fAC1Gqror4QVWvAJeAiBFgbiAbxgjRlqivqwGBwBYR8Yg4gLVAiSh116qq3SGYqo5X1RKqWqJlpVceOx8SFk6nJX9T+8WcVH3h4Whlyf5zbDpxif51iyNiLJNk8U5N4M2HzQXdvEcW79SP2bSHh4cHo6cMYcmC5axati6y3N3dnZp1qrDs11V2rk44Fy8E8ftvqwHYvWsf4eHh+PhkdHo7x4+dolnDVtSs3JhfFyznzKmzTrNdpUoFTp8+x+XLVwkNDWXx4pWUKfO60+zbY/7cJbxVr6bDdjw8PBgzZQhLF6zgD/PzD7wQxB/L1gKwd/cBwsPDyeSkz0bDQ+wesSEiuUVkvYgcFJEDIvKlWd5TRM6by2F7bJeoRKSriBwXkSMiEuubluQdIDAVY4o5GKgBlAQmA1F/+6MuiD2wqZPN/D84Sp2or33NuiFRjp4YTtQWhxaAVJVeK/eSz8eb5iXzR5ZvOXWJaTtOMqJhCTxTuEeWv/F8Vv44fIEHoWGc/+8OZ6/dpmiUKXNsDBj5PSeOnmLy2FmPlJd/ozQnjp8m8GLCdxntsXzZGipULA0Y63QpU6TgyhUnrjWZ+PpmAkBE6NC5NdOnzHWa7XPnLlCqVHE8PY2vlJ9feY4cOe40+1HJb+7MA/jXrcbRoycdtjlgZA9OHD3FpLEzI8tWr9hAmQolAchX4DlSpEzBVWd9No6PAEOBTqpaBCgDtBORiDn6cFUtZh7LAcxzzYCXgFrAGHP2FyNJOgxGRFJjTGPbqeo4m/L4Ou5A8/+ocSNRX18FzgP142DToVXpPeev8fvB8xT0TUvTqcZa0ueVCjFo7QEehIXTet4OAF7JkYFuNV7med+0VC+UnYaTN+LuJnStVvSRHeDYeL10MRq8XZfDB47x23oj/GFov1FsWLOFug1qOG36+/OkoZSvUIpMPhn55+CfDPrhJ2bPWMjI0f3ZuO03QkJCaN+mi8PtjJ04hHIVSpHJJwO7Dqxn8IBReHml4aNW7wKw/LfVzJkZ7cpEgggI2MOvvy5n27ZlhIaG8c8/B5g0abZTbE+cMpzyFUvj45OR/Uc2M6DfSKrXfIOCBfMTHh7OubMX6Phld4faKFG6GA3frsvhA0f5ff0vAAzpN4r5sxYz8MeerNg0n5CQEDq3j3mnOd44GAitqheBi+bPN0XkEGBvTage8Iuq3gdOichxoBSwLaYLknQYjIikxxjZfayqU8yytMBpQFXVV0RaYKwJplXVWzbXngYWqOrX5l+Bf4FfVbWtTZ3lgD+QT1VPi0gNYDlQVFUP2+lXpO243ouVDit+WOmw4kdSTId1b8d8u995z9JNP8NYzopgvKqOj66uGamxESgKdMRY578B7MQYJV4TkVHAdlWdaV4zCVihqjHGKiXpEaCqXheRAOB7EbkBhANdgOtAunjYCRORwcBgEQnG2FV+C4jYjowYj68G/gBWi8hA4IDZTjEgtap2dcJtWVg8G8Sy02s6u2gdni0i4o0R/fGVqt4QkbFAH4xZWB9gKPBxQrqYHNYA3wVOAtOBkRhvxPQE2BmOsYPc1rSRESPUBcw4PjWGww0x1hi/wnCGPwNlgc0JvgMLi2eR0FD7RxwQkRQYv6+zIqItVDVIVcNUNRyYgDHNBWP5ynatPpdZFiNJegQIoKrHgarRnOppnp+KsVES9bq8UV4r0M08ABCRicBZVf3Ppt59oId5xNSnvDGds7CwMFANc+h6MUIgJgGHVHWYTXl2c30QjLjfiHC2pcBsERkG5AAKAjvstZHkHaCzEJGiGLvJWzGmvP7AR8D/nmS/LCyeWhwPdi4PNAf2icges+xb4B3zwQTF2A/4DEBVD4jIPOAgxg5yO43FCz8zDhC4DVQA2gNewBkM5zf0SXbKwuKpxcFgZ1XdDES36bLczjX9gH5xbeOZcYCqegrwe9L9sLB4Zkgij7vZ45lxgBYWFolMEkl4YA/LASYS/j2jfxbYmewfWsPlbeT9YrHL2wC4fCfeCXaSLCndXf9rFubghoNLiONO75PEcoAWFhauwZoCW1hYPLNYU2ALC4tnFmsEaGFh8cySRHL+2cNygBYWFq4hLAluzETBcoAWFhauIRmMAJNUMgQRKWqKFFU2X6uItH/C3YoWEfkmop8WFhbRkAw0QZL6CLAscCrWWk+Gb4BRwAZnGHNzc+Pn5WO4HHiZri268ePC4aTx9gQgg08GDu85QrdWMeZniJbAG3fotvRvrt6+DwKNiuXlvVLPM2ztPjYeCySFuxu5MnrRq+5rpEudkn0XrtJnecQjl0rrii9SpVCOeLU5YlS/SF3gN8oacpUvvVyYwcN7kipVKkLDwujSsRe7d+2Ll92YSJUqFRvWLSRlqlR4eLizaNEyevV2/tONuXLlYOrkkWTJ6ouqMnHiLH4aNckptkeNGUAt/yoEB1+hbCl/APr07UKt2lV48CCEU6fO0q71N1y/fjPBbWTPkZXhY/rhm8XQBZ49bSFTxj/MDP5J2w/o1udrihWsxLWrcVcbtEsymAInqRFgVFR1u6o6R3swidOoZQPOHH+oYfFFow60qtmaVjVbc2DXITauiH82Lnc3NzpVe5lFn1VjxodvMHfXSU4E36BMviws+LQq8z+pSp5M3kzeehSA5zOnY/bHlZnXqgqjm5Wnz4rdhMZzGvPL7F9p1uhRvarve3dmyIDRVK3YgEH9fqR7787xvpeYuH//PtVqNOX1EtV5vUQNataoTOlSrznNfgShoaF0/qYXr7zqR/kKb9KmTQtefLGgU2zPnrWQRvU/eqRs/brNlCnpT/kydThx7BQdO7VxqI2wsDD6fj+UauUaUL/m+3zQ8m0KFjKkGLLnyEpFv7L8e+6CQ208hiWKZB8RaWvq794Wkd+A7FHOPzIFFpEKIrLJ1PW9YQqiNLE5n0pExorIfyJyRUQGi8hXIqI2dSJ0hL2jtHVaRIbEpS0zI7QP0MO0FTltTwiZs/tSpmppls1+/BnvNN5peK1cMTb/sSX+dr1T82I2QzfEK1UK8vukNbSH82d9qD2cMxNBNw1Nd88UHpHlD0LDkGifQ7ePodf7qC6wqpI2nfF2p0uXlqBA52qP3L5tZHZOkcIDjxQpHNbQjY7AwEvs3mNkXbp16zaHDx8jZ45ssVwVN6LTBV63bjNh5ggqIGAPOXI61taloMvs33sIMHWBjz3Uhf6+3zf80HO48983awocMyJSDxiNodO7GENjd7Kd+umA34ElQG+MLBEvA7bKQIMwUmV/CxzCSHfVLAF9i62tBhgSnQuAiWbZwfi2E0H7nm35ud8E0nineexchZrl2bVlN3duOZa+/fx/tw3t4RyPKn4t/ucMNW2kN/edv0qPZbu4eP0O/d4qEekQHaF7l/78smgiPfp8g5ubG3VrRJV0dgw3Nzd2/LWS5wvkZey4qewI2O1U+1HJkycXxV4tyl87XNtOBO83b8yihcucZi9X7hy89HJh9vy9j+r+lQm8eIlDB446zX4EGp505TYieJJrgN8BK1U1Ymz/h4hkBlrFUP8FID3QXlUjFkMidRxFxAdDX+B7VR1ulv1BFO3fOGK3LVXdLSKhwL+quj0mIyLyqdknCmYoTA6vx/VcylYtzbXL/3F03zGKlX31sfNV6/uxbM6KBNzCQ+48COXrRTvoXO3lR7WHtxzB3U2o/dLDJLov58zEok+rcfLyDbr/tovyBbKSysOusFastGj5Dt9/O4BlS1fxVoNaDB/Vlyb1EpTBPFrCw8MpUbIG6dOnY+H8Sbz0UiEOHDjiNPu2eHmlYd7cCXT8ugc3b96K/QIH+bpzW0LDwpg3d4lT7KXx8mTc1GH0/m4QoaFhtOvwCc0bfeYU24+RREZ59ngiU2BTa/c1jBGWLfZkvE4AtzAyvtYTkaiakC9jyGBGav2aWaB/S0AXY2srTtjqAkfn/ACKlixK+Rpl+WXbTL4f/R3Fyxfjux8N1bT0GdNRuFhhtq+N0cfGSkhYOJ0W/kXtl3JRtfDDPizZe4ZNxy/Sv16JSO1hW/L7piNNSneOBzuelKDpO/VZttT4+7H015UUf+1xjWRncP36DTb8uYWaNSq7xL6Hhwfz505gzpxfWbzYsT9KceHd9xpRs5Yfn3zcwSn2PDw8GDd1GIsXLGPl72vJkzc3uZ/LyYqN89m8ewXZc2Rl2fq5ZM7i45T2CFf7RxLgSa0B+gLuGOLltsS4OKSq14DqQApgHhAsIstEJEJUN67av7ESh7acxoQBk2hS8h2alX2f3u36sXvLHvp9MQCAN+pUYtua7Ty4nzB5QVWl17Jd5PNNS/PSDxfst5wIYtq2Y4xoXBbPFA8nAef/ux256XHh+h1OX7lFjvSPT8vjS2DgJcpVMGQbKr5RhpMnzzhsMwJf30ykT2/oY6VOnZpqVStx5MgJp9m3ZcL4oRw6fJwRI2PV8XGYqtUq8WWHT2j29mfcvXvPKTYH/diL40dPMXHsDACOHDrG64UrU6G4PxWK+3PxQhB1/N4m+NIVp7TnDE0QV/OkpsCXgTAgS5TyqK8fwZxu1hIRT6AaMAyYjSGabKv9e9XmsqjavxHfppRRyh9ZHIulrUShSj0/Zo/+JcHX7/n3Cr/vP0fBzOloOnEdAJ9XLsKg1Xt5EBpO6znGxsorOTPSzb84u89dYfK2o3i4ueEm0LXmq2RMkypebY6bNJRyFUqSyScjuw9uYPAPP9Hpi+70HfgdHu7u3L9/n6+/dJ72bPbsWZk8aQTu7m64ubmxYMFvLFu+xmn2IyhfriTN32/M3n0H2RlgjGa7dx/AipXrHLY9acoIKpi6wAePbOaHfiPp2KkNKVOlZPHSaQDsDNhDBwe0gUuULk6jt9/k0IGjLN8wD4DBfX9k/RoXan0lgzCYJ6YLbMpdXlZVf5uyCRhrgH6qusHcvf1cVUfFYKMr0FVV05lrgP8CPVR1kHleMNYAi6iqmGUVgE1ABVXdYpaVBrYDQ2PS+rVty3x9AZiuqnFS+a6cq5rL3+gV/Uq4uolEywd45W7CY96SGl4pU7u8jQypvFzeBsCZK3vjHBpwZ0gru9/5NF9PjH+YgZN5kpsg/YFFpsbnrxi7wLViqiwidTC0PxcDZzEU4j8D1gGo6hXTgfYSkRAe7gKnwxBPiWAHhlTejyLSHciEEdQcudgVW1smh4E6IrISY73wiM2GiYWFRTIYAT6xOEBV/RX4HHgTw9EUB1raueQ4hiPrj7EjOwhYyaOCyN9gSGT2BOYAQRiyepHOTVUfYISxhGOEsXQC2gDX4tlWZwyhpWVAAPB6nG7cwuIZQcPD7R5JgSf6KJw5tY06vRWb87Y/HwEax2LvHoYziwybF5E1wD9R6gUAJaNcnjeebf1NIq4HWlgkOxwcAYpIbmA6kBVjQDJeVUeKSCZgLsbv7GmgqapeM5e8RgK1gTtAC1XdZa+NpP4scLwQET+gNLALYwf3bQxR9Sb2rrOwsHABjoe6hAKdVHWXiKQF/haR1RgPO6xV1QEi0gXogiFx648hhl4Qww+MNf+PkafKAWKsxdUHumLEBB7D+Cuw4In2ysLiWSTUsRGgql4ELpo/3xSRQxjr8fWAyma1aRgJSf5nlk8343+3i0gGEclu2omWp8oBmlNba1pqYZEUiGUKbPuklMl4VY02yFJE8mLsE/wFZLVxaoEYU2QwnOM5m8v+NcueDQeYlNl51TXBubbkbO+8AOOYuLh9nMvbAMhW2kWPZ9kQlkiiPYkRapYUw4Zi2+gwnV2sUeVm4pKFwFeqesP2ySVVVdtkJ/HFcoAWFhauIdTxPzAikgLD+c1S1YhHZYMiprYikp2HT5CdB3LbXJ7LLIuRJJ0P0MLCIhmj4faPWDB3dScBh1R1mM2ppcCH5s8f8jCnwFLgAzEoA1y3t/4H1gjQwsLCRajjI8DyQHNgn4hEpCr/FhgAzBORlsAZoKl5bjlGCMxxjDCYR7PMRoPlAC0sLFyDg2EwqroZYszKWzWa+gq0i08blgO0sLBwDQ6GwSQGlgO0sLBwCRqWNB53s8dTvQkiIt+LyHkRCReRqU+6PxYWzxRWQtQnh4iUAHphPGtcHujzZHsUM2PGDeTU6QB2BKyMLMuYMT1Lf5vBnr3rWPrbDDJkSOdwOz+N+YEjJ7ez5a/H9SXaff4xV28eI5NPxmiutE/g5au0/H449b/oTYMv+zDzdyNpzphffqdaq6406difJh37s+lvQ50gJCSU7j9Np+FXfWncoR8B++OvR/HTmB84euovtu54KCT1bfev2Lz9dzZuXcrCJVPJls1ueslYGT12ICdO72B7wMPsz/Ub+PNXwEr+u3mc4sVfdsh+YraTWN8xWzQ03O6RFHhqHSBQ2Px/tKpuU1WXRSKLSAoRSbBwxqwZC6lfv8UjZR07tWHDhi0Ue6UKGzZscVgWEWD2rEU0afC4FkfOnNnwq1KBc2fthkzFiLubO50+bMTiH79n5oDOzF2xkRPnjOiD9+tWYf6wb5k/7Fsqvl4UgIVrjESsi0Z04+ceXzBk6kLC45kdZM6sRTSu/+i9/DRiIhXK1KVSubf4Y+U6vunaPoar48asmQtoGEWu8uDBo7z3bhu2bN7hkO3EbiexvmOPYI0AnwzmdHeG+fJ6hGyliGQSkfEiEiQi90Rkq5kM1fbaTiISICLXzXq/icjzUepsEJEFIvKpiJzAyDIdPwVxG7Zs2fGYGHWdutWZNWshALNmLaTumzUSaj6SbVsCuBZFshKg34Dv6NF9UIKfWMicKT1FCjwHgJdnavLlysalKzGLa584d5FSLxcCwCdDWtJ6peHAibMx1o+O6KQkbUWKvNKkcfgJjK1bAh77XI4eOcHxY6ccsvsk2kms75gtGqp2j6TA07oJ0gfjmcBuQBXgLkaC1PUY0padMaLH2wBrRKSgqkak1M+FMW0+g5FMtTWw1axj6z3KAwUwHsK+AzzuWRwgSxZfggINOZOgwGCyZPF1pvlI/OtU5eKFIA7sP+wUe+cvXeHwqXO8/EJedh8+wS8r/uS3P//ipQJ5+LpFI9J5p6FQ3lxsCNiLf8USBF6+xqETZwm8fI2XC+Z1uP1uPTrS7J0G3Lhxkzdrv+/4DT3FuPw7lkRGefaIcQQoIunsHYnZyfhiTncjprwBpr5HY6AoUFNVp6vqSqARhiPsZHNtB1WdpqobMJKdNgI8MTJN2JIBqKWqC1R1uao+Jp9mjhB3isjOkFDHntV0xfOknp6p6dipDf37jXCKvTt379Fx0Hi++bgx3mk8ebtWJZaN6c38od/imzEdQ6Yao436VcuS1Scj73QeyKDJC3i1cH7c3ZyTHb1vr2EULVyR+XOX8slnzZ1i81nB2d+x5DACtDcFPoChp3HA5thv839yoxrwN3BKRDxMaU6AP4FIMQ0RKSMiq0XkCkY+sjuAN4ZWsC1/q2qQvQZtZTFTeKSNV2cvXbpM1myGnlPWbJkJDnaSUpcNefM9x3N5c7Fp62/s2b+eHDmzsWHT4gSNBEJCw+g4eAJ1KpWiWpniAPhkSBcpVtSoegX2HTsNgIe7O9983Jj5w77lx66tuXn7DnlyZLVjPf7Mn7uEt+rVdKrNpw1Xf8eStQNU1dyq+pz5f+4or59LzE46CV+MVFkhUY6PMB+gFpHnMFLgC4YGSHmMzNGXMPIL2mLX+TnK8mVreO+9RgC8914jlv2+2ultHDp4lEL5y1CsqB/Fivpx4XwglSvW59Kly/Gyo6r0GD2DfDmz8cFbDwP0g68+XBVY99ceCj5nLJPevf+AO/fuA7BtzyHc3d0pkDu7w/eTv0CeyJ/961bj6NGTDtt8mnH5dyw8liMJEKc1QBFpBuRX1f4ikgsjH9ffru2a07kK7MQmXb4N983/awFpgHqqehsiRdwzRXON0/6ETZk6koqVyuDjk5Ejx7bSr+8Ihg0dy/QZo/jgw6acO3ueD5o7tqMJMGHycMpXLIWPT0b2H97EgP4jmTnd8Vyxuw+f4Pc/d1AwTw6adOwPwBfvvcWKzTs5fOpfRCBHZh++b/0uAFev36R1759wEyGLTwb6f/GhPfPRMnHKcMqbUpL7j2xmQL+RVK/5BgUL5ic8PJxzZy/Q0QEZSYDJU0dGylUeOrqF/n1Hcu3afwwe2gNf30zMXzSJfXsP0qBeiyTfTmJ9x2zRpCH9a5dYZTFFZBRGevlKqvqimY//D1WNqqmRpBCRFsAUIK2q3jKTLw4ECqlqtALsIvIlMNi85r5Z9i4wCxvJTBHZgCHpaVc3xBbvNPlcPuZP6e76PS0rH2DSJDyR5G1v3TkV58Xay/5v2O2U74o/k4UsZjlVfU1EdgOo6lURiSoqnhyYjrGju0FEhgAnAR+gFBCoqsMxZC/dgSkiMgl4CfgaiDmmw8LCIlqSwwgwLnGAISLihjnlMwXIk92fTlMxzg9YjfGEyCoMBamCGFrBqOo+DMGV0sDvwLsYgkpODXGxsHgWcDAdYKIQlxHgaIyMrJlFpBdG7q1eLu2VE1DVqRgawbZl14EvzSOm62bwMIg6grxR6lR2QhctLJ5qNOyJz3BjJVYHqKrTReRvjDASgCaqmhzDYCwsLBKR8NCnwAGauGOEjChP6eNzFhYEwfc4AAAgAElEQVQWziWpTHPtEaszE5HvgDkYz7rmAmaLSFdXd8zCwiJ5Ex4mdo+kQFxGgB8AxVX1DoCI9AN2Az+4smNPG9m9ogsldC4Xbjv/aZGoZC71icvbAAgcHvXJQ+eTrv08l7cBkNrD9UETJTM9H3ulREbDk4aTs0dcHODFKPU8sCM0bGFhYQEkmVGePWJ0gCIyHGPN7ypwQET+MF/XAAISp3sWFhbJleQ+AozY6T2AkRUlgu2u646FhcXTgjNGgCIyGagLXFLVomZZT+ATINis9q2qLjfPdQVaAmHAF6r6hz37MTpAVZ3kcO8tLCyeWZw0BZ6KkZ9zepTy4ao6xLZARIoAzTCe4MqBkevzBVWNUZ4u1jVAESkA9AOKYJMRRVWjpoeysLCwiCRcHXeAqrpRRPLGsXo94BfzOf5TInIc41HXbTFdEJeYvqkYSQUE8AfmAXPj2CELC4tnlPAwN7uHbcJg8/g0Hubbi8heEZksIhFKXjkxMsFH8K9ZFiNxcYBpIubRqnpCVbthOMKnFhHpKSKXbV5XNnVFItYgUpp1ij25XlpYJG1UYzseJgw2j/FxND0WQ46iGEZEytCE9jEuDvC+mQzhhIi0FpE3gfilN05+TATspRNOCfTA+AAcJluOrMz49WdWbJ7P8k3z+PDTdwB4segLzF8xlaXrZ7No9QxeKf6SM5oDoG3bjwgI+IOAnato1+5xpbiE4iqJx8Abd/lk3nYaTtlIo6kbmb3LEAxafeQijaZu5LWhyzkQ+DBpT0hYOD1W/kOTaRtpOn0TO885FiOZK1cO1qyaz95/1vPPnnV83r6lQ/ZsSUzJSjc3N8avHEv/qYZKbPFyxfh5xRgmrxlPl+GdcXN33oNeYWFudo+EoqpBqhqmquHABIxpLsB5zOTGJrnMshiJSy86AF7AFxgZkj8BnPcbkwRR1X8TM+FrWFgYP/QYjn+FJjSp1YL3Pm7C8y/k45vvv+SnIeN5y+9dRg4cxzc9vnBKe0WKvMBHHzWjUqV6lCntj79/FfLnzxP7hXHAVRKP7m5CxzdeZNFHlZj+bjnm7jnDiSs3KeCblqFvvcZruR4NNF+011CZm/9hJcY1LsWwDYccypkXGhpK52968cqrfpSv8CZt2rTgxRcLJtieLYkpWdmoZQPOHjfeGxGhy4jO9Gnbj4+rfUrQ+UvUauI8ZThVsXskFBGxTR/egIcRK0uBZiKSSkTyYZPpKSZidYCq+peq3lTVs6raXFXfUtUtCe28qxGR9iJyTkRui8hiEalqI4uZ1/y5bpRrporITpvXj0yBoyFC4WiKaU/jsVD7GMFBlzm411Blu337DieOniJr9iwoindaLwDSpvXmUmD8UtXHRKFCzxOwcw93794jLCyMTZv/ol69Wk6x7SqJx8zeqXkxa3oAvFJ6kC+TN8E375Hfx5u8mbwfq3/yyi1KPmdom2RKk4q0qVNwMDDhWc0CAy+xe4/xe3br1m0OHz5GzhzZEmzPlsSSrPTN7kuZqqVZNtsYnafLmI6QB6H8e8oYJO3c+DcVa1d0uJ0IwsLF7hEXRGQOxiZGIRH5V0RaAoNEZJ+I7MVIcdcBQFUPYOxRHARWAu3s7QCD/UDoX7GT9l1VG8bpDhIREWkA/ASMAZYAFQBXhPNUwUie2peHMZJOeTomZ+7sFHm5MP/8vZ9+3w1h8rzRdOn5FeLmxtu1P4rdQBw4ePAIPXp+TaZMGbh79x41a/qxa9dep9hODC5cv8ORSzcomj1DjHVeyJKOP08EUatwdoJu3uNg0HUCb961e01cyZMnF8VeLcpfO3Y7bCsmXCFZ2b5nG37uNwFPb08Arl+9jruHOy+88gJH9x7ljTqVyJIjs8PtRBDuhEBoVX0nmuIYf6dVtR9G1EqcsBcGMyquRpIQ3wLLVbWd+XqViPgSvQ6II0Q8CXPClNyMFnNX61OAzN7PkT61/S9xGi9PRk0ZTL9uQ7h16zYdPmpL/+5D+eP3dfjXq07/Ed/TonFbhzt/5MgJhg0bx9LfZnD79h327j1IeFgySN0B3HkQytdLd/G1XxG8U6WIsV69ork4deUW783cQvZ0nryaIyPu4vgvpJdXGubNnUDHr3s8IsTuahyVrCxTtTT/Xf6Po/uO8WrZVyLL+7TtR7serUmRKgU7//zbqd8DZ4TBuBp7gdBrE7MjjmKKFxUH2kU5tRTnO8A4Ye5qjQcomPl1u99gDw8PRk0ZzNIFK1i1bD0ADd6uS59vBwOwYslq+g/v5rS+TZ82j+nTjGQAPXt15vz5pP94d0hYOF8v3YX/izmoWtD+9NPDzY2v/YpEvv5w9laey+TlUPseHh7MnzuBOXN+ZfHiFbFf4AARkpVBgcFOkawsWvIlytUoS+kqpUiZKiVp0qbh2x//R/8vBvJlo44AlKj0Ornz53JG9wEIC0/6mfOSfg/jji9G3sLgKOVRXydJ+o/ozomjp5gyblZk2aXAYEqVex2AshVLcvrkuZgujzeZM/sAxu7mW2/VYt7cpU6z7QpUlV6r9pHPx5vmJfLHWv9uSBh3QwxRiu2ng3F3Ewr4OBa8MGH8UA4dPs6IkXGN1kg4zpasnDhgMk1Lvss7ZZvTu10/dm/ZQ/8vBpLBx1gSSJEyBe+0fZulM353uO8RaCxHUsD1MmKJx2WM5/+iLmLYvr5n/h81P1FGniCvly5Gg7frcvjAMZaunw3A0H6j+a5jX7r1+xp3d3ce3H9At459ndbmrNljyZQpI6EhoXTs0J3r1284xa6rJB73nL/GsoPnKeiblrenbwKgfYVChISFM3DdQa7dfcAXv+6kUOZ0jGlcimt37tN2YQBuYmyg9K3tWMRS+XIlaf5+Y/buO8jOgFUAdO8+gBUr1zlkF56MZGUEb7dpQtmqZRA3Yen039i9dY/TbCeHEWCsspiRFUVSRUhFJlVEJAAIVtXaNmVjMKbAfsBGDCfYy1wsRUS8gVPAGVUtYZb1BNqrqq/5ujKwHnhZVfebqnj3gTaqGiedyNimwM4gMfIBukvifKmtfIDxI7HyAa7/d3WcF/Y2ZWts9ztfMXDBE18kjMuzwKUwdl3SA8+JyKtAK1X93NWdSwA/AAtNLeOlGHGLdcxz4aoaLiJLgA4icgZD7rITcDc+jajqAxE5BTQVkf0YTnWvqj5w1o1YWCR3wpLBJkhc/pz/iJGO5gqAqv6DMZpKcqjqIoyA7frAYqAkhq4vQMQcrz2wBSNUZjRGuv+EzGNaY6w7rsHYFc6R4I5bWDyFhOFm90gKxGUN0E1Vz8ijIQR2gwufJKr6E0YsIAAi0g1jhHbEPB+EkTXClkdWtVW1J9DT5vUGjGQQtnVWAa9gYWERLckhsCouDvCcOQ1WEXEHPgeOurZbCUNEMgNdMdbr7gAVgf8Bk1Q1XtNcCwsLxwgj6U+B4+IA22BMg58DgjCmfE8kri4OPAAKYwg5pcd4OmMk0P1JdsrC4lnkqRgBquoljCyrSR5VvQ7UjrWihYWFywlzwpM3riYuu8ATiCZuUVXjk7zwmefMjSCXt+FItpO4khghHQDpEyFE5e6FTS5vAyBrPnuZ1ZzDwZvOC5J3FuFPyRR4jc3PqTHSzyS9d9vCwiJJkWR3Sm2IyxT4kfT3IjID2OyyHllYWDwVPBVT4GjIB2R1dkcsLCyeLp6KTRARucbDNUA3DKH0Lq7slIWFRfInNLmPAMWIfn6Vh3n1w9XRxGQWFhbPBMnBUdh1gKqqIrI8QpHdwsLCIq6EJv0BYJweyNsjIsVd3hMLC4unimSdD1BEPFQ1FCPLcoCInABuYzwTq6r6WiL10SWIyFSgaEQKLAsLC+eSHEaA9qbAO4DXgLcSqS+JTR/A80l3IjqOHtnGrVu3CQsLIzQ0lLLl6sR+UTzIlSsHUyePJEtWX1SViRNn8dMo52hHjRk3EP9aVQgOvkKpkobSXMaM6Zk2fRTP5cnJ2TPn+aB5O/77zzkJWCNwc3Pjr+0rOH8+kPoNPkywnYtBwXzbZwhXrl1DEBrX86d50/p06v4Dp8/+C8DNW7dI6+3NwmmjAThy/BS9B/3Irdt3cHNz45eJI0mVKu4B4z+N+YEatfy4HHyF8qUf/azbff4xffp35fm8pbh65VqC72vEqH5Ur1WZy8FXeKOs8Ss9fsowCjyfD4B06dNx4/oNqlZskOA2ouKMXWARmYyRjepSxFKciGQC5gJ5gdNAU1W9Zu5ZjMR4GuwO0EJVd9mzb88BCoCqnnDwHpIkSf2+qtdowhUHvvD2iNC43b1nP97eXuz4ayVr1m7k0KFjDtueNWMhP4+bzoQJQyPLIjRuhw0dR8dOrenYqQ3fdx/ocFu2fPF5Kw4dPka6tI6lvfdwd6fz559QpNDz3L59h6Ytv6BcyeIM7dM1ss7gnybg7ZUGgNDQMLr0HsQP3TtTuGB+/rt+Aw8P93i1OXvWIib8PIOx4wc/Up4zZzb8qlTg3Fm72t5x4pfZvzJpwixGjRsQWfbpRx0jf+7Z93/cuHEzuksTTJhzRoBTMQTaptuUdQHWquoAEelivv4f4I+hBVwQKA2MNf+PEXtrgJlFpGNMR8LvJ2kQjRZwMRFZKyJ3ROSaiMwSkaw253eY0+bo7LhOH9EFPA0at7bkzJkdf/+qTJ48x2FbmX0zUaSQkV3ZyysN+fPkJshGkEhVWbluI7WrVwZg646/eaFAPgoXNHRKMqRPh7t7/Bzgti0BXLv2uGZxvwHf0aP7IIcV4QC2b93Jf9G0EcFbDWrx64JlMZ5PCGGxHHFBVTdihN7ZUg+YZv48DSP/Z0T5dDXYDmSIIqL+GPYcoDvgDaSN4XhqMNNobQDSAO9ipPx6A1htpr8HIyt2YzOFfsR13kBjYLIz+6Moy5fNZvu25bRs+Z4zTT9GctW4tWXo0F507dqX8HDnht6evxjEoWMneOWlQpFlf/+zH5+MGcmTOycAZ86dR0T4tMN3NPmoPZNnzXdK2/51qnLxQhAH9h92ij17lClXguDgK5w6ecapdsPF/iEin4rITpsjrvkFsqpqhIxhIA8fzMjJo4/p/muWxYi9KfBFVe0dxw4ldzqZ/9dU1RsAInIM2A40wsgaPQcYBjQBppj1mwIpgNnRGbXVBXZ3z4Cbe9xkGf38GnLhQiCZM/uwYvkcjhw5zubNfyXoxuyRXDVubalduxrBly6za/c+KlUq6zS7d+7cpcN3ffnfF5/h7fXwc1u+egO1q78R+To0LIzdew/wy8SRpE6dilZfdKVIoecpUyLhgROenqnp2KkNDeu3cOQW4kyDxnWcPvoDCI3lvK1sbEIxQ/US/IWyNwJMBns4TqMUsCrC+QGo6l8YC6wVzNc3gAVAC5vrWgBLVTVaNSJVHa+qJVS1RFydH8CFC4EABAdfYcmSlZQs6ZiiWXQ8CY1bwCkat7aUK1eCunVrcOzodmbNHIOfX3mmTf3RIZshoaF89V1f6tTwo3rl8pHloaFhrPlzK7WqVoosy5rFl9dfLUrGDOnxTJ2aimVLcvCIY8vLefM9x3N5c7Fp62/s2b+eHDmzsWHTYqePnAHc3d2p82Z1lixa7nTbLgyDCYqY2pr/XzLLzwO5berl4uFDHNFizwFWdaSHyYzsGMleoxIEZLJ5PQmoKCL5RaQARsZpp05/06TxxNvbK/LnatUqceDAEWc2ASRvjVtbunUbQL78JSj4Qhnee78t69dv4cMWXyTYnqry/Q8jyJ8nNx82a/jIue07d5M/Ty6yZXmotFq+1OscO3mau/fuERoaxs49+yiQ77kEtw9w6OBRCuUvQ7GifhQr6seF84FUrlifS5cuO2Q3OipVLsuxo6e4eMH56dpCxf7hAEuBiK3+D4ElNuUfiEEZ4LrNVDlaYnSAqhp14fFp5iKQJZryrNgswJoLsscwRn4tgAvAKmd2JGvWzGxY/ys7A1axdcvvrFixllWrNjiziUiNWz+/cuwMWMXOgFX416riFNtTpo5k3YZFFHwhP0eObeWDD5sybOhYqlSpwJ696/DzK8+woWOd0pYr2L33AL+tXMtfu/6h0YftaPRhOzZu3QHAijV/4l+t8iP106dLywfNGtKs5Zc0btGOF194njfKlYpXmxMmD+ePtfN4vmA+9h/exPsfNHbW7UQybtJQlq2eQ4GC+dh9cAPvNjf+INVvVIdfFzpPDN0WZ4wARWQOsA0oJCL/ikhLYABQ3Vymqma+BlgOnASOAxOAtrHaf1Yf7bUNhBaRHzDS/OdW1Zvm+ZIYsZDvquocm+v+x8M3draqdiUOpEyVy+Vv9NOUEPV+qOsVRu88RQlRU7jFb+c5oQRdPxznsVufPO/Z/UJ2PzPriS+zJQ1tuifPMPP/P0Sknoi8BywC9gELo9SdhiGB+RwPN0MsLCyi4IwwGFeTkHyATxMKoKrBIuIHDMXY7X2AMZzuEFXsXFUDReQv8+ckqY5nYZEUCH/i47vYeZYdYFoeXd/bDcS6EGY+hvM6hsC6hYVFDIQlmZQHMfPMTYFFJKOI1AMqAztjqW57XVoRKY3xWM5NjJGihYVFDITHciQFnsUR4BvADGAdxpQ3rryOIbh+BvhAVe+4oG8WFk8NyWEE+Mw5QFVdTAIe5VPVDTxbweEWFg6RVEZ59njmHOCTonDG3LFXcpAzty7FXslBEivcwi0R9CQyPpc4sf7Bkz5weRv52rheRzm+WCNACwuLZxbLAVpYWDyzWFNgCwuLZxZrBGhhYfHMEm45QAsLi2cVawRoYWHxzJIc1gCT3ZMgIuItIioiLZ50XywsLGImDLV7JAWsEWASIGWqlExZPJaUKVPg7uHOmt/XM2bwRPqM7EaJssW5ecNIV9/9y74cOZBw5bZRYwZQy9+QrCxbyh+APn27UKt2FR48COHUqbO0a/0N168nXB1s5Oj+kRKPFcvUBeCbrp/T/MOmXL5sPHrdr/cw1qz6M8FtAIweO5Ba/n4EB1+hTEnjXuo38Kfrt19SqPDz+FVqwO7d+xxqw1USn4HXb9Pt17+4euseCDR6vQDvlSnEsFV72HjkPCnc3ciVyZte9UqTzjMly/aeZtqWh9ogx4L+Y85nNSmcPWOc2xw+qi/Va1bmcvBVKpczZDGLFC3EoGE98fJKw7lz52n7SWdu3bwdr3uxR1gySLWX7EaATyMP7j+gVaP2NKn6AU2rfkB5vzK88tpLAAzrPYqm1T6kabUPHXJ+ALNnLaRR/Y8eKVu/bjNlSvpTvkwdThw7RcdObRxq45dZi3i7YcvHyseNnoJfhXr4VajnsPMDmDVzAQ2j3MvBg0d57902bNm8w2H7YEh81o+iyxEh8VnslSps2LAlQe+Xu5sbnWoUY1H72sxoVZ25O45z4tJ1yuTPyoK2/sxv608en7RM3nwQgDqv5GVem1rMa1OLfg3LkDOjV7ycH8Dc2Yt5p/GjmkPDfuxDv17D8CtfjxW/r6HtF49/bo4Qjto9kgIudYAi8pKIrBSRqyJyW0QOiUg781wdEVktIpdE5IaIbBeRx/QSRaSRiBwVkbsishEoHE2d0yIyREQ6mFljr4nILyKSIUq9TCIyXkSCROSeiGw1ExzY1mkpIgfN9i6LyJ8i8pLN+a4icty8Psi8P4c1Je/euQuARwoPPDw8nCocFMHWLQFcu/aoZOW6dZsJCzOyswUE7CFHTsduZdvWndFKPDqbrVsCHpPfPHrkBMePnXJaG66S+Myc1pMXcxhKC16pUpA/czou3bxLueez4+Fu/Eq+ksuXoBt3H7t2xb4z1CyaJ95tGrKYj95L/gJ52bYlAIA/12+l7pvV423XHslhCuzqEeBvGLkP3wfeAn7i4XO4+czzzTGU17YCK0QkUoVGRF7DUID/B2ho1o/pmZ+mGDomn2KIJNcF+tvYSgWswUih3RlDSzQYWBPhwESkEjAOI1mCP/Cx2a/05vkPgG8xEqjWxMgifRyIu+JRDLi5uTFvzTQ27F/Oto072Lfb+Ov/eZfPWLBuBp17fUmKlCkcbcYu7zdvzGonjM6io+Wn7/Pn1qWMHN2f9BnSuaSNxMDZEp/nr93i8MVrvJzT55HyxbtPUuH5xyVtVx04i39RxzRHIjhy+Di16hiPA75ZvyY5ctqV0I03yWEE6LI1QBHxxXBy9VQ1YjFmbcR5VR1lU9cNI9PKS0BLYIt5qgtwFGiqxpBohanT2zeaJkOA+qoaatosAjTjYfr694GiwEuqesysswY4giGL2RlDHW6vqv5gY3epzc8R6nFjbMoW2XkPImUxc6bNR6Y0WWOqSnh4OE2rfUjadN4MnzKA5wvnZ2S/sVy+dIUUKVPQY0gXPm7fnJ+HOVWDKZKvO7clNCyMeXOXxF45nkyZOJshA0ejqnTt9hW9+3Xhy3bfOr2dJ4EjI/U790P4et4WOtcqjnfqh3/cJmw8gLubUPuVR0d6+/69QuoUHjyfNUNUUwmiQ/vv6DvwOzp0bsOqFet4EBLiFLsRJJVRnj1cOQK8iiFSPE5E3haRR0SHRCSXiEwTkfMYEqIhQA3gBZtqpTBkJ23fyZgczvoI52dyEMgiIhHfrGrA38ApEfEQkQjn/ydQwvx5D1BcRIaLSCUbUXRsztcWkV4iUkpE7GYGsJXFtOf8bLl54xYBW3ZR3q8Mly8Z8pEhD0JY/MvvFC1eJE424su77zWiZi0/Pvm4g0vsBwdfITw8HFVlxrR5vPb6Ky5pJzFwlsRnSFg4neZtofbLeaha5GGijCW7T7Lp6AX6NyyLREkIsXL/GWo5afQHcPzYKZo1bEXNyo35dcFyzpw66zTbYPxxsHckBVzmAFU1HMOhBWJIRwaKyCYRKW6O+JYC5YDvAT+gJLACSG1jJhsPNT8jiCnlyX9RXj/ASF+VynztC5TBcLS2x0eYWqKqusZ8XQnYAFwWkdEiEjHFnYwxBW4K/IWhT9o3NkcYGxl9MpA2nTcAqVKnomylkpw6fgbfLA+nRVVqvcHxw47pzUZH1WqV+LLDJzR7+zPu3r3ndPtgKN1FUOfN6hw+5NhmzpPEGRKfqkqvJTvI55uO5uUeLmlvOXaRaVsOM+KdinimfHRyFh6urDpwjloJWP+LCV9fYx1SROjQuTXTp8x1mm2AUNTukRRwaRiMqh4GGpmjsIrAQGAZRjbm4oC/qq6MqC8inlFMBPK4XGV08pVx4SpGBujotu3u2/R5GjBNRDJjrDsOx8gA3cV06sOB4SKSG3gP6Af8i7F2mCB8s/jQ98fvcXd3w81N+GPpOjau3sLEBT+R0ScjInB4/zH6fDMooU0AMGnKCCpULI2PT0YOHtnMD/1G0rFTG1KmSsnipdMA2Bmwhw5fdk9wG+MnD6N8hVJk8snI3kMbGdj/R8pXLE3Rlwujqpw7e55OX37v0H0ATJ46MvJeDh3dQv++I7l27T8GD+2Br28m5i+axL69B2lQr0WC25gydSQVK5XBxycjR45tpV/fEQwbOpbpM0bxwYdNOXf2PB80j78ywp6zl/l972kKZklP07HG1//zqq8waMUuHoSF0Xr6BgBeyeVDtzdLAvD3mUtkS5eGXJm8E3QvYycOoVyFUmTyycCuA+sZPGAUXl5p+KjVuwAs/201c2bGuJqTIMKcEAotIqcxfv/CgFBTxTETxt5AXuA0xhLZtQTZT8yhqIi8A8zGcIAbgCqqut48lwdDc3evqpYwy+ZjrAu+FDENFpHvMNYAP1LVqWbZaWCBqn5t01YLDNW2tKp6y1yPGwgUUtU4J84TkT+A+6r6VgznjwB/qKpdNe5XspV1+Rv9NOUDfBAWGnslB0kMGVF4uvIBBv53KM6JGv1z+9t9g1ecWxGrLfN3u4SqXrYpGwRcVdUBItIFyKiq/4trv2xx5SbIK8AQDE99EsiIsTv7D7AdY9Q0VES6Y+wM9wLORzEzEGOqOU9EJmFsYiQ0WGk60BrYICJDzD75YKwzBqrqcBHpBWTCnP5ijFLfwNiMQUR+xhhJbgeuY0zdC5r3ZWFhYYMLN0EiNH3AkKndQAJ/B105BQ4EgoDvMHR0/8PY6f2fqt4XkYbAaGABhjPsh3FTRSMMqOpOEWkG/AAsxpjCvo0hWB4vVPWeKX3ZG8PZZsVYT9zBw53eAKADxu5xWgz9j57ASPP8NuAT4DOMtcrjwCdmmn0LCwsbYgt1sY2SMBmvquOjVFNglYgo8LN5PquqXjTPB2L8LieIRJ0CP8tYU+D4YU2B40dSnAL75apu9w1e/+/quEyBc6rqeTOKZDXwOUZkSAabOtdUNX6PxphYj8JZWFi4BI3lX5xsqJ43/78E/IqxZBUkItkBzP8T/JffcoAWFhYuIUzV7hEbIuIlImkjfsYIq9uPsWT1oVntQyDB0ftWNhgLCwuXEOp4GExW4FczINwDmK2qK0UkAGNjtCXGOn3ThDZgOcBE4nbo/dgrOUhirOcm1rpZXd9XXd7GoqC/Xd4GQKaPp7q8jeD2r7m8jfji6PdRVU8Cj30RVPUKxnP/DmM5QAsLC5fgjEBoV2M5QAsLC5eQHCJMLAdoYWHhEsLUGgFaWFg8oySVnH/2sByghYWFS7BGgBYWFs8sycEBJotAaBHZICILnnQ/LCws4o4zngRxNdYIMAmQPUdWhozpjU9mH1SVudMXMXX8HH6cOIB8BYwEmOnSp+XG9Zu86fdOgttJDCnJn8b8ECmLWb50nUfOtfv8Y/r078rzeUtx9UqC0rdFkiZdGj4Z2I7cLzyHAuM7j+LYriPUaFGbGs39CQ8PZ/e6v5nzw3SH2omgYMH8zJw5OvJ1vnzP0bv3MEaNmuQU+xF8/nlLWrRohqpy4MBhPv20M/fvJyyGNFWT9rgXKYHeus7doV8C4JY9L6katYaUqdFrl7g3ezjcv2uey0OqRm0glSeocvfHzhCa8DT5yWEEaDnAJEBoWBj9vx/Ogb2H8fJOw5K1s9i8YTtftOoSWadr7w6R+sAJZfj/lpwAACAASURBVNbMBYz/eTo/TxgSWRYhJTnyx34O2Y5g9qxFTPh5BmPHD36kPGfObPhVqcC5s1EzniWMD3q04p8/dzOyzWDcU3iQyjMlRcoWpUT1UnTx70Dog1DS+aR3SlsAx46dpHRp44+Gm5sbJ0/uYOnSlbFcFT9y5MhK27YfUbx4Ve7du8/MmaNp0uRNZs5M2OQnZOc6QrYuJ1WzLyPLUjVpy/3fpxF+8gAeJauSsnJ9HvwxB9zcSPXOV9yfM5Lwi6chTVow1QITSmIFzTtCkpkC25PQtKnzrilJeUNEVohIrijnB4jIPhG5ZcpjzooqWWkjodlFRC6KyHURGSoGtUXkgIjcFJHFIpIxyrWxymomhOCgyxzYawhf3751h+NHT5E1+6OJr+vUq87vixz7hUsMKcltWwKilcXsN+A7enQf5JTYMM+0aShcuggbflkDQFhIKHdu3KHa+7VYOmYRoQ+MTDI3rrhGnrNKlfKcOnWWs05y5rZ4eLjj6Zkad3d3PD09uXgxKMG2wk8dRO88KnLv5puD8JMHAAg7ugePl8sC4P5CMcIvnjGcH8Cdm+DgCC5cw+weSYGkNAL8DTiEod52HygE2OonlsbIK9gJ8MTI0TceqG1TJwuGFOYFILNZd52IFDXT2UfQDCMP4EfA6xgZpt0wtEC6m/ZHYeQhbA2PyGpmwFCQu4SRXn+NiBRU1UBnvAk5c2fnpZcL8c/f+yPLSpZ9jcvBVzl98pwzmkh0/OtU5eKFIA7sP+wUe1lyZ+HmlRt8NuRz8hTJy6l9J5jecxLZ8uWgUKkiNO38HiH3Q5jVbyon9x53Spu2NGnyFnNdoJ534UIQI0aM5+jRbdy9e4+1azexdu0mp7YRHnQO95dKEXZgBx6vlkfSG7Kebr45QJXUrb5HvNIR+s9mQjY4lubSCoOJI7FJaJqkA+pE5P43R3bDRcRTVe8CqOrHNjbdMRKY/gtUADba2LoHNFHVMGCliNTDyDNWUFVPmde/ipFporV5TVxkNaPeV2TCR1+v3KRLbV9DNo2XJ2OmDqHPd0O5det2ZPmbDWvym4OjvyeFp2dqOnZqQ8P6LZxm083dnbxF8zO1xwRO7Dn2//bOPEyq4mrjvzMzDLLKkggBNSDKoqAgYVFQUREV+BRxiUtcgkHERDGKS9SIMcZgDIlEokmMYuIC4oJxC5IoCqgogqCALBIREJRNQQUUmPr+OOfaNU3PdPd0z3QPU+/z1DPTdevWcpf3nq2quGDUxZxy2WAKiwqp36g+Nw+6jjaHHcQV94zkyt6XJq8wDdSqVYsBA07gl7+8I6v1AjRq1JCBA/vRoUNvPv98C48+eg9nn30aEydOzlob2yeNo/agn1Dc9yx2LnoLonUXCwspbN2BrWOvgR1fU2fYrZSsXs6uDypuE64ONsB8UYHL3ULTMDtu45NF9rdllCEiJ5tauhndanO1HfK32gR4xcgvwgfAioj8vLzveltjprKtZin422ImI7+ioiL+PP73/OuJF5j6/Mvf5hcWFnLigON4fvLUcs/PV7RqvT/7t9qXGa8/y7wF02jRsjmvzHg6ow3FN32ykU1rN7J8nu4u9+YLr9Oq4wFsWruB2VNmAbB8/jJciaNBk+xuwn7iiX2YN28B69ZtSF44TRx3XG9WrFjFhg2b2LlzJ08/PYWePbtmtQ23/mO23/crto0dyc53ZlKyURUX9/lGdv1vkaq+O75h5+I5FLRsk1Fbu0pKyk35gLwgwPK20PSKJdr2EmwbTRHphq4Ttho4HzgC3Qbz2zJJ6iprW82IAJNuq5kJRo+9meVLP+SBex8pld/rmB4s/2AFn6yt/NWeKwPvL1pKuwN60rnjsXTueCxrPv6EPkcNyohANq//nI1rN/C9A1oA0LHXoXy8bDVvT32Lg4/oBEDz1i0oqlXEF5u2ZGUcEc4661QmTcq++guwatUaunfvQp06+rgee2wvlizJrgov9cwxJEJx3zPYMetFAHYufYeC5vtDrWIoKKDwgEMo+TQzk0sIg0kDZW2hGe/oKAenAeuBH3o7yGVvE9UUt9WsCLr26MxpPxzI4oXLeHbaBADG/GYcr/z3NQae1i9r6m9VbCV53wN/pNdR3WnatDELFs9g9O1jefif2Q/h/Meo+/jp2J9TVKuIdSs/5a8j72b7tq8ZdufPuGPqWHbu2MG9V/8pq23WrVuH448/ip/97BdZrTfC7NnzmDz5Bd5443l27tzF/PkLuf/+RytcX+1zr6KwzSFIvYbUvfE+vpk6Ealdh1pHqjd753uz2DnbLE3bvmLHjGepc4V673ctnsOuxZktF1YdVOC83RPE20KzKfAUsME5d4Z3vA+6yVIn59wCEfkjMNg5932vzA3oZkuXO+fGWd4Kdt9C80GgY7Qdp+VdRBa21YzQ5juHV/qFXr8tXojNPoqqaE+Qk5p0TF4oQ1TVeoC2oGeloqrWA6x/5+SUB/Odhm3LfeY3bFla+RcmCfJCAixvC03n3KYUH6D/AFeKyF2oR/lI1HGRLSTdVjOLbQUEVHvki52vPOQFAVLOFpqpVuCce0FErkO9uUNRD/BAYGk2OpjitpoBAQGG6hAGk7cq8J6GoAKnh6ACp4d8VIHr121d7jP/5dYPgwocEBCwZ6I6OEECAQYEBFQKqoN2GQgwICCgUlASJMCAgICaiuogAQYnSJ5CRC5xzv1tT2gnjCU/26mqseQz8mIqXEBCXLIHtRPGkp/tVNVY8haBAAMCAmosAgEGBATUWAQCzF9UlW2mKtoJY8nPdmq0/Q+CEyQgIKAGI0iAAQEBNRaBAAMCAmosAgEGBATUWAQCDKjRsM2z/N85X6EkoOoQCLCKISL7iMjJlVBvof2t9Bc4njSqW/0+nHO7RKSuiFxqv4NXsAYhEGAVwnaYex24XUSaZLHexsBgEenpnHMiUk9EficizbLVhteWRDvqichQb3e8bNXfCLhARI6w33VFZIKINM1mO3G4ErhBRFpURuVVQegikvBdDhJt+QgEWEUwohiAbud5HvBZ+WekhQbAL4BbRKQfusF8b2I752UFIlLgbTj1AHA30D6bbQC7gJ8AfxeRk4D3gIPQHfoqCy8BzYHjsl2xiBR6H4wLRaRjtknJ2iix//cRkW/3s7QPYnjPy0C4MFUAEakNTEKX6y9yzi2yBzMrL4JzbiW6DUBX4ElgLXBK3D7KGcEkv+glOxxdSWgwSrbZqL8OgHPuC+B4oD7wOLob36nOuaxsxOuTgSgKnHNvAg8CV2VTCrS6I/J7CN1O4RygTiW1cT9K5ktF5CURGQm67WyQBBMjEGAVwDn3Nbq/8DFAGxHJ2m7d9hIXOufmoNJTMfAV0M4vk2k7nuR3K/B3dCwLzYaWUf0i0g54V0S6G9FuB+pZqgO09spWuK2IxEWklog0tTFFNr+XgH2Ag61sxmqr98H4J7rV60XAOOfc1kzrTtDGePTDcQ9wOvABMExEHrFywbaZAIEAqwjOuYHopu+tgWtFpFGmUqARn/8SD0c3he8I3Cgiva3tbD78W1BiagFktO+yN/YSYBswEehieaehO+7VB8aJyNFGYBUei13vYuBp4EUR+T9U9cU59xi6gdav7PeuirbjQ0R6oJL5T5xz05xza0WkqYgMEpG+ItI6WR0ptNERNXmMBB5wzj2NfqRaAV/amKOyQRL04ZwLqRISUAvYF2iJ7i0c5U8AVqE2u70jwaoC9RfZ33qoajUYqG15fdAd614AenvnNAaap9GGeP8Xev9fCKwBpgOdM7hGDaN2gAOBGcDHQFevTEtgBTAPONrL/y7QtILtXo1+jL4B/gvcgqr0ZwJzgf4Z3BeJ+90N2IxKzIUosa+267cd3W71exk+a72AL4FD7XcHYIM9a3Ut78hcvQv5nHLegT0xoU6JV1GHx1bgOeAC7/ijwEqfBNOsv8BrZz66BegQoHb0AqIG/XXoHsknGRnPAW5LsY3CuN97x/0eZuN7uiIkiEqpa4CDvLy2RoKrgMO9/H2BD42cBqBq6rvAg+mOI+7Y8ehm9xuBmei+1JuBWyt43/2PxN6ohrUfapd9B3gNdX7dizp2fopKvkdk+LwdAuxEP3xNULvpY0B9Oz4YVY1b5PrdyLeU8w7saQm1Wc1DpaOzjZj+iqp5P/PKPWwv9e3Rg5pmO3sBs4Ap9gIUe8ciEuxnZLIalaLeBWqlULf/It8BvGhkegfQwzs23EjwX8Bhafa/N/BTvz0jjHZlkGALYLkR1Crg7WRjISYl10UdUHegH52O3rEi4DvAGOAJu09fAb3SHI9/zcYA44CO9rsPKmXehjp0onIdULX7qHTbiMtvAjxlz92XwENAPTv2XVQSfAKTuEPyrl2uO7CnJeCHRgqHekT0c3uxRlJarZxiD25FVK2e1k43r53ewAh72ZpbXnc0zu0q/6Uvp16/fxOBZcAoVO3dikp8J3llhqNS6LTohU9zHLVRB8SJ9rsAlQSnG9H56nADa2+IR5pFZfRdvHPet3EsA74AFgPX+QRq7RajjoqlwE1Rfgpj8NudZO3cBOwbV67A+/97wP3AQqBZCm34515i6XQv7ywb52pggOV1QlX9dUCHXL8b+Zhy3oE9LRnZfAQ0tt9nG/ldY78bUlqKitTZckmQ3VXS/lbvvqg69Svga3v51hs5NklWTznt/cJezh72+8fW3jpUve/rlb0KVcP3TbFu/2XuCsxG1eE+0fGySDDJNakbfxwl7NdQG2NdI55ngSXANYkIDpXK15GmZI7aYj8CegB1LC+yy/pkezYqka0jfcl5Eqqyr0ftfBO9Y+ehNs3P7N4ttOehwnbaPT3lvAN7WkJtY1/Y/xFJXW+/i4wgR+PZ1BK9hGXUvReeagb8x+p/H439+xGqzp1hL0jvCo5hb9RmdIX9/jmwA7Ul9rE2p2FSm5VplGLdEeH7ktsxwL+NEI6NyhkJvoqq7+XayVDv8Qw8hwLqIJoP/DLB+J6369be8oSY1NgfVbfbpnHNaqPS/Ggvrw0wHrUB3oGG2XQBnkHtwgenUK8vXXa0MXZDzR6XoSaB570y7VA76Q3AKaT4UaqpKecdqO7JXjLfwdESnb2wyIjiCu9YJ1Qa+XUF2hFUcnkPONnLu8Qe9PZe2RNQNa5LBuPqjIa5HIZKZ8OJSTN3oVLGdOD4CtRd28Zyg5fXBzUJJCLB94HJSer8EXBtdF3sb2Pgc+AWr1wt+9sCtfVdnaCu8agj4TtpjmsCSthHAdeiDo6Zdp0WA9dZubak8MFgdwm3m9UVec/rE5tV9Fyu34XqmHLegeqcjIAuMKL7ieUVogb3Zaia1QR1jPQE3kTnApdpg0vS3lFW5ysRCVp+JFXVRj2kM41MUrFflasSo+raSuAAL+9eVG2dB+xfgXEciDpWllD6A+GTYJ9obKgnNVXVfS90VscP7PcDwALiJEjUNvg/nxy9/FvwHDCpXjOgrxHgNrs2v/COzQQmpPNsef//zq7XRODJuHJ1jQQ/J8lHIqQE1znXHaiuyb6+f0QDTkssjbBjtVFnxDzUTrMUldymE5NAkhGPryIWEDP690DVs2lxJNgY+IOR7GyvnYQkiJK377m83F6036Le4+j8H9nYIlWxKSrp9MfzPCcZy272TVSdm2BjGeHl90HV4TV4KnYq18zKDEBV5unAAajKuQQNCznCG3t7I8BhCeooL3TGv2YXATei4SyHWV5Du0dtvbYaoyrvnegHMpm917eR3mvP0FPoh6gET3K2MnXRKXYlwKO5fjeqU8p5B6pjQiW6xagN7hLgYtSmVAKMtDKFqDo8FLUL9ieB5zJJO/WwEIk4EuyJTnWaCfSzvEPQxQn+RDneXtTTWS8u70ngU9QbuwKNWfuHjbMBaljfjEpT/0WN8O1SHEOkjhaxu5Oik5HgB5SWBI9BSfw5v4407s95aJjMTHSmx0C7X4tQB8ev0ZjIueWRXVljibtmc1F1eQ5we4JzOqGbD60nDZuinfsD4BHM647aFKOPxtVxZeuigdwp3ZeQ7LrlugPVMaHTzT7Gs7GhatqdeJJgGeemqsoJ6iwpITYzoYCYunsEGpYyAzjB8vYqrx1UOomCpiNiGoFKQj084vyjtXux/e6OSiLzUaLvlOb1qmUEcQverBg71gmYDHwCDPXyu5Cic8i/ZnH3aK5Hgp3ReMyNRo4TvfGmTIJW/jq7ZkcSk5TH2zU70yt3BSqpLyd9b+8Y9CMwFy9MBo0dfDgRCYaUfsp5B6pjQtXCrfFfW2B/1IZVEr3MeN7FFOotivt9qEkA3xCL7Sr0XrrbUNvPXKCnd14ilbPYyPItvPAONGB3KrFpeS1Qo/r4iKw8stwbC+9IYSwFcX/vQsN0rk5Agj9AA3hXsrt6ly0SbOONoa5XJm17rN2Tx4nNtGhu9+GBuLrPBa7Hs5+m0cZ5qIS5C13Zxz/WHg12XoLFK4ZUsZTzDlTHhNrINqF2l/i5n5cSswn+OI06I5Kph3kz7ffBqLSyIyJB79hdqG1rIsltip1QqSVSp25GnRFTsDAK+x1No4pmEgwBBqd5fXynzMvEgpxvtRd6JKXnRxegUtk76DTBtAPDE11L+/98VPp8jZidTuLLpTouVJp9G/i75bUr45odaf8nJdi4/vo2xv6oQ2gKuztx2qEzcN4hQbxnSCne01x3oLok4iQRNIzjIzRMxH+AL0MdI2NQQ35Suw8xVayAmDF7lHfcJ8Ez0elNbY1cjvXKlWe8b4g6Yl5DDepfoTGDQ1H1cxhqp3qMmDR4MGq8HxY//hTGUoyufLPVXtI+lv9rI8FrsVAQVNJ9DHWApBQYnkI/4klwNuoYSSe2rywH0q2orXSwXbNJxEJTDrNrdl4qY4gjvFrELfCALm21BjUTxJPgQYT5vRmlnHcg3xPq7f0NGlpxPqbOGAm9bSQYLUHVAw1zuQ2VEr/CmzFRRv2FXju/N6LbYiR4u1euHWpML7GXbw2q3qUsYaDOhW9QdTOa4dEFDd3YDrzqndMUnaq1CGiV4rXyF2mYjjoK3kPDQlYQi+8bZeN4EpVi30JtZeLXk4V755PgeagkeC8pqPFxxNQQz3GELjQxB1Xpp3r5TeyazSeF8KC4NkbbffjEnrVvP6xoYHtEgj2S1RtSGs9IrjuQzwlVRxegixYstJf2cWLhFE3RqP6NRiCfAu/YsW72MCcNFEa9re+jXuWhwCBUiigBxsT1Z7C9LNeSphEfDXH5BA2rmOkR1qlGQu+jBv4bUSnxM9I33tdCJdPX0WluzdCPwWv2Ekck+GNUMlxgL3Zk18xI8kvQH58Ex6MLSNRO45yxxBa3uMnLH2bPxBw0VvJyVIr9HFuWKo02HkPjRm+0a7Xd7n9fjwRPRz8iLwPdcv1u7Ckp5x3I50QsJu0g+32KvcTPUXqdvb72EpzmkcokNPQi6fp7du6nlJ74vx+qLpaSBBOcm7IRH53Z0dEIb42RUqE31t+iISlvomEwaU+gRxfh/JDSK9+Ijed1VGKOSLARKi1KumNJs09R/X8z0ipzVRRKx+CNQ+ci/xn90G0FHvKOn26kuh6V+p4ADkmzb9ejUnL0UR1u93wzKuEf7/X/XFQiD9PbsvVs5LoD+ZjQ2QTTjQR+H3dsILrixrOYXSvu+MmocXojKUpPqIqzhdiCltED73uVR3nlM1IRUSltUDwJ2rFoEn/SZbPKqLuJEeBtcfli1+YbVOqLnASlvMWVeE+L0XnYZYbwxJFfF3Sx0sj73tDIaStxMzrQOb4FpOghj3vO7sFmo6AhSV+jc67b2jM0HZ3a+K15oTKvU01LOe9APibU3jbTiOdPluevtzfQJIN/4am4qDRzDiohJpQEiElcvgp0DGonuzAqQ2n7zxbUcTAqi2Os7ZHgTOKCp6mgKoqq88+gqmb7uGMtUQnsIyPJehXtfwX7lmjll73i7xWxGLx5eE4Gu79DjQQf8fLTvmbe/W2OSs0d0NjSy4l9hMbYMzgfOCaT+xJSGfch1x3I14SGjTyLtzgmpaenDUBX4f1d3HkFZb3YlF6gcwSl19X7C6r2dI8756eojWg0OqUu7TX3yhljsZHgSlQNy4oKatduK+rQ6eDl97SPQy972Udno70M+ino7Jcl2Nxhyz8ftZUmisGLSHAz8HQa7SQLUzoDXdHHn3P9G9Q+upAKxBKGlMK9yXUH8iWZJHAiuift0ZbXGjU6b8EMz3EkeCQJJLoy6o/KNSC2PPqPMcnS2nrRXqwhaHDwEajd7GZrq4S4WMAsjLuY2GKarbJY70n28XgLnWN8FSpR/RuVEt8B7suD+x4tzT8T9eJHktkAyo7Bq49KamsoJwwlEenZh+9mdp/KdrIRbrTSTzPU4XZWrq/Rnpxy3oF8SEZKc+yl/NT+H2/H9kdDNHwSrBV3fqpe2Dpo6MwUdGpWcdzxZsB9Rhxfot7auajNrotJCP0qYfzFVGBZ/hTq7Yh6k5dbeg5VvRsYGY4mjZkyldC/aHmv9kZmL6Oravue17Ji8OpTzpJW6Ad1AnC5l/eUkepHqMnjdaClHWuJmlQ+sXL/QZ0r7bM13pAS3KdcdyDXCVVHZ9nD35qYhFYCPGNlvm/HN5HiXhHoxPX94/JOIrZcfmTU7o5OrfPnwR6DemoHeuUmGolktINYDq7vXqi3t5n9ro96TjfgbYiUg375jp+u6ArYJehc5yPIMAYPDVKeh9oSh6A2vldRyX4/NHJgqT1rrbxn4Q47ZzJZNHeEVMZ9ynUHcp1QG9s0oLX9fgz18v7WXtInLP/7qJ1sapL6BF12vdTEeDt2ISpJFlp9N6DS3iqTCKYkqO9Y1Ba5njRj8vItod7M1228ebFMu93vxeg83imo5D0TtVdWKAbPO68TunrOLDRAegqx6XIFRoaLUSfH973z9yJNj3JIFbz/ue5ATgevD+FA4Hz7Pc7Ir5NJKo8YkT1mx5uR3JgdTZCPHCfFmNSGSptLUElyPhrmcDEqLQ5H1e9Dvbr2Ru1zE0kzviwfEzHbWc4kv7j+XGAfpL7ocl1FqAq8DrXR+pJgyjF4lLYTH4w6WtYCLyQoG5Hg29iCDSFV4TOQ6w7kOqGzK4pNIltshBQ5LI5G7TXxMzLKWhG4rZXvZ+QqRnQPEVNz9kGXhboALybNiG4Rcd4+1GYWpIHKufc3oNJoqUVqUZX4c3SVnF4eCSaNwaO0aj0A1QZaoZLgNuCyBOccTmyzqUoJBg+pjPuV6w7kS7KH8DPgbC9vBLqr2MBkkp+V/y5qv/FnO4w0Ar0bz8vqvVTFqBF+JmoEr9SA4JBK3a+zUJXX3384ClX6g923WcScXynv3GcfvblY7Ca6YO1LqM1vSIJzOwcJsOpTEQERPkW/0KeKyEp05ZXBwOvOuecARKTQOberrAqcc+tFpD/q/ZskImc5534vIl+iEf+IyBjn3ArnnBORxuj6eMehkt4ZzrkSESlwzpVU5mBrEsq5nh+iXtchIrLOObfaObfTjm1Gpbb9UVswzpiqLETPhog8jKrPP0enFeKcWygiV6KLP4wQEZxzD3jnzstkjAEVRK4ZOJ8SOh/2C1Qq2IhKcylF+eOpUahEtwoNYI0kwWiO592YwRtVrx5BQ1+SbloeUoXuqS+VtUTtu429vGvQ6Xl3YnZWVG2dgJpD0l2Q9QTUYXKcl9cEXd2lFTrz4yXU5rebOhxS1aZIDQswiEhbNCB2B/C4c26XiBS5mGSQ6JwCp5JbQzSM4jM0DKINKmFc6JybJiLD0Yn1f0YXOFgrIk2BTc45l0zCDEgP/vUUkfvQWMrDUdveNOfcHXbsRvQDtQMlr4ZoSFRv59yiNNs8HSXTLuhMoe7oUvz1UGIdgS6aEM0yOsU5tzmjgQZUGIEAkyBVUhKRWuhMjjroXhCr0JfgRnSl5XOMBC9F1eFH0dkAn9r54sLNqBSIyD/RLUWvRx1N41Fp7AHn3LVWZiB6v45E791d6ZKf1dMOeBd9ForQmM5JqC25E7oW4n7oUmpfOuc+ymRsAZkh2ACTIA2JrAX6Ut3lnJsNICJT0JVPJgL/EJELnHN/EZH6aGzZeq+dQH6VABEZgjoYLnTOTReRy+z3y8A5IrLTOXeDUzvvcyJSCGnd91Jwzi0RkRPR6W4L0EUTHrG+FKIOsrrOuYUZDy4gYwQCzB62oGEvzaMMU2tXo1sxPg2MFZHrnDpGxtjx4PDIIhJcTwc8bOQ3HN3x7kzUBvcocL2I7HDOjYKKE58P59wrIjIT2BV92ERkH3S+7wbUwRKQBwgqcJYgInVQSa85Km0s9o7ti3oUWwIznHP9LT+ovVlEnM3vZHSV5U9Qm55D78FDwFjn3DaT1B5GBYG7nXM3V1K/zkWdI4PQZa3erYx2AtJHQa47sKfAObcNuAm189wiIh28w/uhL+OhaExhdE4gvywhjvweQvdlOQfY6ZxbgwagNwOW2r0CDVz/H+qF/0cl9asn6vg4EN3kPpBfHiGowFmEc+49ERmMbvbTRkReQSP8z0Wnv33kQpxfpcAljsGb5ZzbbkW2o1MRDxGRqfb/oeiqK792zn1dSV17C50DvtE5tz5Z4YCqRVCBKwEi0hHdOvEwNPZvGXCqc25HIL/Kg4icgEpzQ5xzL1teYzSYeRs67/Yh9H7sRE0SRznnFuSmxwG5RpAAKwHOuQVm94nWvvvYHB7lxhMGZIyG6AdnjojUY/cYvNvQYPehaKD7X31bbUDNQ5AAqwhB8qt8lBOD9y90Lu4oNEB9VbgXARAkwCpDeOEqHynE4K1EP/rhXgQAgQAD9jCUE4N3EhqD90Uu+xeQXwgEGLDHwbezJojB25izjgXkHQIBBuyx8GLwviF4ewMSIDhBAvZYiEgBGuwcYvACEiIQYEBAQI1FmAoXEBBQYxEIMCAgoMYiEGBAQECNRSDAgICAGotAgAEBATUWgQADKgQR2SUi80RkgYg8LiJ1gIazAgAAAxdJREFUM6irj4hEW4+eIiLXl1O2kS1rn24bt4jIyFTz48o8KCJnpNFWKxEJMYfVAIEAAyqKbc65zs65jmig8aX+QVGk/Xw5555xzo0up0gjIG0CDAhIhECAAdnADOBAk3yW2C5sC4D9RKSfiLwhInNNUqwPICInichiEZmLbkCP5V8kIuPs/2YiMllE5ls6EhiNLjY7T0TutHLXiMhsEXlXRH7l1XWjiCy1ucHtkg1CRIZaPfNF5Mk4qbaviLxt9Q208oUicqfX9rBML2RA1SIQYEBGEJEidLOf9yzrIOAe59wh6L63NwF9nXOHoxsRXSUie6ELl/4f0BVvI6k4/Al41Tl3GLqf70J0a8vlJn1eIyL9rM3u6G5vXUXkaBHpCpxtef2BbikM5ynnXDdr7310Y/QIrayNAcBfbAwXA5udc92s/qEi0jqFdgLyBGEucEBFUUdE5tn/M4D70a1BP3LOzbL8nsDBwGsiAlAMvAG0Bz50zi2Db5exvyRBG8cBF8C3S95vthWeffSz9I79ro8SYgNgsnNuq7XxTApj6igit6Fqdn10XcEIk2wZrWUi8j8bQz/gUM8+uLe1vTSFtgLyAIEAAyqKbc65zn6GkdxXfhbwH+fcOXHlSp2XIQT4rXPur3FtXFmBuh4EBjnn5ovIRejq0RHi54w6a/ty55xPlIhIqwq0HZADBBU4oDIxC+glIgcCiEg9EWkLLAZaiUgbK3dOGee/BAy3cwtFZG90Pb8GXpkXgSGebbGlrf83HRgkInVEpAGqbidDA2CtiNQCzos7dqaIFFifDwCWWNvDrTwi0taW4g+oJggSYEClwTm33iSpCSJS27Jvcs4tFZFLgOdFZCuqQjdIUMUI4G8icjGwCxjunHtDRF6zMJN/mx2wA/CGSaBfAj9yzs0VkceA+ejOfLNT6PIvgTeB9fbX79NKdIe3hsClzrntIvJ31DY4V7Tx9ei6gwHVBGE1mICAgBqLoAIHBATUWAQCDAgIqLEIBBgQEFBjEQgwICCgxiIQYEBAQI1FIMCAgIAai0CAAQEBNRb/DzXDFOKYPcqCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(print_confusion_matrix(cf_matrix, class_names=dataset.get_labels()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.5914</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.6277</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>0.7483</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>0.7113</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.7551</td>\n",
       "      <td>0.7896</td>\n",
       "      <td>0.7720</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guilt</th>\n",
       "      <td>0.6537</td>\n",
       "      <td>0.6677</td>\n",
       "      <td>0.6606</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.8734</td>\n",
       "      <td>0.8415</td>\n",
       "      <td>0.8571</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.7695</td>\n",
       "      <td>0.6900</td>\n",
       "      <td>0.7276</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shame</th>\n",
       "      <td>0.5748</td>\n",
       "      <td>0.5957</td>\n",
       "      <td>0.5851</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         precision  recall  f1-score  support\n",
       "anger       0.5914  0.6687    0.6277      329\n",
       "disgust     0.7483  0.6778    0.7113      329\n",
       "fear        0.7551  0.7896    0.7720      328\n",
       "guilt       0.6537  0.6677    0.6606      328\n",
       "joy         0.8734  0.8415    0.8571      328\n",
       "sadness     0.7695  0.6900    0.7276      329\n",
       "shame       0.5748  0.5957    0.5851      329"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, fscore, support = precision_recall_fscore_support(test_actual_label_ids, test_pred_label_ids)\n",
    "score_dict = {\n",
    "  \"precision\": precision.round(4),\n",
    "  \"recall\": recall.round(4),\n",
    "  \"f1-score\": fscore.round(4),\n",
    "  \"support\": support.round(4)\n",
    "}\n",
    "score_df = pd.DataFrame(score_dict, index=dataset.get_labels())\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.7043</td>\n",
       "      <td>0.7043</td>\n",
       "      <td>0.7043</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       precision  recall  f1-score support\n",
       "score     0.7043  0.7043    0.7043    None"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, fscore, support = precision_recall_fscore_support(test_actual_label_ids, test_pred_label_ids, average=\"micro\")\n",
    "score_dict = {\n",
    "  \"precision\": precision.round(4),\n",
    "  \"recall\": recall.round(4),\n",
    "  \"f1-score\": fscore.round(4),\n",
    "  \"support\": support\n",
    "}\n",
    "score_df = pd.DataFrame(score_dict, index=[\"score\"])\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa: 0.6550730940693303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "kappa_score = cohen_kappa_score(test_actual_label_ids, test_pred_label_ids)\n",
    "print(\"kappa:\", kappa_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
