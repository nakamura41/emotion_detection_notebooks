{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "import urllib.request\n",
    "import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from pytorch_pretrained_bert.modeling import BertForSequenceClassification\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n",
    "\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, usually either \"0\" or \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6,7\"\n",
    "os.environ[\"TFHUB_CACHE_DIR\"]=\"tfhub_modules\"\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_rank = -1\n",
    "max_seq_length = 40\n",
    "bert_model = \"bert-base-uncased\"\n",
    "do_lower_case = True\n",
    "num_labels = 4\n",
    "gradient_accumulation_steps = 1\n",
    "train_batch_size = 32\n",
    "eval_batch_size = 8\n",
    "test_batch_size = 8\n",
    "learning_rate = 5e-5\n",
    "num_train_epochs = 3.0\n",
    "warmup_proportion = 0.1\n",
    "output_dir = \"bert\"\n",
    "do_train = True\n",
    "do_eval = True\n",
    "fp16 = True\n",
    "loss_scale = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if local_rank == -1:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "else:\n",
    "    torch.cuda.set_device(local_rank)\n",
    "    device = torch.device(\"cuda\", local_rank)\n",
    "    n_gpu = 1\n",
    "    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "    torch.distributed.init_process_group(backend='nccl')\n",
    "\n",
    "seed = 20190104\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/29/2019 11:11:20 - INFO - __main__ -   device: cuda, n_gpu: 2, distributed training: False, 16-bits training: True\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"device: {}, n_gpu: {}, distributed training: {}, 16-bits training: {}\".format(\n",
    "    device, n_gpu, bool(local_rank != -1), fp16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer Comparison - NLTK Tokenizer vs BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"I love Kung Fu Panda and chicken tikka masala!\",\n",
    "    \"Divide each difficulty into as many parts as is feasible and necessary to resolve it.\",\n",
    "    \"It is not enough to have a good mind; the main thing is to use it well.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   [   'i',\n",
      "        'love',\n",
      "        'kung',\n",
      "        'fu',\n",
      "        'panda',\n",
      "        'and',\n",
      "        'chicken',\n",
      "        'tikka',\n",
      "        'masala',\n",
      "        '!'],\n",
      "    [   'divide',\n",
      "        'each',\n",
      "        'difficulty',\n",
      "        'into',\n",
      "        'as',\n",
      "        'many',\n",
      "        'parts',\n",
      "        'as',\n",
      "        'is',\n",
      "        'feasible',\n",
      "        'and',\n",
      "        'necessary',\n",
      "        'to',\n",
      "        'resolve',\n",
      "        'it',\n",
      "        '.'],\n",
      "    [   'it',\n",
      "        'is',\n",
      "        'not',\n",
      "        'enough',\n",
      "        'to',\n",
      "        'have',\n",
      "        'a',\n",
      "        'good',\n",
      "        'mind',\n",
      "        ';',\n",
      "        'the',\n",
      "        'main',\n",
      "        'thing',\n",
      "        'is',\n",
      "        'to',\n",
      "        'use',\n",
      "        'it',\n",
      "        'well',\n",
      "        '.']]\n"
     ]
    }
   ],
   "source": [
    "nltk_tokenized_text = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
    "pp.pprint(nltk_tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/29/2019 11:11:23 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/david/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   [   'i',\n",
      "        'love',\n",
      "        'kung',\n",
      "        'fu',\n",
      "        'panda',\n",
      "        'and',\n",
      "        'chicken',\n",
      "        'ti',\n",
      "        '##kka',\n",
      "        'mas',\n",
      "        '##ala',\n",
      "        '!'],\n",
      "    [   'divide',\n",
      "        'each',\n",
      "        'difficulty',\n",
      "        'into',\n",
      "        'as',\n",
      "        'many',\n",
      "        'parts',\n",
      "        'as',\n",
      "        'is',\n",
      "        'feasible',\n",
      "        'and',\n",
      "        'necessary',\n",
      "        'to',\n",
      "        'resolve',\n",
      "        'it',\n",
      "        '.'],\n",
      "    [   'it',\n",
      "        'is',\n",
      "        'not',\n",
      "        'enough',\n",
      "        'to',\n",
      "        'have',\n",
      "        'a',\n",
      "        'good',\n",
      "        'mind',\n",
      "        ';',\n",
      "        'the',\n",
      "        'main',\n",
      "        'thing',\n",
      "        'is',\n",
      "        'to',\n",
      "        'use',\n",
      "        'it',\n",
      "        'well',\n",
      "        '.']]\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_model, do_lower_case=do_lower_case)\n",
    "bert_tokenized_text = [bert_tokenizer.tokenize(sentence) for sentence in sentences]\n",
    "pp.pprint(bert_tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/29/2019 11:11:23 - INFO - __main__ -   {'anger': 0, 'sadness': 1, 'joy': 2}\n"
     ]
    }
   ],
   "source": [
    "label_list = [\"anger\", \"sadness\", \"joy\"]\n",
    "label_map = {label : i for i, label in enumerate(label_list)}\n",
    "logger.info(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmoIntDataset(object):\n",
    "    BASE_URL = \"http://saifmohammad.com/WebDocs/\"\n",
    "    TRAIN_URI = \"EmoInt%20Train%20Data/{}-ratings-0to1.train.txt\"\n",
    "    TEST_URI = \"EmoInt%20Test%20Gold%20Data/{}-ratings-0to1.test.gold.txt\"\n",
    "    THRESHOLD = 0.33\n",
    "  \n",
    "    def get_labels(self):\n",
    "        return [\"anger\", \"fear\", \"joy\", \"sadness\"]\n",
    "  \n",
    "    def get_label_map(self):\n",
    "        return {label : i for i, label in enumerate(self.get_labels())}\n",
    "\n",
    "    def __load_data_per_class(self, label, url, threshold=0):\n",
    "        resource = urllib.request.urlopen(url)\n",
    "        np_array = np.asarray([line.split('\\t') for line in [line.strip() for line in resource.read().decode('utf-8').splitlines()]])\n",
    "        df = pd.DataFrame(np_array, columns=[\"id\", \"text\", \"label\", \"label_level\"])\n",
    "        df['label_level'] = df['label_level'].astype(float)\n",
    "        df = df.query('label_level>' + str(threshold))\n",
    "        df.loc[df[\"label\"] == label, \"label_int\"] = self.get_label_map()[label]\n",
    "        return df[[\"text\", \"label\", \"label_int\"]]\n",
    "    \n",
    "    def __load_data(self, set_threshold=False):\n",
    "        train_data = None\n",
    "        test_data = None\n",
    "\n",
    "        for label in self.get_labels():\n",
    "            # load train dataset\n",
    "            train_df = self.__load_data_per_class(label, self.BASE_URL + self.TRAIN_URI.format(label), threshold=(self.THRESHOLD if set_threshold else 0))\n",
    "\n",
    "            # load test dataset\n",
    "            test_df = self.__load_data_per_class(label, self.BASE_URL + self.TEST_URI.format(label), threshold=(self.THRESHOLD if set_threshold else 0))\n",
    "\n",
    "            train_data = (train_df if train_data is None else train_data.append(train_df))\n",
    "            test_data = (test_df if test_data is None else test_data.append(test_df))\n",
    "\n",
    "        return train_data, test_data\n",
    "\n",
    "    def __init__(self, set_threshold=False):\n",
    "        self.train_dataset, self.test_dataset = self.__load_data(set_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "dataset = EmoIntDataset(set_threshold=True)\n",
    "train_dataset = dataset.train_dataset \n",
    "test_dataset = dataset.test_dataset\n",
    "train_dataset, eval_dataset = train_test_split(train_dataset, test_size=0.1, random_state=41, stratify=train_dataset.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset.shape: (2610, 3)\n",
      "eval_dataset.shape: (291, 3)\n",
      "test_dataset.shape: (2508, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_dataset.shape: (%d, %d)\" % train_dataset.shape)\n",
    "print(\"eval_dataset.shape: (%d, %d)\" % eval_dataset.shape)\n",
    "print(\"test_dataset.shape: (%d, %d)\" % test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/29/2019 11:12:56 - INFO - __main__ -   row index:123\n",
      "01/29/2019 11:12:56 - INFO - __main__ -   text:Food that gets delivered 😍🙌🏻  \n",
      "01/29/2019 11:12:56 - INFO - __main__ -   label:joy\n",
      "01/29/2019 11:12:56 - INFO - __main__ -   label_int:2.0\n"
     ]
    }
   ],
   "source": [
    "for (row_index, row) in train_dataset.iterrows():\n",
    "    logger.info(\"row index:{}\".format(row_index))\n",
    "    logger.info(\"text:{}\".format(row.text))\n",
    "    logger.info(\"label:{}\".format(row.label))\n",
    "    logger.info(\"label_int:{}\".format(row.label_int))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "        \n",
    "def convert_dataset_to_features(dataset, label_map, max_seq_length, tokenizer):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "\n",
    "    features = []\n",
    "    index = 0\n",
    "    for (guid, row) in dataset.iterrows():\n",
    "        tokens = tokenizer.tokenize(row.text)\n",
    "\n",
    "        # Account for [CLS] and [SEP] with \"- 2\"\n",
    "        if len(tokens) > max_seq_length - 2:\n",
    "            tokens = tokens[:(max_seq_length - 2)]\n",
    "\n",
    "        # The convention in BERT is:\n",
    "        # (a) For sequence pairs:\n",
    "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "        #  type_ids: 0   0  0    0    0     0       0 0    1  1  1  1   1 1\n",
    "        # (b) For single sequences:\n",
    "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
    "        #  type_ids: 0   0   0   0  0     0 0\n",
    "        #\n",
    "        # Where \"type_ids\" are used to indicate whether this is the first\n",
    "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
    "        # embedding vector (and position vector). This is not *strictly* necessary\n",
    "        # since the [SEP] token unambigiously separates the sequences, but it makes\n",
    "        # it easier for the model to learn the concept of sequences.\n",
    "        #\n",
    "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
    "        # the entire model is fine-tuned.\n",
    "        tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "        segment_ids = [0] * len(tokens)\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "\n",
    "        label_id = label_map[row.label]\n",
    "        if index < 5:\n",
    "            logger.info(\"*** row ***\")\n",
    "            logger.info(\"guid: %s\" % (guid))\n",
    "            logger.info(\"tokens: %s\" % \" \".join(\n",
    "                    [str(x) for x in tokens]))\n",
    "            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "            logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "            logger.info(\n",
    "                    \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "            logger.info(\"label: %s (id = %d)\" % (row.label, label_id))\n",
    "\n",
    "        features.append(\n",
    "                InputFeatures(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              label_id=label_id))\n",
    "        index += 1\n",
    "        \n",
    "    return features\n",
    "\n",
    "\n",
    "def _truncate_seq_pair(tokens, tokens_b, max_length):\n",
    "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "    # This is a simple heuristic which will always truncate the longer sequence\n",
    "    # one token at a time. This makes more sense than truncating an equal percent\n",
    "    # of tokens from each, since if one sequence is very short then each token\n",
    "    # that's truncated likely contains more information than a longer sequence.\n",
    "    while True:\n",
    "        total_length = len(tokens) + len(tokens_b)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        if len(tokens) > len(tokens_b):\n",
    "            tokens.pop()\n",
    "        else:\n",
    "            tokens_b.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/29/2019 11:12:58 - INFO - __main__ -   *** row ***\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   guid: 123\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   tokens: [CLS] food that gets delivered [UNK] [SEP]\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   input_ids: 101 2833 2008 4152 5359 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   label: joy (id = 2)\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   *** row ***\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   guid: 700\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   tokens: [CLS] @ the _ nasty _ p now you gotta do that with fast n furious [SEP]\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   input_ids: 101 1030 1996 1035 11808 1035 1052 2085 2017 10657 2079 2008 2007 3435 1050 9943 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   label: anger (id = 0)\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   *** row ***\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   guid: 656\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   tokens: [CLS] thank god the fed ##s did not raise rates . assume they are nervous about a world where 99 ##0 is the new employee form & amp ; the safety net is z ##il ##ch [SEP]\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   input_ids: 101 4067 2643 1996 7349 2015 2106 2025 5333 6165 1012 7868 2027 2024 6091 2055 1037 2088 2073 5585 2692 2003 1996 2047 7904 2433 1004 23713 1025 1996 3808 5658 2003 1062 4014 2818 102 0 0 0\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   label: fear (id = 1)\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   *** row ***\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   guid: 717\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   tokens: [CLS] my little sister sure can hold a gr ##udge [UNK] [SEP]\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   input_ids: 101 2026 2210 2905 2469 2064 2907 1037 24665 15979 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   label: anger (id = 0)\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   *** row ***\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   guid: 59\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   tokens: [CLS] @ jr ##ding ##y ##9 ##6 ik ##r people still got a gr ##udge against him for no reason like w ##tf ? ! [SEP]\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   input_ids: 101 1030 3781 4667 2100 2683 2575 20912 2099 2111 2145 2288 1037 24665 15979 2114 2032 2005 2053 3114 2066 1059 24475 1029 999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:58 - INFO - __main__ -   label: anger (id = 0)\n"
     ]
    }
   ],
   "source": [
    "train_features = convert_dataset_to_features(train_dataset, dataset.get_label_map(), max_seq_length, bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/29/2019 11:14:07 - INFO - __main__ -   train_features length:2610\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"train_features length:{}\".format(len(train_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/29/2019 11:12:59 - INFO - __main__ -   *** row ***\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   guid: 471\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   tokens: [CLS] lord make me an instrument of your peace — where there ' s hate , let me so ##w love — where there ' s injury , pardon — where there ' s despair , hope [SEP]\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   input_ids: 101 2935 2191 2033 2019 6602 1997 2115 3521 1517 2073 2045 1005 1055 5223 1010 2292 2033 2061 2860 2293 1517 2073 2045 1005 1055 4544 1010 14933 1517 2073 2045 1005 1055 13905 1010 3246 102 0 0\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   label: sadness (id = 3)\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   *** row ***\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   guid: 379\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   tokens: [CLS] @ ar ##dit _ hal ##iti i ' m so gut ##ted . i loved her cheer ##y disposition . [SEP]\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   input_ids: 101 1030 12098 23194 1035 11085 25090 1045 1005 1049 2061 9535 3064 1012 1045 3866 2014 15138 2100 22137 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   label: joy (id = 2)\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   *** row ***\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   guid: 302\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   tokens: [CLS] ho ##rri ##d having a car n no li ##sc ##ence [SEP]\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   input_ids: 101 7570 18752 2094 2383 1037 2482 1050 2053 5622 11020 10127 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   label: fear (id = 1)\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   *** row ***\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   guid: 395\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   tokens: [CLS] if i spend more than £10 in shi ##mmy on £1 drinks i ' ll be raging , but we all know it ' s gonna happen [SEP]\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   input_ids: 101 2065 1045 5247 2062 2084 26812 1999 11895 18879 2006 14534 8974 1045 1005 2222 2022 17559 1010 2021 2057 2035 2113 2009 1005 1055 6069 4148 102 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   label: anger (id = 0)\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   *** row ***\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   guid: 809\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   tokens: [CLS] @ t ##j _ fa ##sho l ##ma ##o clown my own hair i ' m going to dread l ##ma ##o [SEP]\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   input_ids: 101 1030 1056 3501 1035 6904 22231 1048 2863 2080 15912 2026 2219 2606 1045 1005 1049 2183 2000 14436 1048 2863 2080 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:12:59 - INFO - __main__ -   label: fear (id = 1)\n"
     ]
    }
   ],
   "source": [
    "eval_features = convert_dataset_to_features(eval_dataset, dataset.get_label_map(), max_seq_length, bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/29/2019 11:14:20 - INFO - __main__ -   eval_features length:291\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"eval_features length:{}\".format(len(eval_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/29/2019 11:13:00 - INFO - __main__ -   *** row ***\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   guid: 2\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   tokens: [CLS] this game has pissed me off more than any other game this year . my blood is boiling ! time to turn it off ! # st ##lc ##ards [SEP]\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   input_ids: 101 2023 2208 2038 9421 2033 2125 2062 2084 2151 2060 2208 2023 2095 1012 2026 2668 2003 16018 999 2051 2000 2735 2009 2125 999 1001 2358 15472 18117 102 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   label: anger (id = 0)\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   *** row ***\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   guid: 4\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   tokens: [CLS] @ mo ##oco ##w ##ward @ mrs ##aj ##har ##gre ##aves @ mel ##ly ##7 ##7 @ gary ##bar ##low if he can ' t come to my mum ' a 60th after 25 ##k t ##wee ##ts [SEP]\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   input_ids: 101 1030 9587 24163 2860 7652 1030 3680 13006 8167 17603 21055 1030 11463 2135 2581 2581 1030 5639 8237 8261 2065 2002 2064 1005 1056 2272 2000 2026 12954 1005 1037 20928 2044 2423 2243 1056 28394 3215 102\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   label: anger (id = 0)\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   *** row ***\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   guid: 5\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   tokens: [CLS] @ mo ##oco ##w ##ward @ mrs ##aj ##har ##gre ##aves @ mel ##ly ##7 ##7 @ gary ##bar ##low if he can ' t come to my mum ' a 60th after 25 ##k t ##wee ##ts [SEP]\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   input_ids: 101 1030 9587 24163 2860 7652 1030 3680 13006 8167 17603 21055 1030 11463 2135 2581 2581 1030 5639 8237 8261 2065 2002 2064 1005 1056 2272 2000 2026 12954 1005 1037 20928 2044 2423 2243 1056 28394 3215 102\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   label: anger (id = 0)\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   *** row ***\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   guid: 6\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   tokens: [CLS] wanna go home and focus up on this game . don ' t wanna rage at all [SEP]\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   input_ids: 101 10587 2175 2188 1998 3579 2039 2006 2023 2208 1012 2123 1005 1056 10587 7385 2012 2035 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   label: anger (id = 0)\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   *** row ***\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   guid: 7\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   tokens: [CLS] @ virgin ##media i ' ve been disconnected whilst on holiday [UNK] but i don ' t move house until the 1st october [UNK] # furious [SEP]\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   input_ids: 101 1030 6261 16969 1045 1005 2310 2042 23657 5819 2006 6209 100 2021 1045 2123 1005 1056 2693 2160 2127 1996 3083 2255 100 1001 9943 102 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/29/2019 11:13:00 - INFO - __main__ -   label: anger (id = 0)\n"
     ]
    }
   ],
   "source": [
    "test_features = convert_dataset_to_features(test_dataset, dataset.get_label_map(), max_seq_length, bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/29/2019 11:14:36 - INFO - __main__ -   test_features length:2508\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"test_features length:{}\".format(len(test_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/29/2019 11:13:02 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/david/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "01/29/2019 11:13:02 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/david/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpc0qm87dz\n",
      "01/29/2019 11:13:06 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "01/29/2019 11:13:12 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "01/29/2019 11:13:12 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "# Prepare model\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    bert_model,\n",
    "    cache_dir=PYTORCH_PRETRAINED_BERT_CACHE / 'distributed_{}'.format(local_rank),\n",
    "    num_labels = num_labels\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "if fp16:\n",
    "    model.half()\n",
    "        \n",
    "if local_rank != -1:\n",
    "    try:\n",
    "        from apex.parallel import DistributedDataParallel as DDP\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
    "\n",
    "    model = DDP(model)\n",
    "elif n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/29/2019 11:14:45 - INFO - __main__ -   train_batch_size = 32\n",
      "01/29/2019 11:14:45 - INFO - __main__ -   num train_dataset = 2610\n",
      "01/29/2019 11:14:45 - INFO - __main__ -   gradient_accumulation_steps = 1\n",
      "01/29/2019 11:14:45 - INFO - __main__ -   num_train_epochs = 3.0\n",
      "01/29/2019 11:14:45 - INFO - __main__ -   num_train_steps = 244\n",
      "01/29/2019 11:14:45 - INFO - __main__ -   t_total = 244\n"
     ]
    }
   ],
   "source": [
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "train_batch_size = int(train_batch_size / gradient_accumulation_steps)\n",
    "logger.info(\"train_batch_size = {}\".format(train_batch_size))\n",
    "logger.info(\"num train_dataset = {}\".format(len(train_dataset)))\n",
    "logger.info(\"gradient_accumulation_steps = {}\".format(gradient_accumulation_steps))\n",
    "logger.info(\"num_train_epochs = {}\".format(num_train_epochs))\n",
    "\n",
    "num_train_steps = int(\n",
    "    len(train_dataset) / train_batch_size / gradient_accumulation_steps * num_train_epochs\n",
    ")\n",
    "logger.info(\"num_train_steps = {}\".format(num_train_steps))\n",
    "\n",
    "t_total = num_train_steps\n",
    "\n",
    "if local_rank != -1:\n",
    "    t_total = t_total // torch.distributed.get_world_size()\n",
    "\n",
    "logger.info(\"t_total = {}\".format(t_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fp16:\n",
    "    try:\n",
    "        from apex.optimizers import FP16_Optimizer\n",
    "        from apex.optimizers import FusedAdam\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
    "\n",
    "    optimizer = FusedAdam(optimizer_grouped_parameters,\n",
    "                          lr=learning_rate,\n",
    "                          bias_correction=False,\n",
    "                          max_grad_norm=1.0)\n",
    "    if loss_scale == 0:\n",
    "        optimizer = FP16_Optimizer(optimizer, dynamic_loss_scale=True)\n",
    "    else:\n",
    "        optimizer = FP16_Optimizer(optimizer, static_loss_scale=loss_scale)\n",
    "\n",
    "else:\n",
    "    optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                         lr=learning_rate,\n",
    "                         warmup=warmup_proportion,\n",
    "                         t_total=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/29/2019 11:14:47 - INFO - __main__ -   ***** Running training *****\n",
      "01/29/2019 11:14:48 - INFO - __main__ -     Num examples = 2610\n",
      "01/29/2019 11:14:48 - INFO - __main__ -     Batch size = 32\n",
      "01/29/2019 11:14:48 - INFO - __main__ -     Num steps = 244\n"
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "nb_tr_steps = 0\n",
    "tr_loss = 0\n",
    "    \n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "logger.info(\"  Batch size = %d\", train_batch_size)\n",
    "logger.info(\"  Num steps = %d\", num_train_steps)\n",
    "train_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "train_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "train_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "train_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2833,  2008,  ...,     0,     0,     0],\n",
       "        [  101,  1030,  1996,  ...,     0,     0,     0],\n",
       "        [  101,  4067,  2643,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  5037,  4654,  ...,     0,     0,     0],\n",
       "        [  101,  1045,  1005,  ...,     0,     0,     0],\n",
       "        [  101, 10126,  5637,  ...,  2890, 10222,   102]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 101, 2833, 2008, 4152, 5359,  100,  102,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2610, 40])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2610, 40])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_segment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_segment_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2610, 40])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_segment_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 1,  ..., 2, 0, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2610])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_input_ids, train_input_mask, train_segment_ids, train_label_ids)\n",
    "if local_rank == -1:\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "else:\n",
    "    train_sampler = DistributedSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.sampler.RandomSampler at 0x7faecef4ef28>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/29/2019 11:14:56 - INFO - __main__ -   num_train_epochs = 3.0\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"num_train_epochs = {}\".format(num_train_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(preds, labels):\n",
    "    return np.sum(preds == labels)\n",
    "\n",
    "def warmup_linear(x, warmup=0.002):\n",
    "    if x < warmup:\n",
    "        return x/warmup\n",
    "    return 1.0 - x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38df479d51a4426b1e09e6c6f087b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=82, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grad overflow on iteration 0\n",
      "Using dynamic loss scale of 4294967296\n",
      "\n",
      "Grad overflow on iteration 1\n",
      "Using dynamic loss scale of 2147483648.0\n",
      "\n",
      "Grad overflow on iteration 2\n",
      "Using dynamic loss scale of 1073741824.0\n",
      "\n",
      "Grad overflow on iteration 3\n",
      "Using dynamic loss scale of 536870912.0\n",
      "\n",
      "Grad overflow on iteration 4\n",
      "Using dynamic loss scale of 268435456.0\n",
      "\n",
      "Grad overflow on iteration 5\n",
      "Using dynamic loss scale of 134217728.0\n",
      "\n",
      "Grad overflow on iteration 6\n",
      "Using dynamic loss scale of 67108864.0\n",
      "\n",
      "Grad overflow on iteration 7\n",
      "Using dynamic loss scale of 33554432.0\n",
      "\n",
      "Grad overflow on iteration 8\n",
      "Using dynamic loss scale of 16777216.0\n",
      "\n",
      "Grad overflow on iteration 9\n",
      "Using dynamic loss scale of 8388608.0\n",
      "\n",
      "Grad overflow on iteration 10\n",
      "Using dynamic loss scale of 4194304.0\n",
      "\n",
      "Grad overflow on iteration 11\n",
      "Using dynamic loss scale of 2097152.0\n",
      "\n",
      "Grad overflow on iteration 12\n",
      "Using dynamic loss scale of 1048576.0\n",
      "\n",
      "Grad overflow on iteration 13\n",
      "Using dynamic loss scale of 524288.0\n",
      "\n",
      "Grad overflow on iteration 14\n",
      "Using dynamic loss scale of 262144.0\n",
      "\n",
      "Grad overflow on iteration 15\n",
      "Using dynamic loss scale of 131072.0\n",
      "\n",
      "Grad overflow on iteration 16\n",
      "Using dynamic loss scale of 65536.0\n",
      "\n",
      "Grad overflow on iteration 35\n",
      "Using dynamic loss scale of 32768.0\n",
      "\n",
      "Grad overflow on iteration 79\n",
      "Using dynamic loss scale of 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|███▎      | 1/3 [00:28<00:56, 28.12s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c0ec613ae1c4ce494c5ee942f0601e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=82, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grad overflow on iteration 82\n",
      "Using dynamic loss scale of 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████▋   | 2/3 [00:52<00:26, 26.86s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88129f19ebd4024beff8fb77992c1f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=82, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 3/3 [01:15<00:00, 25.96s/it]\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for _ in trange(int(num_train_epochs), desc=\"Epoch\"):\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        train_input_ids, train_input_mask, train_segment_ids, train_label_ids = batch\n",
    "        loss = model(train_input_ids, train_segment_ids, train_input_mask, train_label_ids)\n",
    "        if n_gpu > 1:\n",
    "            loss = loss.mean() # mean() to average on multi-gpu.\n",
    "        if gradient_accumulation_steps > 1:\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "            \n",
    "        if fp16:\n",
    "            optimizer.backward(loss)\n",
    "        else:\n",
    "            loss.backward()\n",
    "            \n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += train_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "            # modify learning rate with special warm up BERT uses\n",
    "            lr_this_step = learning_rate * warmup_linear(global_step/t_total, warmup_proportion)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr_this_step\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "train_loss = tr_loss/nb_tr_steps if do_train else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/29/2019 11:16:25 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/david/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "01/29/2019 11:16:25 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/david/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpxjatxdqu\n",
      "01/29/2019 11:16:29 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save a trained model\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "output_model_file = \"pytorch_emoint_bert_model.pt\"\n",
    "torch.save(model_to_save.state_dict(), output_model_file)\n",
    "\n",
    "# Load a trained model that you have fine-tuned\n",
    "model_state_dict = torch.load(output_model_file)\n",
    "model = BertForSequenceClassification.from_pretrained(bert_model, state_dict=model_state_dict, num_labels=num_labels)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(mode, features, batch_size):\n",
    "    logger.info(\"***** Running {} *****\".format(mode))\n",
    "    logger.info(\"  Num examples = %d\", len(features))\n",
    "    logger.info(\"  Batch size = %d\", batch_size)\n",
    "    \n",
    "    input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "    data = TensorDataset(input_ids, input_mask, segment_ids, label_ids)\n",
    "    \n",
    "    # Run prediction for full data\n",
    "    sampler = SequentialSampler(data)\n",
    "    dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n",
    "\n",
    "    model.eval()\n",
    "    loss, accuracy = 0, 0\n",
    "    nb_steps, nb_examples = 0, 0\n",
    "    all_pred_label_ids = []\n",
    "    all_actual_label_ids = []\n",
    "\n",
    "    for input_ids, input_mask, segment_ids, label_ids in tqdm(dataloader, desc=mode):\n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "        label_ids = label_ids.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tmp_loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "            logits = model(input_ids, segment_ids, input_mask)\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        preds = np.argmax(logits, axis=1)\n",
    "        \n",
    "        label_ids = label_ids.to('cpu').numpy()\n",
    "        \n",
    "        all_pred_label_ids += preds.tolist()\n",
    "        all_actual_label_ids += label_ids.tolist()\n",
    "        \n",
    "        tmp_accuracy = calc_accuracy(preds, label_ids)\n",
    "\n",
    "        loss += tmp_loss.mean().item()\n",
    "        accuracy += tmp_accuracy\n",
    "\n",
    "        nb_examples += input_ids.size(0)\n",
    "        nb_steps += 1\n",
    "\n",
    "    loss = loss / nb_steps\n",
    "    accuracy = accuracy / nb_examples\n",
    "    \n",
    "    result = {'{}_loss'.format(mode): loss,\n",
    "              '{}_accuracy'.format(mode): accuracy,\n",
    "              'global_step': global_step}\n",
    "\n",
    "    output_file = \"pytorch_emoint_bert_{}_results.txt\".format(mode)\n",
    "    with open(output_file, \"w\") as writer:\n",
    "        logger.info(\"***** {} results *****\".format(mode))\n",
    "        for key in sorted(result.keys()):\n",
    "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "\n",
    "    return loss, accuracy, all_pred_label_ids, all_actual_label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/29/2019 11:16:32 - INFO - __main__ -   ***** Running eval *****\n",
      "01/29/2019 11:16:32 - INFO - __main__ -     Num examples = 291\n",
      "01/29/2019 11:16:32 - INFO - __main__ -     Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc81a14034fb475da0406551085ad83c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='eval', max=37, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/29/2019 11:16:34 - INFO - __main__ -   ***** eval results *****\n",
      "01/29/2019 11:16:34 - INFO - __main__ -     eval_accuracy = 0.872852233676976\n",
      "01/29/2019 11:16:34 - INFO - __main__ -     eval_loss = 0.38137887055809433\n",
      "01/29/2019 11:16:34 - INFO - __main__ -     global_step = 246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = evaluate('eval', eval_features, eval_batch_size)\n",
    "eval_loss, eval_accuracy, eval_pred_label_ids, eval_actual_label_ids = eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>63</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         anger  fear  joy  sadness\n",
       "anger       63     5    4        1\n",
       "fear         3    84    1        4\n",
       "joy          5     1   58        0\n",
       "sadness      6     7    0       49"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "cf_matrix = confusion_matrix(eval_actual_label_ids, eval_pred_label_ids)\n",
    "\n",
    "df_cm = pd.DataFrame(\n",
    "    cf_matrix, index=dataset.get_labels(), columns=dataset.get_labels(), \n",
    ")\n",
    "\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (4,3), fontsize=15):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure(288x216)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(print_confusion_matrix(cf_matrix, class_names=dataset.get_labels()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.8182</td>\n",
       "      <td>0.8630</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.8660</td>\n",
       "      <td>0.9130</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.9206</td>\n",
       "      <td>0.9062</td>\n",
       "      <td>0.9134</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.7903</td>\n",
       "      <td>0.8448</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         precision  recall  f1-score  support\n",
       "anger       0.8182  0.8630    0.8400       73\n",
       "fear        0.8660  0.9130    0.8889       92\n",
       "joy         0.9206  0.9062    0.9134       64\n",
       "sadness     0.9074  0.7903    0.8448       62"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, fscore, support = precision_recall_fscore_support(eval_actual_label_ids, eval_pred_label_ids)\n",
    "score_dict = {\n",
    "  \"precision\": precision.round(4),\n",
    "  \"recall\": recall.round(4),\n",
    "  \"f1-score\": fscore.round(4),\n",
    "  \"support\": support.round(4)\n",
    "}\n",
    "score_df = pd.DataFrame(score_dict, index=dataset.get_labels())\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa: 0.8284307476575945\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "kappa_score = cohen_kappa_score(eval_actual_label_ids, eval_pred_label_ids)\n",
    "print(\"kappa:\", kappa_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/29/2019 11:16:34 - INFO - __main__ -   ***** Running test *****\n",
      "01/29/2019 11:16:34 - INFO - __main__ -     Num examples = 2508\n",
      "01/29/2019 11:16:34 - INFO - __main__ -     Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5807b3a649bb42db94a369835c9ef3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='test', max=314, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/29/2019 11:16:44 - INFO - __main__ -   ***** test results *****\n",
      "01/29/2019 11:16:44 - INFO - __main__ -     global_step = 246\n",
      "01/29/2019 11:16:44 - INFO - __main__ -     test_accuracy = 0.8548644338118022\n",
      "01/29/2019 11:16:44 - INFO - __main__ -     test_loss = 0.45134367762952093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_result = evaluate('test', test_features, test_batch_size)\n",
    "test_loss, test_accuracy, test_pred_label_ids, test_actual_label_ids = test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>550</td>\n",
       "      <td>47</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>66</td>\n",
       "      <td>649</td>\n",
       "      <td>16</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>493</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>43</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         anger  fear  joy  sadness\n",
       "anger      550    47   13       33\n",
       "fear        66   649   16       58\n",
       "joy         19    20  493       11\n",
       "sadness     43    33    5      452"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "cf_matrix = confusion_matrix(test_actual_label_ids, test_pred_label_ids)\n",
    "\n",
    "df_cm = pd.DataFrame(\n",
    "    cf_matrix, index=dataset.get_labels(), columns=dataset.get_labels(), \n",
    ")\n",
    "\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure(288x216)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(print_confusion_matrix(cf_matrix, class_names=dataset.get_labels()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.8112</td>\n",
       "      <td>0.8554</td>\n",
       "      <td>0.8327</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.8665</td>\n",
       "      <td>0.8226</td>\n",
       "      <td>0.8440</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.9355</td>\n",
       "      <td>0.9079</td>\n",
       "      <td>0.9215</td>\n",
       "      <td>543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.8159</td>\n",
       "      <td>0.8480</td>\n",
       "      <td>0.8316</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         precision  recall  f1-score  support\n",
       "anger       0.8112  0.8554    0.8327      643\n",
       "fear        0.8665  0.8226    0.8440      789\n",
       "joy         0.9355  0.9079    0.9215      543\n",
       "sadness     0.8159  0.8480    0.8316      533"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, fscore, support = precision_recall_fscore_support(test_actual_label_ids, test_pred_label_ids)\n",
    "score_dict = {\n",
    "  \"precision\": precision.round(4),\n",
    "  \"recall\": recall.round(4),\n",
    "  \"f1-score\": fscore.round(4),\n",
    "  \"support\": support.round(4)\n",
    "}\n",
    "score_df = pd.DataFrame(score_dict, index=dataset.get_labels())\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.8549</td>\n",
       "      <td>0.8549</td>\n",
       "      <td>0.8549</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       precision  recall  f1-score support\n",
       "score     0.8549  0.8549    0.8549    None"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, fscore, support = precision_recall_fscore_support(test_actual_label_ids, test_pred_label_ids, average=\"micro\")\n",
    "score_dict = {\n",
    "  \"precision\": precision.round(4),\n",
    "  \"recall\": recall.round(4),\n",
    "  \"f1-score\": fscore.round(4),\n",
    "  \"support\": support\n",
    "}\n",
    "score_df = pd.DataFrame(score_dict, index=[\"score\"])\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa: 0.8050044150572462\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "kappa_score = cohen_kappa_score(test_actual_label_ids, test_pred_label_ids)\n",
    "print(\"kappa:\", kappa_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
