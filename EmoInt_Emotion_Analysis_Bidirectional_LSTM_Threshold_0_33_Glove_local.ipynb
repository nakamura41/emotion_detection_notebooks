{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n",
      "['/job:localhost/replica:0/task:0/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, usually either \"0\" or \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "print(tf.__version__)\n",
    "print(K.tensorflow_backend._get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "OdaHCMv2rGKs",
    "outputId": "757ce36e-5dc9-4f0b-888a-afe86c9e8511"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import Word2Vec\n",
    "from tempfile import gettempdir\n",
    "import zipfile\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "RANDOM_SEED = 20190101\n",
    "\n",
    "def set_random(random_seed):\n",
    "    seed(random_seed)\n",
    "    set_random_seed(random_seed)\n",
    "\n",
    "set_random(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oBynQmEcrNAy"
   },
   "outputs": [],
   "source": [
    "class EmoIntDataset(object):\n",
    "  BASE_URL = \"http://saifmohammad.com/WebDocs/\"\n",
    "  TRAIN_URI = \"EmoInt%20Train%20Data/{}-ratings-0to1.train.txt\"\n",
    "  TEST_URI = \"EmoInt%20Test%20Gold%20Data/{}-ratings-0to1.test.gold.txt\"\n",
    "  EMOTION_CLASSES = [\"anger\", \"fear\", \"joy\", \"sadness\"]\n",
    "  \n",
    "  THRESHOLD = 0.33\n",
    "  \n",
    "  def __load_data_per_class(self, url, threshold=0):\n",
    "    resource = urllib.request.urlopen(url)\n",
    "    np_array = np.asarray([line.split('\\t') for line in [line.strip() for line in resource.read().decode('utf-8').splitlines()]])\n",
    "    df = pd.DataFrame(np_array, columns=[\"id\", \"text\", \"emotion\", \"emotion_level\"])\n",
    "    df['emotion_level'] = df['emotion_level'].astype(float)\n",
    "    df = df.query('emotion_level>' + str(threshold))\n",
    "    return df[[\"text\", \"emotion\"]]\n",
    "  \n",
    "  def load_data(self, set_threshold=False):\n",
    "    train_data = None\n",
    "    test_data = None\n",
    "    \n",
    "    for emotion in self.EMOTION_CLASSES:\n",
    "      # load train dataset\n",
    "      train_df = self.__load_data_per_class(self.BASE_URL + self.TRAIN_URI.format(emotion), threshold=(self.THRESHOLD if set_threshold else 0))\n",
    "      \n",
    "      # load test dataset\n",
    "      test_df = self.__load_data_per_class(self.BASE_URL + self.TEST_URI.format(emotion), threshold=(self.THRESHOLD if set_threshold else 0))\n",
    "      \n",
    "      train_data = (train_df if train_data is None else train_data.append(train_df))\n",
    "      test_data = (test_df if test_data is None else test_data.append(test_df))\n",
    "      \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "tevwfq4Tu6fe",
    "outputId": "5507d39f-e094-4727-d761-2c4d1a883ecb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2610, 2)\n",
      "(291, 2)\n",
      "(2508, 2)\n"
     ]
    }
   ],
   "source": [
    "emo_int_dataset = EmoIntDataset()\n",
    "train_data, test_data = emo_int_dataset.load_data(set_threshold=True)\n",
    "train_data, valid_data = train_test_split(train_data, test_size=0.1, random_state=200, stratify=train_data.emotion)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(valid_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "J-xXkD_4175U",
    "outputId": "abd86198-fa3a-4c35-eb10-993337f48b8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fear': 0, 'anger': 1, 'sadness': 2, 'joy': 3}\n",
      "['fear', 'anger', 'sadness', 'joy']\n"
     ]
    }
   ],
   "source": [
    "emotions = train_data.emotion.unique()\n",
    "dic = dict()\n",
    "labels = []\n",
    "for i, emotion in enumerate(emotions):\n",
    "    dic[emotion]=i\n",
    "    labels.append(emotion)\n",
    "print(dic)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "yhA_GXLyw1gx",
    "outputId": "6a4c4c00-a630-4af6-a75c-fea4d0a33070"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8672 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "NUM_WORDS=20000\n",
    "texts = train_data.text\n",
    "tokenizer = Tokenizer(num_words=NUM_WORDS,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\'',\n",
    "                      lower=True)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences_train = tokenizer.texts_to_sequences(texts)\n",
    "sequences_valid = tokenizer.texts_to_sequences(valid_data.text)\n",
    "sequences_test = tokenizer.texts_to_sequences(test_data.text)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "f3a8LX2z0Vn3",
    "outputId": "9fe28fe7-328a-4fcb-9872-437ec9683444"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X train, validation and test tensor: (2610, 33) (291, 33) (2508, 33)\n",
      "Shape of label train, validation and test tensor: (2610, 4) (291, 4) (2508, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train = pad_sequences(sequences_train)\n",
    "X_val = pad_sequences(sequences_valid, maxlen=X_train.shape[1])\n",
    "X_test = pad_sequences(sequences_test, maxlen=X_train.shape[1])\n",
    "\n",
    "y_train = to_categorical(np.asarray(train_data.emotion.apply(lambda x:dic[x])))\n",
    "y_val = to_categorical(np.asarray(valid_data.emotion.apply(lambda x:dic[x])))\n",
    "y_test = to_categorical(np.asarray(test_data.emotion.apply(lambda x:dic[x])))\n",
    "\n",
    "print('Shape of X train, validation and test tensor:', X_train.shape, X_val.shape, X_test.shape)\n",
    "print('Shape of label train, validation and test tensor:', y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OZprqF6Yqeoe"
   },
   "outputs": [],
   "source": [
    "np.save(\"emoint_X_train.npy\", X_train)\n",
    "np.save(\"emoint_X_val.npy\", X_val)\n",
    "np.save(\"emoint_X_test.npy\", X_test)\n",
    "\n",
    "np.save(\"emoint_y_train.npy\", y_train)\n",
    "np.save(\"emoint_y_val.npy\", y_val)\n",
    "np.save(\"emoint_y_test.npy\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kdMDYkGMF7CA"
   },
   "source": [
    "## Word Embedding using Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://nlp.stanford.edu/data/glove.twitter.27B.zip'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "open('glove.twitter.27B.zip', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv glove.twitter.27B.zip ../../Datasets/WordEmbeddings/glove.twitter.27B.zip\n",
    "!unzip ../../Datasets/WordEmbeddings/glove.twitter.27B.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Glove.Twitter to Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_file = \"../../Datasets/WordEmbeddings/glove.twitter.27B.200d.txt\"\n",
    "tmp_glove_file = \"../../Datasets/WordEmbeddings/glove.word2vec.twitter.27B.200d.txt\"\n",
    "\n",
    "glove2word2vec(glove_file, tmp_glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "naD_jPLlmlFq"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "word_vectors = KeyedVectors.load_word2vec_format('../../Datasets/WordEmbeddings/glove.word2vec.twitter.27B.200d.txt', binary=False)\n",
    "\n",
    "EMBEDDING_DIM=200\n",
    "vocabulary_size = min(len(word_index)+1, NUM_WORDS)\n",
    "embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i>=NUM_WORDS:\n",
    "        continue\n",
    "    try:\n",
    "        embedding_vector = word_vectors[word]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except KeyError:\n",
    "        embedding_matrix[i] = np.random.normal(0,np.sqrt(0.25), EMBEDDING_DIM)\n",
    "\n",
    "del(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aXmsV7sr7Ovh"
   },
   "outputs": [],
   "source": [
    "file_embedded_matrix = \"emoint_embedded_matrix_glove_twitter.npy\"\n",
    "np.save(file_embedded_matrix, embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TD731zTjqTI3"
   },
   "source": [
    "## Reload the embedded layer and training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "SgGl84NR9Y2Y",
    "outputId": "61b12e65-4402-4a12-c7f8-984d7ba226fb"
   },
   "outputs": [],
   "source": [
    "file_embedded_matrix = \"emoint_embedded_matrix_glove_twitter.npy\"\n",
    "embedding_matrix = np.load(file_embedded_matrix)\n",
    "print(\"embedding matrix shape:\", embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "colab_type": "code",
    "id": "txZDRozUyXAQ",
    "outputId": "ed176b31-9088-4236-d632-83748ce4e04a"
   },
   "outputs": [],
   "source": [
    "X_train = np.load(\"emoint_X_train.npy\")\n",
    "X_val = np.load(\"emoint_X_val.npy\")\n",
    "X_test = np.load(\"emoint_X_test.npy\")\n",
    "\n",
    "y_train = np.load(\"emoint_y_train.npy\")\n",
    "y_val = np.load(\"emoint_y_val.npy\")\n",
    "y_test = np.load(\"emoint_y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "colab_type": "code",
    "id": "Q0fX0z7_7Mi5",
    "outputId": "82ec7754-bcbf-44d7-bf24-6a2cd3639bc9"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPooling2D, Dropout, concatenate, LSTM, SpatialDropout1D, Bidirectional\n",
    "from keras.layers.core import Reshape, Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam, Adadelta, RMSprop\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "sequence_length = X_train.shape[1]\n",
    "HIDDEN_DIM = 600\n",
    "DROPOUT_RATE = 0.2\n",
    "N_CLASSES = 4\n",
    "vocabulary_size = embedding_matrix.shape[0]\n",
    "\n",
    "print(\"sequence length:\", sequence_length)\n",
    "\n",
    "inputs = Input(shape=(sequence_length,), name='input_1')\n",
    "embedding_layer = Embedding(vocabulary_size, EMBEDDING_DIM, weights=[embedding_matrix], input_length=sequence_length, trainable=True, name='embedding')\n",
    "embedding = embedding_layer(inputs)\n",
    "spatial_droput = SpatialDropout1D(0.4, name='spatial_dropout')(embedding)\n",
    "lstm = Bidirectional(LSTM(units=HIDDEN_DIM, dropout=DROPOUT_RATE, recurrent_dropout=DROPOUT_RATE, name='lstm'))(spatial_droput)\n",
    "output = Dense(units=N_CLASSES, activation='softmax', name='output')(lstm)\n",
    "\n",
    "model = None \n",
    "\n",
    "# this creates a model that includes\n",
    "model = Model(inputs, output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "colab_type": "code",
    "id": "rClQ6sed4JA5",
    "outputId": "20296d37-73a1-466f-99fa-fc6504e99985"
   },
   "outputs": [],
   "source": [
    "!rm -r tmp\n",
    "!mkdir tmp\n",
    "!ls -lA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4283
    },
    "colab_type": "code",
    "id": "HHZ1POD77GRp",
    "outputId": "0864429c-6681-43a6-bd68-9bc6099c55e2"
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=1e-3, decay=0.0)\n",
    "adadelta = Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['acc'])\n",
    "\n",
    "filepath=\"tmp/weights-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "model_checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "callbacks = [early_stopping, model_checkpoint]\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=1000, epochs=100, verbose=1, validation_data=(X_val, y_val), callbacks=callbacks)  # starts training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OtGrA8RBKShg"
   },
   "outputs": [],
   "source": [
    "model_path = 'emoint_bidirectional_lstm_glove_model.h5'\n",
    "weight_path = 'emoint_bidirectional_lstm_glove_weights.h5'\n",
    "\n",
    "model.save(model_path)\n",
    "model.save_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "colab_type": "code",
    "id": "eFzd1urtKeFw",
    "outputId": "01a74e98-8890-44ae-caa8-7cd95bcaa8b2"
   },
   "outputs": [],
   "source": [
    "!ls -lah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b0P0vTv-7RC6"
   },
   "outputs": [],
   "source": [
    "sequences_test=tokenizer.texts_to_sequences(test_data.text)\n",
    "X_test = pad_sequences(sequences_test, maxlen=X_test.shape[1])\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IgHlDfC_-rS5",
    "outputId": "f3945581-42d0-42a1-b0df-4d91d9f7e6e8"
   },
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-JaFoS4u_pwS"
   },
   "outputs": [],
   "source": [
    "y_pred_original = [labels[val] for val in np.argmax(y_pred, axis=1).squeeze()]\n",
    "y_test_original = np.asarray(test_data.emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BREyqdCAI9d0"
   },
   "outputs": [],
   "source": [
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (4,3), fontsize=15):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "XG9HPQb10TZm",
    "outputId": "c9fe229c-43fe-41bd-a3d6-82c163c1ad2f"
   },
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test_original, y_pred_original, labels=labels)\n",
    "\n",
    "df_cm = pd.DataFrame(\n",
    "    cf_matrix, index=labels, columns=labels, \n",
    ")\n",
    "\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "59xnXmbEAKXy",
    "outputId": "9f68f9f9-0b05-46df-c050-6be4554b0013"
   },
   "outputs": [],
   "source": [
    "print(print_confusion_matrix(cf_matrix, class_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9XE5c4LJEZXy",
    "outputId": "6f276941-fb3c-468e-d8d1-87b1625413a4"
   },
   "outputs": [],
   "source": [
    "test_accuracy = accuracy_score(y_test_original, y_pred_original)\n",
    "print(\"test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jAISNDCVwvR7"
   },
   "source": [
    "### Performance score for each classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "iFb9Q6A1DcXi",
    "outputId": "3f6ff514-f49d-4d2a-a94d-f94c8912bd28"
   },
   "outputs": [],
   "source": [
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test_original, y_pred_original)\n",
    "score_dict = {\n",
    "  \"precision\": precision.round(4),\n",
    "  \"recall\": recall.round(4),\n",
    "  \"f1-score\": fscore.round(4),\n",
    "  \"support\": support.round(4)\n",
    "}\n",
    "score_df = pd.DataFrame(score_dict, index=labels)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cHi1Gw7Oz1zG"
   },
   "source": [
    "### Performance score using micro average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "KP69PDE9D_jz",
    "outputId": "092c1a18-323c-402c-91c3-9bcfef72a24e"
   },
   "outputs": [],
   "source": [
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test_original, y_pred_original, average=\"micro\")\n",
    "score_dict = {\n",
    "  \"precision\": precision.round(4),\n",
    "  \"recall\": recall.round(4),\n",
    "  \"f1-score\": fscore.round(4),\n",
    "  \"support\": support\n",
    "}\n",
    "score_df = pd.DataFrame(score_dict, index=[\"score\"])\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IWXNCktiz8Vb"
   },
   "source": [
    "### Performance score using macro average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "g4e0vsNIydDs",
    "outputId": "55b1571b-4072-4375-e9bf-464c04876875"
   },
   "outputs": [],
   "source": [
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test_original, y_pred_original, average=\"macro\")\n",
    "score_dict = {\n",
    "  \"precision\": precision.round(4),\n",
    "  \"recall\": recall.round(4),\n",
    "  \"f1-score\": fscore.round(4),\n",
    "  \"support\": support\n",
    "}\n",
    "score_df = pd.DataFrame(score_dict, index=[\"score\"])\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wFJFH7u6z-oG"
   },
   "source": [
    "### Performance score using weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "z99JkHjuzv68",
    "outputId": "f2b1675b-1673-482a-a993-04fb5de9afe7"
   },
   "outputs": [],
   "source": [
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test_original, y_pred_original, average=\"weighted\")\n",
    "score_dict = {\n",
    "  \"precision\": precision.round(4),\n",
    "  \"recall\": recall.round(4),\n",
    "  \"f1-score\": fscore.round(4),\n",
    "  \"support\": support\n",
    "}\n",
    "score_df = pd.DataFrame(score_dict, index=[\"score\"])\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Y83dx5SyoBR8",
    "outputId": "0d58dac8-378d-4f59-9471-25c23d188bfc"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "kappa_score = cohen_kappa_score(y_test_original, y_pred_original, labels=labels)\n",
    "print(\"kappa:\", kappa_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "EmoInt-Emotion-Analysis-Bidirectional-LSTM-Threshold-0.33.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
