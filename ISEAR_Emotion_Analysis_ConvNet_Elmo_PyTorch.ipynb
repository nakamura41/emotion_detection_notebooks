{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "matplotlib.backends - DEBUG - backend module://ipykernel.pylab.backend_inline version unknown\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "torch.manual_seed(1)\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, usually either \"0\" or \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "os.environ[\"TFHUB_CACHE_DIR\"]=\"tfhub_modules\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISEARDataset(object):\n",
    "  FILENAME = \"data/isear_databank.csv\"\n",
    "  EMOTION_CLASSES = [\"anger\", \"disgust\", \"fear\", \"guilt\", \"joy\", \"sadness\", \"shame\"]\n",
    "  EMOTION_CLASSES_DICT = {\"anger\": 0, \"disgust\": 1, \"fear\": 2, \"guilt\": 3, \"joy\": 4, \"sadness\": 5, \"shame\": 6}\n",
    "  RANDOM_STATE = 41\n",
    "  \n",
    "  def get_classes(self):\n",
    "    return self.EMOTION_CLASSES\n",
    "  \n",
    "  def get_classes_dict(self):\n",
    "    return self.EMOTION_CLASSES_DICT\n",
    "  \n",
    "  def __load_data_file(self):\n",
    "    data = pd.read_csv(self.FILENAME)\n",
    "    data[\"emotion\"] = data[\"Field1\"]\n",
    "    data[\"text\"] = data[\"SIT\"]\n",
    "    return data[[\"text\", \"emotion\"]]\n",
    "\n",
    "  def load_data(self):\n",
    "    train_data = None\n",
    "    test_data = None\n",
    "    \n",
    "    data = self.__load_data_file()\n",
    "    \n",
    "    train_data, test_data = train_test_split(data, test_size=0.3, random_state=self.RANDOM_STATE, stratify=data[\"emotion\"].values)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root - DEBUG - train_data.shape: (4829, 2)\n",
      "root - DEBUG - valid_data.shape: (537, 2)\n",
      "root - DEBUG - test_data.shape: (2300, 2)\n"
     ]
    }
   ],
   "source": [
    "isear_dataset = ISEARDataset()\n",
    "train_data, test_data = isear_dataset.load_data()\n",
    "train_data, valid_data = train_test_split(train_data, test_size=0.1, random_state=200, stratify=train_data.emotion)\n",
    "\n",
    "logging.debug(\"train_data.shape: (%d, %d)\" % train_data.shape)\n",
    "logging.debug(\"valid_data.shape: (%d, %d)\" % valid_data.shape)\n",
    "logging.debug(\"test_data.shape: (%d, %d)\" % test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root - DEBUG - class dictionary: {'anger': 0, 'disgust': 1, 'fear': 2, 'guilt': 3, 'joy': 4, 'sadness': 5, 'shame': 6}\n",
      "root - DEBUG - class labels: ['anger', 'disgust', 'fear', 'guilt', 'joy', 'sadness', 'shame']\n",
      "root - DEBUG - number of bins: 7\n",
      "matplotlib.font_manager - DEBUG - findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000\n",
      "matplotlib.font_manager - DEBUG - findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bins: [0, 1, 2, 3, 4, 5, 6, 7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dic = isear_dataset.get_classes_dict()\n",
    "labels = isear_dataset.get_classes()\n",
    "n_classes = len(labels)\n",
    "logging.debug(\"class dictionary: %s\" % dic)\n",
    "logging.debug(\"class labels: %s\" % labels)\n",
    "logging.debug(\"number of bins: %s\" % n_classes)\n",
    "\n",
    "for emotion in labels:\n",
    "  train_data.loc[train_data.emotion == emotion, \"emotion_int\"] = dic[emotion]\n",
    "  valid_data.loc[valid_data.emotion == emotion, \"emotion_int\"] = dic[emotion]\n",
    "  test_data.loc[test_data.emotion == emotion, \"emotion_int\"] = dic[emotion]\n",
    "\n",
    "bins = list(range(0, n_classes + 1))\n",
    "print(\"bins:\", bins)\n",
    "hist, _ = np.histogram(train_data[\"emotion_int\"], bins=bins)\n",
    "\n",
    "y_pos = np.arange(len(labels))\n",
    "\n",
    "plt.bar(y_pos, hist, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, labels)\n",
    "plt.ylabel('Number')\n",
    "plt.title('Emotions')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "allennlp.modules.elmo - INFO - Initializing ELMo\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json HTTP/1.1\" 200 0\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 HTTP/1.1\" 200 0\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 HTTP/1.1\" 200 0\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 HTTP/1.1\" 200 0\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 HTTP/1.1\" 200 0\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 HTTP/1.1\" 200 0\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 HTTP/1.1\" 200 0\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 HTTP/1.1\" 200 0\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 HTTP/1.1\" 200 0\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 HTTP/1.1\" 200 0\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 HTTP/1.1\" 200 0\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json HTTP/1.1\" 200 0\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 HTTP/1.1\" 200 0\n"
     ]
    }
   ],
   "source": [
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "\n",
    "options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json\"\n",
    "weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5\"\n",
    "\n",
    "# Compute two different representation for each token.\n",
    "# Each representation is a linear weighted combination for the\n",
    "# 3 layers in ELMo (i.e., charcnn, the outputs of the two BiLSTM))\n",
    "elmo = Elmo(options_file, weight_file, num_output_representations=1, dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "allennlp.commands.elmo - INFO - Initializing ELMo.\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json HTTP/1.1\" 200 0\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 HTTP/1.1\" 200 0\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 HTTP/1.1\" 200 0\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 HTTP/1.1\" 200 0\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 HTTP/1.1\" 200 0\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 HTTP/1.1\" 200 0\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 HTTP/1.1\" 200 0\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 HTTP/1.1\" 200 0\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 HTTP/1.1\" 200 0\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 HTTP/1.1\" 200 0\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 HTTP/1.1\" 200 0\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json HTTP/1.1\" 200 0\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com:443\n",
      "urllib3.connectionpool - DEBUG - https://s3-us-west-2.amazonaws.com:443 \"HEAD /allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 HTTP/1.1\" 200 0\n"
     ]
    }
   ],
   "source": [
    "from allennlp.commands.elmo import ElmoEmbedder\n",
    "\n",
    "\n",
    "options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json\"\n",
    "weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5\"\n",
    "\n",
    "elmo = ElmoEmbedder(options_file, weight_file, cuda_device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.07195003, -0.23072985, -0.00943072, ..., -0.6438828 ,\n",
       "         -0.6441163 , -0.24662834],\n",
       "        [-0.21027166, -0.2679156 , -0.15733792, ..., -0.18545806,\n",
       "          0.22321805,  0.07739294],\n",
       "        [-0.86810684,  0.6293375 ,  0.22367026, ..., -0.09220622,\n",
       "          1.0322137 , -0.5260475 ],\n",
       "        [-0.11161093,  0.4175899 ,  0.39825487, ...,  0.39508057,\n",
       "          0.0679122 ,  0.03724104]],\n",
       "\n",
       "       [[ 0.03155486, -0.17761199, -0.7605889 , ...,  0.41598114,\n",
       "          0.10596061, -0.24359159],\n",
       "        [ 0.33438826, -0.9164163 ,  0.1910559 , ..., -0.15816395,\n",
       "          0.09414726, -0.1000901 ],\n",
       "        [-0.2522697 , -0.23032828, -0.4141932 , ...,  0.34381485,\n",
       "          0.45502275, -0.02311403],\n",
       "        [-0.16855855,  0.15430757, -0.18263504, ...,  0.60374373,\n",
       "         -0.34326386, -0.11222638]],\n",
       "\n",
       "       [[-0.97102267, -1.4836148 ,  0.98300326, ..., -0.57647145,\n",
       "         -0.14606684, -1.2897296 ],\n",
       "        [ 0.8983372 , -1.3780742 ,  0.15474083, ..., -0.5491963 ,\n",
       "         -0.28076473,  0.01883367],\n",
       "        [-0.93069595, -0.6096678 , -0.23893082, ..., -0.17408538,\n",
       "          0.09147653, -0.67278534],\n",
       "        [-0.08608697, -0.583987  ,  0.47339645, ...,  1.181642  ,\n",
       "         -0.19155507, -0.10948979]]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = elmo.embed_sentence([\"Hello\", \"I\", \"love\", \"you\"])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, elmo_embedding, input_dim, embedding_dim, \n",
    "                 hidden_dim, batch_size, output_dim=1, num_layers=1):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.elmo = elmo_embedding\n",
    "        self.output_dim = output_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, self.num_layers)\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        # This is what we'll initialise our hidden state as\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        # Forward pass through LSTM layer\n",
    "        # shape of lstm_out: [input_size, batch_size, hidden_dim]\n",
    "        # shape of self.hidden: (a, b), where a and b both \n",
    "        # have shape (num_layers, batch_size, hidden_dim).\n",
    "        embeds = self.elmo(sentence)['elmo_representations'][0]\n",
    "        lstm_out, self.hidden = self.lstm(embeds.view(self.input_dim, self.batch_size, -1))\n",
    "        flatten = self.linear(lstm_out[-1].view(self.batch_size, -1))\n",
    "        output = self.sigmoid(flatten)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of backend CUDA but got backend CPU for argument #3 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-1ec30f7481f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# y_train = torch.from_numpy(y_train).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-b2752608603b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# shape of self.hidden: (a, b), where a and b both\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# have shape (num_layers, batch_size, hidden_dim).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melmo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'elmo_representations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mflatten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/allennlp/modules/elmo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, word_inputs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# run the biLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mbilm_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elmo_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreshaped_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshaped_word_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0mlayer_activations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbilm_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'activations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mmask_with_bos_eos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbilm_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/allennlp/modules/elmo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, word_inputs)\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0mtype_representation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_embedding'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m             \u001b[0mtoken_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_token_embedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0mtype_representation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_embedding'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/allennlp/modules/elmo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    355\u001b[0m         character_embedding = torch.nn.functional.embedding(\n\u001b[1;32m    356\u001b[0m                 \u001b[0mcharacter_ids_with_bos_eos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_chars_per_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_char_embedding_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         )\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1452\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1454\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of backend CUDA but got backend CPU for argument #3 'index'"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "input_dim = 280\n",
    "embedding_dim = 256\n",
    "hidden_dim = 256\n",
    "batch_size = 10\n",
    "output_dim = 6\n",
    "elmo_cuda = elmo.to(device)\n",
    "model = LSTMClassifier(elmo_cuda, input_dim, embedding_dim, hidden_dim, batch_size, output_dim)\n",
    "# model = model.to(device)\n",
    "X_train = batch_to_ids(train_data.text[0:10])\n",
    "# X_train = X_train.to(device)\n",
    "y_train = to_categorical(np.asarray(train_data.emotion[0:10].apply(lambda x:dic[x])))\n",
    "# y_train = torch.from_numpy(y_train).to(device)\n",
    "embeddings = model(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of backend CPU but got backend CUDA for argument #3 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-b934ade3e287>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-b2752608603b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# shape of self.hidden: (a, b), where a and b both\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# have shape (num_layers, batch_size, hidden_dim).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melmo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'elmo_representations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mflatten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/allennlp/modules/elmo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, word_inputs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# run the biLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mbilm_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elmo_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreshaped_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshaped_word_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0mlayer_activations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbilm_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'activations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mmask_with_bos_eos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbilm_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/allennlp/modules/elmo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, word_inputs)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0mtype_representation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_embedding'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0mlstm_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elmo_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_representation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0;31m# Prepare the output.  The first layer is duplicated.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/allennlp/modules/elmo_lstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_sequence_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mstacked_sequence_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestoration_indices\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_and_run_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lstm_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturned_timesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstacked_sequence_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/allennlp/modules/encoder_base.py\u001b[0m in \u001b[0;36msort_and_run_forward\u001b[0;34m(self, module, inputs, mask, hidden_state)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0minitial_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_initial_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorting_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# Actually call the module on the sorted PackedSequence.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/allennlp/modules/encoder_base.py\u001b[0m in \u001b[0;36m_get_initial_states\u001b[0;34m(self, batch_size, num_valid, sorting_indices)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# LSTMs have a state tuple of (state, memory).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             sorted_states = [state.index_select(1, sorting_indices)\n\u001b[0;32m--> 204\u001b[0;31m                              for state in correctly_shaped_states]\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mnum_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/allennlp/modules/encoder_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# LSTMs have a state tuple of (state, memory).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             sorted_states = [state.index_select(1, sorting_indices)\n\u001b[0;32m--> 204\u001b[0;31m                              for state in correctly_shaped_states]\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mnum_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of backend CPU but got backend CUDA for argument #3 'index'"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "num_epochs = 200\n",
    "learning_rate = 1e-3\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#####################\n",
    "# Train model\n",
    "#####################\n",
    "\n",
    "hist = np.zeros(num_epochs)\n",
    "\n",
    "for t in range(num_epochs):\n",
    "    # Clear stored gradient\n",
    "    model.zero_grad()\n",
    "    \n",
    "    # Initialise hidden state\n",
    "    # Don't do this if you want your LSTM to be stateful\n",
    "    model.hidden = model.init_hidden()\n",
    "    \n",
    "    # Forward pass\n",
    "    y_pred = model(X_train)\n",
    "    \n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    print(\"Epoch \", t, \"Cross Entropy Loss: \", loss.item())\n",
    "    hist[t] = loss.item()\n",
    "\n",
    "    # Zero out gradient, else they will accumulate between epochs\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
