{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "OdaHCMv2rGKs",
    "outputId": "4c25ffe9-28d1-4b60-dc3e-c1bb37427aba"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, usually either \"0\" or \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "print(tf.__version__)\n",
    "print(K.tensorflow_backend._get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import Word2Vec\n",
    "from tempfile import gettempdir\n",
    "import zipfile\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "RANDOM_SEED = 20190101\n",
    "\n",
    "def set_random(random_seed):\n",
    "    seed(random_seed)\n",
    "    set_random_seed(random_seed)\n",
    "\n",
    "set_random(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oBynQmEcrNAy"
   },
   "outputs": [],
   "source": [
    "class EmoIntDataset(object):\n",
    "  BASE_URL = \"http://saifmohammad.com/WebDocs/\"\n",
    "  TRAIN_URI = \"EmoInt%20Train%20Data/{}-ratings-0to1.train.txt\"\n",
    "  TEST_URI = \"EmoInt%20Test%20Gold%20Data/{}-ratings-0to1.test.gold.txt\"\n",
    "  EMOTION_CLASSES = [\"anger\", \"fear\", \"joy\", \"sadness\"]\n",
    "  \n",
    "  THRESHOLD = 0.33\n",
    "  \n",
    "  def __load_data_per_class(self, url, threshold=0):\n",
    "    resource = urllib.request.urlopen(url)\n",
    "    np_array = np.asarray([line.split('\\t') for line in [line.strip() for line in resource.read().decode('utf-8').splitlines()]])\n",
    "    df = pd.DataFrame(np_array, columns=[\"id\", \"text\", \"emotion\", \"emotion_level\"])\n",
    "    df['emotion_level'] = df['emotion_level'].astype(float)\n",
    "    df = df.query('emotion_level>' + str(threshold))\n",
    "    return df[[\"text\", \"emotion\"]]\n",
    "  \n",
    "  def load_data(self, set_threshold=False):\n",
    "    train_data = None\n",
    "    test_data = None\n",
    "    \n",
    "    for emotion in self.EMOTION_CLASSES:\n",
    "      # load train dataset\n",
    "      train_df = self.__load_data_per_class(self.BASE_URL + self.TRAIN_URI.format(emotion), threshold=(self.THRESHOLD if set_threshold else 0))\n",
    "      \n",
    "      # load test dataset\n",
    "      test_df = self.__load_data_per_class(self.BASE_URL + self.TEST_URI.format(emotion), threshold=(self.THRESHOLD if set_threshold else 0))\n",
    "      \n",
    "      train_data = (train_df if train_data is None else train_data.append(train_df))\n",
    "      test_data = (test_df if test_data is None else test_data.append(test_df))\n",
    "      \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "tevwfq4Tu6fe",
    "outputId": "ec36e15a-4715-4252-aabf-39e9cf5965b8"
   },
   "outputs": [],
   "source": [
    "emo_int_dataset = EmoIntDataset()\n",
    "train_data, test_data = emo_int_dataset.load_data(set_threshold=True)\n",
    "train_data, valid_data = train_test_split(train_data, test_size=0.1, random_state=RANDOM_SEED, stratify=train_data.emotion)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(valid_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "J-xXkD_4175U",
    "outputId": "a7a98816-a9aa-4124-f705-80c699360ece"
   },
   "outputs": [],
   "source": [
    "emotions = train_data.emotion.unique()\n",
    "dic = dict()\n",
    "labels = []\n",
    "for i, emotion in enumerate(emotions):\n",
    "    dic[emotion]=i\n",
    "    labels.append(emotion)\n",
    "print(dic)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "yhA_GXLyw1gx",
    "outputId": "1e3a39c7-2e9b-4c4f-8683-cbd05b975ce8"
   },
   "outputs": [],
   "source": [
    "NUM_WORDS=20000\n",
    "texts = train_data.text\n",
    "tokenizer = Tokenizer(num_words=NUM_WORDS,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\'',\n",
    "                      lower=True)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences_train = tokenizer.texts_to_sequences(texts)\n",
    "sequences_valid = tokenizer.texts_to_sequences(valid_data.text)\n",
    "sequences_test = tokenizer.texts_to_sequences(test_data.text)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "f3a8LX2z0Vn3",
    "outputId": "9b05668d-f7b4-461c-a0eb-73f44b7dea6d"
   },
   "outputs": [],
   "source": [
    "X_train = pad_sequences(sequences_train)\n",
    "X_val = pad_sequences(sequences_valid, maxlen=X_train.shape[1])\n",
    "X_test = pad_sequences(sequences_test, maxlen=X_train.shape[1])\n",
    "\n",
    "y_train = to_categorical(np.asarray(train_data.emotion.apply(lambda x:dic[x])))\n",
    "y_val = to_categorical(np.asarray(valid_data.emotion.apply(lambda x:dic[x])))\n",
    "y_test = to_categorical(np.asarray(test_data.emotion.apply(lambda x:dic[x])))\n",
    "\n",
    "print('Shape of X train, validation and test tensor:', X_train.shape, X_val.shape, X_test.shape)\n",
    "print('Shape of label train, validation and test tensor:', y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "naD_jPLlmlFq"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "word_vectors = KeyedVectors.load_word2vec_format('../../Datasets/WordEmbeddings/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "\n",
    "EMBEDDING_DIM=300\n",
    "vocabulary_size = min(len(word_index)+1, NUM_WORDS)\n",
    "embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i>=NUM_WORDS:\n",
    "        continue\n",
    "    try:\n",
    "        embedding_vector = word_vectors[word]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except KeyError:\n",
    "        embedding_matrix[i] = np.random.normal(0,np.sqrt(0.25), EMBEDDING_DIM)\n",
    "\n",
    "del(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_embedded_matrix = \"emoint_embedded_matrix_word2vec_googlenews.npy\"\n",
    "np.save(file_embedded_matrix, embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"emoint_X_train.npy\", X_train)\n",
    "np.save(\"emoint_X_val.npy\", X_val)\n",
    "np.save(\"emoint_X_test.npy\", X_test)\n",
    "\n",
    "np.save(\"emoint_y_train.npy\", y_train)\n",
    "np.save(\"emoint_y_val.npy\", y_val)\n",
    "np.save(\"emoint_y_test.npy\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5H1f3UbhE329"
   },
   "source": [
    "## Reload embedding layer and training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "W_ksCjVeE3a2",
    "outputId": "0735ce9c-b13f-43f8-9942-081318aca6f6"
   },
   "outputs": [],
   "source": [
    "file_embedded_matrix = \"emoint_embedded_matrix_word2vec_googlenews.npy\"\n",
    "embedding_matrix = np.load(file_embedded_matrix)\n",
    "print(\"embedding matrix shape:\", embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "colab_type": "code",
    "id": "FGZlNGwuE73I",
    "outputId": "777edc4c-7132-4a44-85f7-043f3b90a1d2"
   },
   "outputs": [],
   "source": [
    "X_train = np.load(\"emoint_X_train.npy\")\n",
    "X_val = np.load(\"emoint_X_val.npy\")\n",
    "X_test = np.load(\"emoint_X_test.npy\")\n",
    "\n",
    "y_train = np.load(\"emoint_y_train.npy\")\n",
    "y_val = np.load(\"emoint_y_val.npy\")\n",
    "y_test = np.load(\"emoint_y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "colab_type": "code",
    "id": "Q0fX0z7_7Mi5",
    "outputId": "ec459fa1-dea4-41ed-fada-bc92e1e56eb0"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Conv2D, MaxPooling2D, Dropout, concatenate, LSTM\n",
    "from tensorflow.keras.layers import Reshape, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta, RMSprop\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "sequence_length = X_train.shape[1]\n",
    "filter_sizes = [3,4,5]\n",
    "num_filters = 100\n",
    "drop_rate = 0.5\n",
    "vocabulary_size = embedding_matrix.shape[0]\n",
    "\n",
    "print(sequence_length)\n",
    "\n",
    "inputs = Input(shape=(sequence_length,), name='input_1')\n",
    "embedding_layer = Embedding(vocabulary_size, EMBEDDING_DIM, weights=[embedding_matrix], input_length=sequence_length, trainable=True, name='embedding')\n",
    "embedding = embedding_layer(inputs)\n",
    "reshape = Reshape((sequence_length, EMBEDDING_DIM, 1), name='reshape_1')(embedding)\n",
    "\n",
    "conv_1 = Conv2D(num_filters, (filter_sizes[0], EMBEDDING_DIM), activation='relu',kernel_regularizer=regularizers.l2(0.01), name='conv_1')(reshape)\n",
    "conv_2 = Conv2D(num_filters, (filter_sizes[1], EMBEDDING_DIM), activation='relu',kernel_regularizer=regularizers.l2(0.01), name='conv_2')(reshape)\n",
    "conv_3 = Conv2D(num_filters, (filter_sizes[2], EMBEDDING_DIM), activation='relu',kernel_regularizer=regularizers.l2(0.01), name='conv_3')(reshape)\n",
    "\n",
    "maxpool_1 = MaxPooling2D((sequence_length - filter_sizes[0] + 1, 1), strides=1, name='maxpool_1')(conv_1)\n",
    "maxpool_2 = MaxPooling2D((sequence_length - filter_sizes[1] + 1, 1), strides=1, name='maxpool_2')(conv_2)\n",
    "maxpool_3 = MaxPooling2D((sequence_length - filter_sizes[2] + 1, 1), strides=1, name='maxpool_3')(conv_3)\n",
    "\n",
    "merged_tensor = concatenate([maxpool_1, maxpool_2, maxpool_3], axis=1, name='concatenate_1')\n",
    "flatten = Flatten()(merged_tensor)\n",
    "dropout = Dropout(drop_rate, name='dropout_1')(flatten)\n",
    "output = Dense(units=4, activation='softmax',kernel_regularizer=regularizers.l2(0.01), name='dense_1')(dropout)\n",
    "\n",
    "model = None \n",
    "\n",
    "# this creates a model that includes\n",
    "model = Model(inputs, output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "rClQ6sed4JA5",
    "outputId": "b9e5e551-970b-40d4-f670-a15b3dea4c97"
   },
   "outputs": [],
   "source": [
    "!rm -r tmp\n",
    "!mkdir tmp\n",
    "!ls -lA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7235
    },
    "colab_type": "code",
    "id": "HHZ1POD77GRp",
    "outputId": "d1bb2a8a-651f-44c3-dbff-8c1ed50751d0"
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=1e-3, decay=0.0)\n",
    "adadelta = Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['acc'])\n",
    "\n",
    "filepath=\"tmp/weights-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "model_checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "callbacks = [early_stopping, model_checkpoint]\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=1000, epochs=100, verbose=1, validation_data=(X_val, y_val), callbacks=callbacks)  # starts training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OtGrA8RBKShg"
   },
   "outputs": [],
   "source": [
    "model_path = 'emoint_convnet_word2vec_googlenews_model.h5'\n",
    "weight_path = 'emoint_convnet_word2vec_googlenews_weights.h5'\n",
    "\n",
    "model.save(model_path)\n",
    "model.save_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "colab_type": "code",
    "id": "eFzd1urtKeFw",
    "outputId": "f68815ff-ebfc-4ed5-fcc8-8c63bd25ff87"
   },
   "outputs": [],
   "source": [
    "!ls -lah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b0P0vTv-7RC6"
   },
   "outputs": [],
   "source": [
    "sequences_test=tokenizer.texts_to_sequences(test_data.text)\n",
    "X_test = pad_sequences(sequences_test, maxlen=X_test.shape[1])\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IgHlDfC_-rS5",
    "outputId": "31b11c6c-f20d-48ee-8b34-d4ed77f64a54"
   },
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-JaFoS4u_pwS"
   },
   "outputs": [],
   "source": [
    "y_pred_original = [labels[val] for val in np.argmax(y_pred, axis=1).squeeze()]\n",
    "y_test_original = np.asarray(test_data.emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BREyqdCAI9d0"
   },
   "outputs": [],
   "source": [
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (4,3), fontsize=15):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "XG9HPQb10TZm",
    "outputId": "e3b800d0-3f15-45a2-defb-9f715fd29de2"
   },
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test_original, y_pred_original, labels=labels)\n",
    "\n",
    "df_cm = pd.DataFrame(\n",
    "    cf_matrix, index=labels, columns=labels, \n",
    ")\n",
    "\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "59xnXmbEAKXy",
    "outputId": "d0eb88ff-ba79-445c-f709-5b1b9a3f76fc"
   },
   "outputs": [],
   "source": [
    "print(print_confusion_matrix(cf_matrix, class_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9XE5c4LJEZXy",
    "outputId": "bc5b6c2a-56f9-482a-d5d7-8a8f8951d073"
   },
   "outputs": [],
   "source": [
    "test_accuracy = accuracy_score(y_test_original, y_pred_original)\n",
    "print(\"test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jAISNDCVwvR7"
   },
   "source": [
    "### Performance score for each classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "iFb9Q6A1DcXi",
    "outputId": "c929fdf3-b791-4b64-9f23-dda88a238456"
   },
   "outputs": [],
   "source": [
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test_original, y_pred_original)\n",
    "score_dict = {\n",
    "  \"precision\": precision.round(4),\n",
    "  \"recall\": recall.round(4),\n",
    "  \"f1-score\": fscore.round(4),\n",
    "  \"support\": support.round(4)\n",
    "}\n",
    "score_df = pd.DataFrame(score_dict, index=labels)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cHi1Gw7Oz1zG"
   },
   "source": [
    "### Performance score using micro average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "KP69PDE9D_jz",
    "outputId": "a09292bc-cb8c-4da1-e465-f01284bcb061"
   },
   "outputs": [],
   "source": [
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test_original, y_pred_original, average=\"micro\")\n",
    "score_dict = {\n",
    "  \"precision\": precision.round(4),\n",
    "  \"recall\": recall.round(4),\n",
    "  \"f1-score\": fscore.round(4),\n",
    "  \"support\": support\n",
    "}\n",
    "score_df = pd.DataFrame(score_dict, index=[\"score\"])\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IWXNCktiz8Vb"
   },
   "source": [
    "### Performance score using macro average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "g4e0vsNIydDs",
    "outputId": "67b18848-4c46-4c36-d085-17e3caf36efb"
   },
   "outputs": [],
   "source": [
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test_original, y_pred_original, average=\"macro\")\n",
    "score_dict = {\n",
    "  \"precision\": precision.round(4),\n",
    "  \"recall\": recall.round(4),\n",
    "  \"f1-score\": fscore.round(4),\n",
    "  \"support\": support\n",
    "}\n",
    "score_df = pd.DataFrame(score_dict, index=[\"score\"])\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wFJFH7u6z-oG"
   },
   "source": [
    "### Performance score using weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "z99JkHjuzv68",
    "outputId": "f96c549e-7a24-4411-cb4e-53e64c431b9a"
   },
   "outputs": [],
   "source": [
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test_original, y_pred_original, average=\"weighted\")\n",
    "score_dict = {\n",
    "  \"precision\": precision.round(4),\n",
    "  \"recall\": recall.round(4),\n",
    "  \"f1-score\": fscore.round(4),\n",
    "  \"support\": support\n",
    "}\n",
    "score_df = pd.DataFrame(score_dict, index=[\"score\"])\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohen Kappa Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Y83dx5SyoBR8",
    "outputId": "ac60ea1c-5d2f-4ce8-f56a-e17404d025cd"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "kappa_score = cohen_kappa_score(y_test_original, y_pred_original, labels=labels)\n",
    "print(\"kappa:\", kappa_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "EmoInt-Emotion-Analysis-ConvNet-Threshold-0.33.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
