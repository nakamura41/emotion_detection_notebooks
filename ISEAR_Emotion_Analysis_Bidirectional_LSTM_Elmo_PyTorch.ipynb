{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, usually either \"0\" or \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "os.environ[\"TFHUB_CACHE_DIR\"]=\"tfhub_modules\"\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.tokenizers.word_tokenizer import WordTokenizer\n",
    "from allennlp.modules.elmo import batch_to_ids\n",
    "\n",
    "NUM_WORDS = 20000\n",
    "\n",
    "class ISEARDataset(object):\n",
    "    FILENAME = \"data/isear_databank.csv\"\n",
    "    EMOTION_CLASSES = [\"anger\", \"disgust\", \"fear\", \"guilt\", \"joy\", \"sadness\", \"shame\"]\n",
    "    EMOTION_CLASSES_DICT = {\"anger\": 0, \"disgust\": 1, \"fear\": 2, \"guilt\": 3, \"joy\": 4, \"sadness\": 5, \"shame\": 6}\n",
    "    RANDOM_STATE = 41\n",
    "  \n",
    "    def get_classes(self):\n",
    "        return self.EMOTION_CLASSES\n",
    "  \n",
    "    def get_classes_dict(self):\n",
    "        return self.EMOTION_CLASSES_DICT\n",
    "    \n",
    "    def _tokens_to_texts(self, tokens):\n",
    "        texts = []\n",
    "        for token in tokens:\n",
    "            texts.append([t.text for t in token])\n",
    "        return texts\n",
    "\n",
    "    def _sequence_texts(self, texts):\n",
    "        tokenizer = WordTokenizer()\n",
    "        tokens = tokenizer.batch_tokenize(texts)\n",
    "        sequences = batch_to_ids(self._tokens_to_texts(tokens))\n",
    "        return sequences\n",
    "\n",
    "    def __init__(self, n_items=0):\n",
    "        data = pd.read_csv(self.FILENAME)\n",
    "\n",
    "        if n_items > 0:\n",
    "            data = data.iloc[0:n_items,:]\n",
    "\n",
    "        data[\"text\"] = data[\"SIT\"]\n",
    "        data[\"emotion\"] = data[\"Field1\"]\n",
    "\n",
    "        for emotion in self.get_classes():\n",
    "            data.loc[data[\"emotion\"] == emotion, \"emotion_int\"] = self.get_classes_dict()[emotion]\n",
    "\n",
    "        self.X = self._sequence_texts(data[\"text\"]).numpy()\n",
    "        self.y = data[\"emotion_int\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ISEARDataset()\n",
    "# dataset = ISEARDataset(200)\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.X, dataset.y, test_size=0.3, random_state=dataset.RANDOM_STATE, stratify=dataset.y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=dataset.RANDOM_STATE, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (4292, 201, 50)\n",
      "y_train.shape: (4292)\n",
      "X_valid.shape: (1074, 201, 50)\n",
      "y_valid.shape: (1074)\n",
      "X_test.shape: (2300, 201, 50)\n",
      "y_test.shape: (2300)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train.shape: (%d, %d, %d)\" % X_train.shape)\n",
    "print(\"y_train.shape: (%d)\" % y_train.shape)\n",
    "\n",
    "print(\"X_valid.shape: (%d, %d, %d)\" % X_valid.shape)\n",
    "print(\"y_valid.shape: (%d)\" % y_valid.shape)\n",
    "\n",
    "print(\"X_test.shape: (%d, %d, %d)\" % X_test.shape)\n",
    "print(\"y_test.shape: (%d)\" % y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"pytorch_isear_X_train_elmo.npy\", X_train)\n",
    "np.save(\"pytorch_isear_X_valid_elmo.npy\", X_valid)\n",
    "np.save(\"pytorch_isear_X_test_elmo.npy\", X_test)\n",
    "\n",
    "np.save(\"pytorch_isear_y_train_elmo.npy\", y_train)\n",
    "np.save(\"pytorch_isear_y_valid_elmo.npy\", y_valid)\n",
    "np.save(\"pytorch_isear_y_test_elmo.npy\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"pytorch_isear_X_train_elmo.npy\")\n",
    "X_valid = np.load(\"pytorch_isear_X_valid_elmo.npy\")\n",
    "X_test = np.load(\"pytorch_isear_X_test_elmo.npy\")\n",
    "\n",
    "y_train = np.load(\"pytorch_isear_y_train_elmo.npy\")\n",
    "y_valid = np.load(\"pytorch_isear_y_valid_elmo.npy\")\n",
    "y_test = np.load(\"pytorch_isear_y_test_elmo.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class dictionary: {'anger': 0, 'disgust': 1, 'fear': 2, 'guilt': 3, 'joy': 4, 'sadness': 5, 'shame': 6}\n",
      "class labels: ['anger', 'disgust', 'fear', 'guilt', 'joy', 'sadness', 'shame']\n",
      "number of bins: 7\n"
     ]
    }
   ],
   "source": [
    "dic = dataset.get_classes_dict()\n",
    "labels = dataset.get_classes()\n",
    "n_classes = len(labels)\n",
    "print(\"class dictionary: %s\" % dic)\n",
    "print(\"class labels: %s\" % labels)\n",
    "print(\"number of bins: %s\" % n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bins: [0, 1, 2, 3, 4, 5, 6, 7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = list(range(0, n_classes + 1))\n",
    "print(\"bins:\", bins)\n",
    "hist, _ = np.histogram(y_train, bins=bins)\n",
    "\n",
    "y_pos = np.arange(len(labels))\n",
    "\n",
    "plt.bar(y_pos, hist, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, labels)\n",
    "plt.ylabel('Number')\n",
    "plt.title('Emotions')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.shape: torch.Size([4292, 1, 1, 1])\n",
      "y_onehot.shape: torch.Size([4292, 7, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "from torch import autograd\n",
    "\n",
    "def make_one_hot(labels, C=2):\n",
    "    '''\n",
    "    Converts an integer label torch.autograd.Variable to a one-hot Variable.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    labels : torch.autograd.Variable of torch.cuda.LongTensor\n",
    "        N x 1 x H x W, where N is batch size. \n",
    "        Each value is an integer representing correct classification.\n",
    "    C : integer. \n",
    "        number of classes in labels.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    target : torch.autograd.Variable of torch.cuda.FloatTensor\n",
    "        N x C x H x W, where C is class number. One-hot encoded.\n",
    "    '''\n",
    "    one_hot = torch.FloatTensor(labels.size(0), C, labels.size(2), labels.size(3)).zero_()\n",
    "    target = one_hot.scatter_(1, labels.data, 1)\n",
    "    \n",
    "    target = autograd.Variable(target)\n",
    "        \n",
    "    return target\n",
    "  \n",
    "y = torch.LongTensor(y_train).view(-1, 1, 1, 1)\n",
    "print(\"y.shape:\", y.shape)\n",
    "y_onehot = make_one_hot(y, C=7)\n",
    "print(\"y_onehot.shape:\", y_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "class ISEAR_Tensor_Dataset(data.TensorDataset):\n",
    "  \n",
    "  def __init__(self, text, emotion, num_class=2):\n",
    "    X = torch.LongTensor(text)\n",
    "    y = torch.LongTensor(emotion).view(-1, 1, 1, 1)\n",
    "    y_onehot = make_one_hot(y, num_class)\n",
    "    y_onehot = y_onehot.view(y_onehot.shape[0], y_onehot.shape[1])\n",
    "    tensors = []\n",
    "    tensors.append(X)\n",
    "    tensors.append(y_onehot)\n",
    "    super().__init__(*tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ISEAR_Tensor_Dataset(X_train, y_train, num_class=7)\n",
    "valid_dataset = ISEAR_Tensor_Dataset(X_valid, y_valid, num_class=7)\n",
    "test_dataset = ISEAR_Tensor_Dataset(X_test, y_test, num_class=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset.tensors[0].shape: torch.Size([4292, 201, 50])\n",
      "train_dataset.tensors[1].shape: torch.Size([4292, 7])\n"
     ]
    }
   ],
   "source": [
    "print(\"train_dataset.tensors[0].shape:\", train_dataset.tensors[0].shape)\n",
    "print(\"train_dataset.tensors[1].shape:\", train_dataset.tensors[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset length: 4292\n",
      "valid_dataset length: 1074\n",
      "test_dataset length: 2300\n"
     ]
    }
   ],
   "source": [
    "print(\"train_dataset length:\", len(train_dataset))\n",
    "print(\"valid_dataset length:\", len(valid_dataset))\n",
    "print(\"test_dataset length:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Elmo Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/allennlp/commands/find_learning_rate.py:54: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2823, in run_cell\n",
      "    self.events.trigger('post_run_cell', result)\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/IPython/core/events.py\", line 88, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/ipykernel/pylab/backend_inline.py\", line 164, in configure_once\n",
      "    activate_matplotlib(backend)\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/IPython/core/pylabtools.py\", line 314, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/matplotlib/__init__.py\", line 1422, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  import matplotlib; matplotlib.use('Agg') # pylint: disable=multiple-statements,wrong-import-position\n",
      "01/21/2019 15:31:56 - INFO - allennlp.commands.elmo -   Initializing ELMo.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15912526845932007\n"
     ]
    }
   ],
   "source": [
    "from allennlp.commands.elmo import ElmoEmbedder\n",
    "\n",
    "\n",
    "options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json\"\n",
    "weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5\"\n",
    "\n",
    "elmo_embedder = ElmoEmbedder(options_file, weight_file)\n",
    "tokens = [\"I\", \"ate\", \"an\", \"apple\", \"for\", \"breakfast\"]\n",
    "vectors = elmo_embedder.embed_sentence(tokens)\n",
    "\n",
    "import scipy\n",
    "vectors2 = elmo_embedder.embed_sentence([\"I\", \"ate\", \"a\", \"carrot\", \"for\", \"breakfast\"])\n",
    "print(scipy.spatial.distance.cosine(vectors[2][3], vectors2[2][3])) # cosine distance between \"apple\" and \"carrot\" in the last layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors.shape: (3, 6, 256)\n",
      "vectors2.shape: (3, 6, 256)\n",
      "vectors[2][3].shape: (256,)\n",
      "vectors2[2][3].shape: (256,)\n"
     ]
    }
   ],
   "source": [
    "print(\"vectors.shape:\", vectors.shape)\n",
    "print(\"vectors2.shape:\", vectors2.shape)\n",
    "\n",
    "print(\"vectors[2][3].shape:\", vectors[2][3].shape)\n",
    "print(\"vectors2[2][3].shape:\", vectors2[2][3].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Elmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/21/2019 15:32:11 - INFO - allennlp.modules.elmo -   Initializing ELMo\n"
     ]
    }
   ],
   "source": [
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "\n",
    "options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json\"\n",
    "weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5\"\n",
    "\n",
    "# Compute two different representation for each token.\n",
    "# Each representation is a linear weighted combination for the\n",
    "# 3 layers in ELMo (i.e., charcnn, the outputs of the two BiLSTM))\n",
    "elmo = Elmo(options_file, weight_file, num_output_representations=1, dropout=0)\n",
    "elmo = elmo.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Elmo Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: torch.Size([201, 50])\n",
      "experiment_X_train.shape: torch.Size([1, 201, 50])\n",
      "embedded shape: torch.Size([1, 201, 256])\n"
     ]
    }
   ],
   "source": [
    "shape = train_dataset[0][0].shape\n",
    "print(\"shape:\", shape)\n",
    "experiment_X_train = train_dataset[0][0].view(1, shape[0], shape[1]).to(device)\n",
    "print(\"experiment_X_train.shape:\", experiment_X_train.shape)\n",
    "\n",
    "embedded = elmo(experiment_X_train)\n",
    "print(\"embedded shape:\", embedded['elmo_representations'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2986, -0.5326,  0.0442,  ...,  0.1001,  0.1496,  0.0450],\n",
       "        [ 0.0817,  0.2332, -0.3614,  ...,  0.0515, -0.1492, -0.0824],\n",
       "        [ 0.3065,  0.9892, -0.3809,  ...,  0.4843,  0.2650,  0.4003],\n",
       "        [-0.4204,  0.3005, -0.3551,  ...,  0.2576,  0.6135,  0.2514],\n",
       "        [ 0.1153,  0.1129, -0.3060,  ..., -0.2441, -0.0024,  0.1993],\n",
       "        [-0.4667,  0.5766,  0.2039,  ..., -0.4124, -0.3936, -0.1430]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "sentences = [\n",
    "  [\"I\", \"ate\", \"an\", \"apple\", \"for\", \"breakfast\"], \n",
    "  [\"I\", \"ate\", \"a\", \"carrot\", \"for\", \"breakfast\"]\n",
    "]\n",
    "character_ids = batch_to_ids(sentences)\n",
    "\n",
    "embeddings = elmo(character_ids.to(device))\n",
    "embeddings['elmo_representations'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22254729270935059"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector1 = embeddings['elmo_representations'][0][0].cpu().detach().numpy()\n",
    "vector2 = embeddings['elmo_representations'][0][1].cpu().detach().numpy()\n",
    "scipy.spatial.distance.cosine(vector1[3], vector2[3]) # cosine distance between \"apple\" and \"carrot\" in the last layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "  \n",
    "    def _transpose_embedding(self, x):\n",
    "        return x.permute(1, 0, 2)\n",
    "\n",
    "    def __init__(self, device, elmo_embedding, input_dim, embedding_dim, \n",
    "                 hidden_dim, batch_size, output_dim=1, num_layers=1, drop_rate=0.2):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.device = device\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = elmo_embedding\n",
    "        self.output_dim = output_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.drop_rate = drop_rate\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim, hidden_size=self.hidden_dim, \n",
    "            dropout=self.drop_rate)\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def __shape_to_string(self, shape):\n",
    "        return str(shape)\n",
    "    \n",
    "    def summary(self, input_size):\n",
    "        sentence = torch.LongTensor(np.zeros(input_size)).to(self.device)\n",
    "        print(\"{:<20}  {:<25}\".format(\"input\", self.__shape_to_string(sentence.shape)))\n",
    "        embeds = self.embedding(sentence)['elmo_representations'][0]\n",
    "        print(\"{:<20}  {:<25}\".format(\"embedding\", self.__shape_to_string(embeds.shape)))\n",
    "        transposed_embeds = self._transpose_embedding(embeds)\n",
    "        print(\"{:<20}  {:<25}\".format(\"transposed_embeds\", self.__shape_to_string(transposed_embeds.shape)))\n",
    "        lstm, (hn, cn) = self.lstm(transposed_embeds)\n",
    "        print(\"{:<20}  {:<25}\".format(\"lstm\", self.__shape_to_string(lstm.shape)))\n",
    "        lstm_last_seq = lstm[self.input_dim-1, :]\n",
    "        print(\"{:<20}  {:<25}\".format(\"lstm_last_seq\", self.__shape_to_string(lstm_last_seq.shape)))\n",
    "        output = F.softmax(self.linear(lstm_last_seq))\n",
    "        print(\"{:<20}  {:<25}\".format(\"output\", self.__shape_to_string(output.shape)))\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.embedding(sentence)['elmo_representations'][0]\n",
    "        transposed_embeds = self._transpose_embedding(embeds)\n",
    "        lstm, (hn, cn) = self.lstm(transposed_embeds)\n",
    "        lstm_last_seq = lstm[self.input_dim-1,:]\n",
    "        output = F.softmax(self.linear(lstm_last_seq))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input                 torch.Size([1, 201, 50]) \n",
      "embedding             torch.Size([1, 201, 256])\n",
      "transposed_embeds     torch.Size([201, 1, 256])\n",
      "lstm                  torch.Size([201, 1, 256])\n",
      "lstm_last_seq         torch.Size([1, 256])     \n",
      "output                torch.Size([1, 7])       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "embedding_dim = 256\n",
    "hidden_dim = 256\n",
    "batch_size = 50\n",
    "output_dim = n_classes\n",
    "drop_rate = 0.2\n",
    "\n",
    "model = LSTMClassifier(device, elmo, input_dim, embedding_dim, \n",
    "                 hidden_dim, batch_size, output_dim, num_layers=1, drop_rate=drop_rate)\n",
    "model = model.to(device)\n",
    "\n",
    "model.summary([1, 201, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': <__main__.ISEAR_Tensor_Dataset at 0x7fc37af95be0>,\n",
       " 'batch_size': 50,\n",
       " 'num_workers': 0,\n",
       " 'collate_fn': <function torch.utils.data.dataloader.default_collate(batch)>,\n",
       " 'pin_memory': False,\n",
       " 'drop_last': False,\n",
       " 'timeout': 0,\n",
       " 'worker_init_fn': None,\n",
       " 'sampler': <torch.utils.data.sampler.RandomSampler at 0x7fc37b0464e0>,\n",
       " 'batch_sampler': <torch.utils.data.sampler.BatchSampler at 0x7fc37bcb6710>,\n",
       " '_DataLoader__initialized': True}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, data_loader, device, optimiser, loss_fn=nn.BCELoss(), log_interval=100):\n",
    "    #####################\n",
    "    # Train model\n",
    "    #####################\n",
    "\n",
    "    # switch model to training mode, clear gradient accumulators\n",
    "    model.train()\n",
    "    # model.hidden = model.init_hidden()\n",
    "    \n",
    "    train_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    all_pred = []\n",
    "    all_target = []\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimiser.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        train_loss += loss.data # sum up batch loss\n",
    "        \n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        pred = pred.view(pred.size(0))\n",
    "\n",
    "        target = target.max(1, keepdim=True)[1]\n",
    "        target = target.view(target.size(0))\n",
    "\n",
    "        correct = pred.eq(target.view_as(pred)).sum()\n",
    "        total_correct += correct\n",
    "\n",
    "        all_pred += pred.cpu().numpy().tolist()\n",
    "        all_target += target.cpu().numpy().tolist()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}\\t/\\t{}\\t({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data))\n",
    "    \n",
    "    print('Train: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        train_loss, total_correct, len(data_loader.dataset),\n",
    "        100. * total_correct / len(data_loader.dataset)))\n",
    "    \n",
    "    return train_loss, all_pred, all_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device, loss_fn=nn.BCELoss()):\n",
    "    #####################\n",
    "    # Evaluation model\n",
    "    #####################\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    all_pred = []\n",
    "    all_target = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            eval_loss += loss_fn(output, target).data # sum up batch loss\n",
    "            \n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            pred = pred.view(pred.size(0))\n",
    "            \n",
    "            target = target.max(1, keepdim=True)[1]\n",
    "            target = target.view(target.size(0))\n",
    "            \n",
    "            correct = pred.eq(target.view_as(pred)).sum()\n",
    "            total_correct += correct\n",
    "\n",
    "            all_pred += pred.cpu().numpy().tolist()\n",
    "            all_target += target.cpu().numpy().tolist()\n",
    "\n",
    "    print('Evaluate: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        eval_loss, total_correct, len(data_loader.dataset),\n",
    "        100. * total_correct / len(data_loader.dataset)))\n",
    "    \n",
    "    return eval_loss, all_pred, all_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/tf36/lib/python3.6/site-packages/ipykernel_launcher.py:49: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0\t/\t4292\t(0%)]\tLoss: 0.411261\n",
      "Train Epoch: 0 [500\t/\t4292\t(12%)]\tLoss: 0.410569\n",
      "Train Epoch: 0 [1000\t/\t4292\t(23%)]\tLoss: 0.411489\n",
      "Train Epoch: 0 [1500\t/\t4292\t(35%)]\tLoss: 0.409269\n",
      "Train Epoch: 0 [2000\t/\t4292\t(47%)]\tLoss: 0.412217\n",
      "Train Epoch: 0 [2500\t/\t4292\t(58%)]\tLoss: 0.410079\n",
      "Train Epoch: 0 [3000\t/\t4292\t(70%)]\tLoss: 0.410405\n",
      "Train Epoch: 0 [3500\t/\t4292\t(81%)]\tLoss: 0.410302\n",
      "Train Epoch: 0 [4000\t/\t4292\t(93%)]\tLoss: 0.409703\n",
      "Train: Average loss: 35.2894, Accuracy: 609/4292 (14%)\n",
      "Evaluate: Average loss: 9.0258, Accuracy: 153/1074 (14%)\n",
      "\n",
      "Train Epoch: 1 [0\t/\t4292\t(0%)]\tLoss: 0.411683\n",
      "Train Epoch: 1 [500\t/\t4292\t(12%)]\tLoss: 0.409128\n",
      "Train Epoch: 1 [1000\t/\t4292\t(23%)]\tLoss: 0.409962\n",
      "Train Epoch: 1 [1500\t/\t4292\t(35%)]\tLoss: 0.410264\n",
      "Train Epoch: 1 [2000\t/\t4292\t(47%)]\tLoss: 0.410494\n",
      "Train Epoch: 1 [2500\t/\t4292\t(58%)]\tLoss: 0.410222\n",
      "Train Epoch: 1 [3000\t/\t4292\t(70%)]\tLoss: 0.409522\n",
      "Train Epoch: 1 [3500\t/\t4292\t(81%)]\tLoss: 0.411628\n",
      "Train Epoch: 1 [4000\t/\t4292\t(93%)]\tLoss: 0.410132\n",
      "Train: Average loss: 35.2856, Accuracy: 579/4292 (13%)\n",
      "Evaluate: Average loss: 9.0229, Accuracy: 154/1074 (14%)\n",
      "\n",
      "Train Epoch: 2 [0\t/\t4292\t(0%)]\tLoss: 0.409895\n",
      "Train Epoch: 2 [500\t/\t4292\t(12%)]\tLoss: 0.409595\n",
      "Train Epoch: 2 [1000\t/\t4292\t(23%)]\tLoss: 0.410035\n",
      "Train Epoch: 2 [1500\t/\t4292\t(35%)]\tLoss: 0.410372\n",
      "Train Epoch: 2 [2000\t/\t4292\t(47%)]\tLoss: 0.409935\n",
      "Train Epoch: 2 [2500\t/\t4292\t(58%)]\tLoss: 0.410362\n",
      "Train Epoch: 2 [3000\t/\t4292\t(70%)]\tLoss: 0.410973\n",
      "Train Epoch: 2 [3500\t/\t4292\t(81%)]\tLoss: 0.410313\n",
      "Train Epoch: 2 [4000\t/\t4292\t(93%)]\tLoss: 0.410325\n",
      "Train: Average loss: 35.2740, Accuracy: 595/4292 (13%)\n",
      "Evaluate: Average loss: 9.0233, Accuracy: 154/1074 (14%)\n",
      "\n",
      "Train Epoch: 3 [0\t/\t4292\t(0%)]\tLoss: 0.410141\n",
      "Train Epoch: 3 [500\t/\t4292\t(12%)]\tLoss: 0.410044\n",
      "Train Epoch: 3 [1000\t/\t4292\t(23%)]\tLoss: 0.409937\n",
      "Train Epoch: 3 [1500\t/\t4292\t(35%)]\tLoss: 0.409898\n",
      "Train Epoch: 3 [2000\t/\t4292\t(47%)]\tLoss: 0.410954\n",
      "Train Epoch: 3 [2500\t/\t4292\t(58%)]\tLoss: 0.402654\n",
      "Train Epoch: 3 [3000\t/\t4292\t(70%)]\tLoss: 0.410047\n",
      "Train Epoch: 3 [3500\t/\t4292\t(81%)]\tLoss: 0.409919\n",
      "Train Epoch: 3 [4000\t/\t4292\t(93%)]\tLoss: 0.410507\n",
      "Train: Average loss: 35.2712, Accuracy: 560/4292 (13%)\n",
      "Evaluate: Average loss: 9.0230, Accuracy: 154/1074 (14%)\n",
      "\n",
      "Train Epoch: 4 [0\t/\t4292\t(0%)]\tLoss: 0.410338\n",
      "Train Epoch: 4 [500\t/\t4292\t(12%)]\tLoss: 0.410060\n",
      "Train Epoch: 4 [1000\t/\t4292\t(23%)]\tLoss: 0.410190\n",
      "Train Epoch: 4 [1500\t/\t4292\t(35%)]\tLoss: 0.409999\n",
      "Train Epoch: 4 [2000\t/\t4292\t(47%)]\tLoss: 0.410788\n",
      "Train Epoch: 4 [2500\t/\t4292\t(58%)]\tLoss: 0.410268\n",
      "Train Epoch: 4 [3000\t/\t4292\t(70%)]\tLoss: 0.410134\n",
      "Train Epoch: 4 [3500\t/\t4292\t(81%)]\tLoss: 0.410295\n",
      "Train Epoch: 4 [4000\t/\t4292\t(93%)]\tLoss: 0.409883\n",
      "Train: Average loss: 35.2737, Accuracy: 580/4292 (13%)\n",
      "Evaluate: Average loss: 9.0224, Accuracy: 154/1074 (14%)\n",
      "\n",
      "Train Epoch: 5 [0\t/\t4292\t(0%)]\tLoss: 0.410203\n",
      "Train Epoch: 5 [500\t/\t4292\t(12%)]\tLoss: 0.410065\n",
      "Train Epoch: 5 [1000\t/\t4292\t(23%)]\tLoss: 0.410503\n",
      "Train Epoch: 5 [1500\t/\t4292\t(35%)]\tLoss: 0.409290\n",
      "Train Epoch: 5 [2000\t/\t4292\t(47%)]\tLoss: 0.411932\n",
      "Train Epoch: 5 [2500\t/\t4292\t(58%)]\tLoss: 0.410588\n",
      "Train Epoch: 5 [3000\t/\t4292\t(70%)]\tLoss: 0.409794\n",
      "Train Epoch: 5 [3500\t/\t4292\t(81%)]\tLoss: 0.410394\n",
      "Train Epoch: 5 [4000\t/\t4292\t(93%)]\tLoss: 0.410790\n",
      "Train: Average loss: 35.2745, Accuracy: 593/4292 (13%)\n",
      "Evaluate: Average loss: 9.0224, Accuracy: 154/1074 (14%)\n",
      "\n",
      "Train Epoch: 6 [0\t/\t4292\t(0%)]\tLoss: 0.410609\n",
      "Train Epoch: 6 [500\t/\t4292\t(12%)]\tLoss: 0.410164\n",
      "Train Epoch: 6 [1000\t/\t4292\t(23%)]\tLoss: 0.410651\n",
      "Train Epoch: 6 [1500\t/\t4292\t(35%)]\tLoss: 0.410079\n",
      "Train Epoch: 6 [2000\t/\t4292\t(47%)]\tLoss: 0.410450\n",
      "Train Epoch: 6 [2500\t/\t4292\t(58%)]\tLoss: 0.409809\n",
      "Train Epoch: 6 [3000\t/\t4292\t(70%)]\tLoss: 0.410775\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "log_interval = 10\n",
    "max_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_loss_hist = np.zeros(max_epochs)\n",
    "eval_loss_hist = np.zeros(max_epochs)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "  \n",
    "    train_loss, train_pred, train_target = train(epoch, model, train_loader, device, optimiser, loss_fn, log_interval)\n",
    "    train_loss_hist[epoch] = train_loss\n",
    "    \n",
    "    valid_loss, valid_pred, valid_target = evaluate(model, valid_loader, device, loss_fn=nn.BCELoss())\n",
    "    eval_loss_hist[epoch] = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_loss_hist, color='skyblue')\n",
    "plt.plot(eval_loss_hist, color='red')\n",
    "plt.ylabel('Historic Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
